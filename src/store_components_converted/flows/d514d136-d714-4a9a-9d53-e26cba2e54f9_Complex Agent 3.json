{
  "id": "d514d136-d714-4a9a-9d53-e26cba2e54f9",
  "name": "Complex Agent (3)",
  "description": "This Agent is created on the fly based on what the user asks and a Manager Agent calls it if needed. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "noneu",
    "first_name": "eric",
    "last_name": "wong",
    "id": "b17846b4-4c66-41c9-93f1-4462c700dd97",
    "full_name": "eric wong"
  },
  "store_url": "https://www.langflow.store/store/component/d514d136-d714-4a9a-9d53-e26cba2e54f9",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-07-29T07:01:36.886Z",
    "updated": "2024-07-29T07:01:36.972Z",
    "downloaded": "2025-08-19T17:50:06.125Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.13",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
          "display_name": "Hierarchical Crew",
          "id": "HierarchicalCrewComponent-4Uj1M",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "display_name": "Hierarchical Crew",
            "documentation": "",
            "edited": false,
            "field_order": [
              "verbose",
              "memory",
              "use_cache",
              "max_rpm",
              "share_crew",
              "function_calling_llm",
              "agents",
              "tasks",
              "manager_llm",
              "manager_agent"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Output",
                "method": "build_output",
                "name": "output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agents": {
                "advanced": false,
                "display_name": "Agents",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Agent"
                ],
                "list": true,
                "name": "agents",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n"
              },
              "function_calling_llm": {
                "advanced": true,
                "display_name": "Function Calling LLM",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "function_calling_llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "manager_agent": {
                "advanced": false,
                "display_name": "Manager Agent",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Agent"
                ],
                "list": false,
                "name": "manager_agent",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "manager_llm": {
                "advanced": false,
                "display_name": "Manager LLM",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "manager_llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_rpm": {
                "advanced": true,
                "display_name": "Max RPM",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_rpm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "share_crew": {
                "advanced": true,
                "display_name": "Share Crew",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "share_crew",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tasks": {
                "advanced": false,
                "display_name": "Tasks",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "HierarchicalTask"
                ],
                "list": true,
                "name": "tasks",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "use_cache": {
                "advanced": true,
                "display_name": "Cache",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "use_cache",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "verbose": {
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 0
              }
            }
          },
          "type": "HierarchicalCrewComponent"
        },
        "height": 499,
        "id": "HierarchicalCrewComponent-4Uj1M",
        "position": {
          "x": 2444.845721347115,
          "y": 1410.1850661630874
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-M9PCX",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-3.5-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            }
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 639,
        "id": "OpenAIModel-M9PCX",
        "position": {
          "x": 993.5222179419411,
          "y": 2121.1120144471624
        },
        "positionAbsolute": {
          "x": 993.5222179419411,
          "y": 2121.1120144471624
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-MqBuM",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "ChatOutput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "data_template": {
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "Session ID for the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            }
          },
          "type": "ChatOutput"
        },
        "height": 317,
        "id": "ChatOutput-MqBuM",
        "position": {
          "x": 2947.7605810360546,
          "y": 1557.6959660020289
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Each task must have a description, an expected output and an agent responsible for execution.",
          "display_name": "Hierarchical Task",
          "id": "HierarchicalTaskComponent-uvvXY",
          "node": {
            "base_classes": [
              "HierarchicalTask"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "display_name": "Hierarchical Task",
            "documentation": "",
            "edited": false,
            "field_order": [
              "task_description",
              "expected_output",
              "tools"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Task",
                "method": "build_task",
                "name": "task_output",
                "selected": "HierarchicalTask",
                "types": [
                  "HierarchicalTask"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n"
              },
              "expected_output": {
                "advanced": false,
                "display_name": "Expected Output",
                "dynamic": false,
                "info": "Clear definition of expected task outcome.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "expected_output",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Succinct response that answers the User's query."
              },
              "task_description": {
                "advanced": false,
                "display_name": "Description",
                "dynamic": false,
                "info": "Descriptive text detailing task's purpose and execution.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "task_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tools": {
                "advanced": true,
                "display_name": "Tools",
                "dynamic": false,
                "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            }
          },
          "type": "HierarchicalTaskComponent"
        },
        "height": 463,
        "id": "HierarchicalTaskComponent-uvvXY",
        "position": {
          "x": 1940.5188074417165,
          "y": 682.2998623189735
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-Sovbo",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            }
          },
          "type": "CrewAIAgentComponent"
        },
        "dragging": false,
        "height": 689,
        "id": "CrewAIAgentComponent-Sovbo",
        "position": {
          "x": 1397.4912377259789,
          "y": 1242.739374306084
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-YuOXi",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are polite and helpful. You've always been a beacon of politeness."
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You can answer general questions from the User and may call others for help if needed."
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Manager"
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            }
          },
          "type": "CrewAIAgentComponent"
        },
        "dragging": false,
        "height": 689,
        "id": "CrewAIAgentComponent-YuOXi",
        "position": {
          "x": 1897.563645835175,
          "y": 2043.8342912334688
        },
        "positionAbsolute": {
          "x": 1897.563645835175,
          "y": 2043.8342912334688
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-rjBJH",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            }
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 639,
        "id": "OpenAIModel-rjBJH",
        "position": {
          "x": 1689.7403176652529,
          "y": 2778.554803586579
        },
        "positionAbsolute": {
          "x": 1689.7403176652529,
          "y": 2778.554803586579
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-4Y9vu",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "query": {
                "advanced": false,
                "display_name": "query",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "query",
                "password": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed. If it is just a general query (e.g a greeting) you can respond them directly."
              }
            }
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 431,
        "id": "Prompt-4Y9vu",
        "position": {
          "x": 1314.943965489173,
          "y": 624.296875
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "ChatInput-qSNp5",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "ChatInput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Could you search info about AAPL?"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "Session ID for the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            }
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 317,
        "id": "ChatInput-qSNp5",
        "position": {
          "x": -812.219234501281,
          "y": 283.9527676042414
        },
        "positionAbsolute": {
          "x": -812.219234501281,
          "y": 283.9527676042414
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Tool for interacting with Yahoo Finance News.",
          "display_name": "Yahoo Finance News Tool",
          "id": "YFinanceTool-dNohd",
          "node": {
            "base_classes": [
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Tool for interacting with Yahoo Finance News.",
            "display_name": "Yahoo Finance News Tool",
            "documentation": "",
            "edited": false,
            "field_order": [],
            "frozen": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "tool",
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import cast\n\nfrom langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.io import Output\n\n\nclass YfinanceToolComponent(Component):\n    display_name = \"Yahoo Finance News Tool\"\n    description = \"Tool for interacting with Yahoo Finance News.\"\n    name = \"YFinanceTool\"\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\n    ]\n\n    def build_tool(self) -> Tool:\n        return cast(Tool, YahooFinanceNewsTool())\n"
              }
            }
          },
          "type": "YFinanceTool"
        },
        "dragging": false,
        "height": 227,
        "id": "YFinanceTool-dNohd",
        "position": {
          "x": 339.85802955438953,
          "y": 941.0061737791777
        },
        "positionAbsolute": {
          "x": 339.85802955438953,
          "y": 941.0061737791777
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-UzvYL",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-3.5-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            }
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 639,
        "id": "OpenAIModel-UzvYL",
        "position": {
          "x": -1421.3072930401338,
          "y": 944.2116827656167
        },
        "positionAbsolute": {
          "x": -1421.3072930401338,
          "y": 944.2116827656167
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-6jr8o",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Role Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "query": {
                "advanced": false,
                "display_name": "query",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "query",
                "password": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Define a Role that could execute or answer well the user's query.\n\nUser's query: {query}\n\nRole should be two words max. Something like \"Researcher\" or \"Software Developer\".\n"
              }
            }
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 431,
        "id": "Prompt-6jr8o",
        "position": {
          "x": -1968.539387148609,
          "y": 742.2153329137714
        },
        "positionAbsolute": {
          "x": -1968.539387148609,
          "y": 742.2153329137714
        },
        "selected": true,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-knIJ9",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "json_mode",
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "combobox": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "gpt-3.5-turbo",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "output_schema",
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1,
                "name": "seed",
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "load_from_db": false
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.1,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false
          },
          "type": "OpenAIModel",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI"
        },
        "dragging": false,
        "height": 639,
        "id": "OpenAIModel-knIJ9",
        "position": {
          "x": -522.221251851577,
          "y": 2109.2822016163946
        },
        "positionAbsolute": {
          "x": -522.221251851577,
          "y": 2109.2822016163946
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-fXAPy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "query",
                "role"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Goal Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "query": {
                "advanced": false,
                "display_name": "query",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "query",
                "password": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "role": {
                "advanced": false,
                "display_name": "role",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "password": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Define the Goal of this Role, given the User's Query. \nUser's query: {query}\n\nRole: {role}\n\nThe goal should be concise and specific.\nGoal: \n"
              }
            }
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 525,
        "id": "Prompt-fXAPy",
        "position": {
          "x": -1127.1897676702288,
          "y": 1693.922415635935
        },
        "positionAbsolute": {
          "x": -1127.1897676702288,
          "y": 1693.922415635935
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-4VkJT",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-3.5-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            }
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 639,
        "id": "OpenAIModel-4VkJT",
        "position": {
          "x": -173.231944282948,
          "y": 3277.114857802737
        },
        "positionAbsolute": {
          "x": -173.231944282948,
          "y": 3277.114857802737
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-tdfhI",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "goal": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "goal",
                "display_name": "goal",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "role": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "role",
                "display_name": "role",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Define a Backstory of this Role and Goal, given the User's Query. \nUser's query: {query}\n\nRole: {role}\nGoal: {goal}\n\nThe backstory should be specific and well aligned with the rest of the information.\nBackstory:"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query",
                "role",
                "goal"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 619,
        "id": "Prompt-tdfhI",
        "position": {
          "x": -559.9999554636487,
          "y": 2893.2894056013133
        },
        "positionAbsolute": {
          "x": -559.9999554636487,
          "y": 2893.2894056013133
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Call the searchapi.io API",
          "display_name": "Search API",
          "id": "SearchAPI-92fIN",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Call the searchapi.io API",
            "display_name": "Search API",
            "documentation": "https://www.searchapi.io/docs/google",
            "edited": false,
            "field_order": [
              "engine",
              "api_key",
              "input_value",
              "search_params"
            ],
            "frozen": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "run_model",
                "name": "api_run_model",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "advanced": false,
                "display_name": "SearchAPI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Union\n\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import SecretStrInput, MultilineInput, DictInput, MessageTextInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\n\n\nclass SearchAPIComponent(LCToolComponent):\n    display_name: str = \"Search API\"\n    description: str = \"Call the searchapi.io API\"\n    name = \"SearchAPI\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n\n    inputs = [\n        MessageTextInput(name=\"engine\", display_name=\"Engine\", value=\"google\"),\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\n    ]\n\n    def run_model(self) -> Union[Data, list[Data]]:\n        wrapper = self._build_wrapper()\n        results = wrapper.results(query=self.input_value, **(self.search_params or {}))\n        list_results = results.get(\"organic_results\", [])\n        data = [Data(data=result, text=result[\"snippet\"]) for result in list_results]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return Tool(\n            name=\"search_api\",\n            description=\"Search for recent results.\",\n            func=lambda x: wrapper.run(query=x, **(self.search_params or {})),\n        )\n\n    def _build_wrapper(self):\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\n"
              },
              "engine": {
                "advanced": false,
                "display_name": "Engine",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "engine",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "google"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_params": {
                "advanced": true,
                "display_name": "Search parameters",
                "dynamic": false,
                "info": "",
                "list": true,
                "name": "search_params",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              }
            }
          },
          "type": "SearchAPI"
        },
        "dragging": false,
        "height": 561,
        "id": "SearchAPI-92fIN",
        "position": {
          "x": 401.20112810226453,
          "y": 226.06794616816035
        },
        "positionAbsolute": {
          "x": 401.20112810226453,
          "y": 226.06794616816035
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "APIRequest-SFKVs",
        "type": "genericNode",
        "position": {
          "x": 49.02363588374208,
          "y": 1342.3639425303813
        },
        "data": {
          "type": "APIRequest",
          "node": {
            "template": {
              "_type": "Component",
              "query_params": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "query_params",
                "display_name": "Query Parameters",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "body": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "body",
                "display_name": "Body",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import asyncio\nimport json\nfrom typing import Any, List, Optional\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport httpx\nfrom loguru import logger\n\nfrom axiestudio.base.curl.parse import parse_context\nfrom axiestudio.custom import Component\nfrom axiestudio.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = (\n        \"This component allows you to make HTTP requests to one or more URLs. \"\n        \"You can provide headers and body as either dictionaries or Data objects. \"\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\n        \"**Note:** Check advanced options for more settings.\"\n    )\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n        ),\n        MessageTextInput(\n            name=\"curl\",\n            display_name=\"Curl\",\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\n            value=\"GET\",\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\n        ),\n        NestedDictInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        NestedDictInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=5,\n            info=\"The timeout to use for the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n    ]\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        try:\n            parsed = parse_context(curl)\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"value\"] = dict(parsed.headers)\n\n            if parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    build_config[\"body\"][\"value\"] = json_data\n                except json.JSONDecodeError as e:\n                    logger.error(f\"Error decoding JSON data: {e}\")\n            else:\n                build_config[\"body\"][\"value\"] = {}\n        except Exception as exc:\n            logger.error(f\"Error parsing curl: {exc}\")\n            raise ValueError(f\"Error parsing curl: {exc}\")\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"curl\" and field_value:\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: Optional[dict] = None,\n        body: Optional[dict] = None,\n        timeout: int = 5,\n    ) -> Data:\n        method = method.upper()\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\n            raise ValueError(f\"Unsupported method: {method}\")\n\n        if isinstance(body, str) and body:\n            try:\n                body = json.loads(body)\n            except Exception as e:\n                logger.error(f\"Error decoding JSON data: {e}\")\n                body = None\n                raise ValueError(f\"Error decoding JSON data: {e}\")\n\n        data = body if body else None\n\n        try:\n            response = await client.request(method, url, headers=headers, json=data, timeout=timeout)\n            try:\n                result = response.json()\n            except Exception:\n                result = response.text\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": response.status_code,\n                    \"result\": result,\n                },\n            )\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> List[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        curl = self.curl\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        query_params = self.query_params.data if self.query_params else {}\n\n        if curl:\n            self._build_config = self.parse_curl(curl, dotdict())\n\n        if isinstance(headers, Data):\n            headers = headers.data\n\n        if isinstance(body, Data):\n            body = body.data\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\n            )\n        self.status = results\n        return results\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "curl": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "curl",
                "display_name": "Curl",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "headers": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "headers",
                "display_name": "Headers",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "method": {
                "combobox": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "GET",
                "name": "method",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "5",
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": false,
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "urls": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": [
                  "",
                  ""
                ],
                "name": "urls",
                "display_name": "URLs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter one or more URLs, separated by commas.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "API Request",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "make_requests",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "urls",
              "curl",
              "method",
              "headers",
              "body",
              "query_params",
              "timeout"
            ],
            "beta": false,
            "edited": false
          },
          "id": "APIRequest-SFKVs"
        },
        "selected": false,
        "width": 384,
        "height": 1087,
        "dragging": false
      },
      {
        "id": "RecursiveCharacterTextSplitter-aqflH",
        "type": "genericNode",
        "position": {
          "x": -714.489026289207,
          "y": 1471.1842490855413
        },
        "data": {
          "type": "RecursiveCharacterTextSplitter",
          "node": {
            "template": {
              "_type": "Component",
              "data_input": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "data_input",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Data"
                ],
                "dynamic": false,
                "info": "The texts to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 200,
                "name": "chunk_overlap",
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1000,
                "name": "chunk_size",
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom axiestudio.base.textsplitters.model import LCTextSplitterComponent\nfrom axiestudio.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom axiestudio.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separators": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "separators",
                "display_name": "Separators",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text trying to keep all related text together.",
            "base_classes": [
              "Data"
            ],
            "display_name": "Recursive Character Text Splitter",
            "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "split_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "chunk_size",
              "chunk_overlap",
              "data_input",
              "separators"
            ],
            "beta": false,
            "edited": false
          },
          "id": "RecursiveCharacterTextSplitter-aqflH"
        },
        "selected": false,
        "width": 384,
        "height": 573,
        "positionAbsolute": {
          "x": -714.489026289207,
          "y": 1471.1842490855413
        },
        "dragging": false
      },
      {
        "id": "CohereRerank-TuwVP",
        "type": "genericNode",
        "position": {
          "x": 696.7293491502287,
          "y": 1238.3748920468363
        },
        "data": {
          "type": "CohereRerank",
          "node": {
            "template": {
              "_type": "Component",
              "retriever": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "retriever",
                "display_name": "Retriever",
                "advanced": false,
                "input_types": [
                  "Retriever"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, cast\n\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain_cohere import CohereRerank\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.field_typing import Retriever\nfrom axiestudio.io import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, SecretStrInput\nfrom axiestudio.schema import Data\n\n\nclass CohereRerankComponent(LCVectorStoreComponent):\n    display_name = \"Cohere Rerank\"\n    description = \"Rerank documents using the Cohere API and a retriever.\"\n    name = \"CohereRerank\"\n    icon = \"Cohere\"\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n                \"rerank-english-v2.0\",\n                \"rerank-multilingual-v2.0\",\n            ],\n            value=\"rerank-english-v3.0\",\n        ),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        IntInput(name=\"top_n\", display_name=\"Top N\", value=3),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", value=\"axiestudio\", advanced=True),\n        HandleInput(name=\"retriever\", display_name=\"Retriever\", input_types=[\"Retriever\"]),\n    ]\n\n    def build_base_retriever(self) -> Retriever:  # type: ignore[type-var]\n        cohere_reranker = CohereRerank(\n            cohere_api_key=self.api_key, model=self.model, top_n=self.top_n, user_agent=self.user_agent\n        )\n        retriever = ContextualCompressionRetriever(base_compressor=cohere_reranker, base_retriever=self.retriever)\n        return cast(Retriever, retriever)\n\n    async def search_documents(self) -> List[Data]:  # type: ignore\n        retriever = self.build_base_retriever()\n        documents = await retriever.ainvoke(self.search_query)\n        data = self.to_data(documents)\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "combobox": false,
                "trace_as_metadata": true,
                "options": [
                  "rerank-english-v3.0",
                  "rerank-multilingual-v3.0",
                  "rerank-english-v2.0",
                  "rerank-multilingual-v2.0"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "rerank-english-v3.0",
                "name": "model",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "search_query",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "top_n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 3,
                "name": "top_n",
                "display_name": "Top N",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "user_agent": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "axiestudio",
                "name": "user_agent",
                "display_name": "User Agent",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Rerank documents using the Cohere API and a retriever.",
            "icon": "Cohere",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "Cohere Rerank",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "search_query",
              "model",
              "api_key",
              "top_n",
              "user_agent",
              "retriever"
            ],
            "beta": false,
            "edited": false
          },
          "id": "CohereRerank-TuwVP"
        },
        "selected": false,
        "width": 384,
        "height": 779,
        "positionAbsolute": {
          "x": 696.7293491502287,
          "y": 1238.3748920468363
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "HierarchicalCrewComponent",
            "id": "HierarchicalCrewComponent-4Uj1M",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-MqBuM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-HierarchicalCrewComponent-4Uj1M{dataType:HierarchicalCrewComponent,id:HierarchicalCrewComponent-4Uj1M,name:output,output_types:[Message]}-ChatOutput-MqBuM{fieldName:input_value,id:ChatOutput-MqBuM,inputTypes:[Message],type:str}",
        "selected": false,
        "source": "HierarchicalCrewComponent-4Uj1M",
        "sourceHandle": "{dataType:HierarchicalCrewComponent,id:HierarchicalCrewComponent-4Uj1M,name:output,output_types:[Message]}",
        "target": "ChatOutput-MqBuM",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-MqBuM,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "HierarchicalTaskComponent",
            "id": "HierarchicalTaskComponent-uvvXY",
            "name": "task_output",
            "output_types": [
              "HierarchicalTask"
            ]
          },
          "targetHandle": {
            "fieldName": "tasks",
            "id": "HierarchicalCrewComponent-4Uj1M",
            "inputTypes": [
              "HierarchicalTask"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-HierarchicalTaskComponent-uvvXY{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-uvvXY,name:task_output,output_types:[HierarchicalTask]}-HierarchicalCrewComponent-4Uj1M{fieldName:tasks,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[HierarchicalTask],type:other}",
        "selected": false,
        "source": "HierarchicalTaskComponent-uvvXY",
        "sourceHandle": "{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-uvvXY,name:task_output,output_types:[HierarchicalTask]}",
        "target": "HierarchicalCrewComponent-4Uj1M",
        "targetHandle": "{fieldName:tasks,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[HierarchicalTask],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-Sovbo",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          },
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-4Uj1M",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-Sovbo{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Sovbo,name:output,output_types:[Agent]}-HierarchicalCrewComponent-4Uj1M{fieldName:agents,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}",
        "selected": false,
        "source": "CrewAIAgentComponent-Sovbo",
        "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Sovbo,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-4Uj1M",
        "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-M9PCX",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-Sovbo",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-M9PCX{dataType:OpenAIModel,id:OpenAIModel-M9PCX,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-Sovbo{fieldName:llm,id:CrewAIAgentComponent-Sovbo,inputTypes:[LanguageModel],type:other}",
        "selected": false,
        "source": "OpenAIModel-M9PCX",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-M9PCX,name:model_output,output_types:[LanguageModel]}",
        "target": "CrewAIAgentComponent-Sovbo",
        "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-Sovbo,inputTypes:[LanguageModel],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-YuOXi",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          },
          "targetHandle": {
            "fieldName": "manager_agent",
            "id": "HierarchicalCrewComponent-4Uj1M",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-YuOXi{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-YuOXi,name:output,output_types:[Agent]}-HierarchicalCrewComponent-4Uj1M{fieldName:manager_agent,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}",
        "selected": false,
        "source": "CrewAIAgentComponent-YuOXi",
        "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-YuOXi,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-4Uj1M",
        "targetHandle": "{fieldName:manager_agent,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-rjBJH",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-YuOXi",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-rjBJH{dataType:OpenAIModel,id:OpenAIModel-rjBJH,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-YuOXi{fieldName:llm,id:CrewAIAgentComponent-YuOXi,inputTypes:[LanguageModel],type:other}",
        "selected": false,
        "source": "OpenAIModel-rjBJH",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-rjBJH,name:model_output,output_types:[LanguageModel]}",
        "target": "CrewAIAgentComponent-YuOXi",
        "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-YuOXi,inputTypes:[LanguageModel],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-4Y9vu",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "task_description",
            "id": "HierarchicalTaskComponent-uvvXY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-4Y9vu{dataType:Prompt,id:Prompt-4Y9vu,name:prompt,output_types:[Message]}-HierarchicalTaskComponent-uvvXY{fieldName:task_description,id:HierarchicalTaskComponent-uvvXY,inputTypes:[Message],type:str}",
        "selected": false,
        "source": "Prompt-4Y9vu",
        "sourceHandle": "{dataType:Prompt,id:Prompt-4Y9vu,name:prompt,output_types:[Message]}",
        "target": "HierarchicalTaskComponent-uvvXY",
        "targetHandle": "{fieldName:task_description,id:HierarchicalTaskComponent-uvvXY,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-qSNp5",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-4Y9vu",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-4Y9vu{fieldName:query,id:Prompt-4Y9vu,inputTypes:[Message,Text],type:str}",
        "selected": false,
        "source": "ChatInput-qSNp5",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
        "target": "Prompt-4Y9vu",
        "targetHandle": "{fieldName:query,id:Prompt-4Y9vu,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "YFinanceTool",
            "id": "YFinanceTool-dNohd",
            "name": "tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-Sovbo",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-YFinanceTool-dNohd{dataType:YFinanceTool,id:YFinanceTool-dNohd,name:tool,output_types:[Tool]}-CrewAIAgentComponent-Sovbo{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "YFinanceTool-dNohd",
        "sourceHandle": "{dataType:YFinanceTool,id:YFinanceTool-dNohd,name:tool,output_types:[Tool]}",
        "target": "CrewAIAgentComponent-Sovbo",
        "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-6jr8o",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-UzvYL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-6jr8o{dataType:Prompt,id:Prompt-6jr8o,name:prompt,output_types:[Message]}-OpenAIModel-UzvYL{fieldName:input_value,id:OpenAIModel-UzvYL,inputTypes:[Message],type:str}",
        "selected": false,
        "source": "Prompt-6jr8o",
        "sourceHandle": "{dataType:Prompt,id:Prompt-6jr8o,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-UzvYL",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-UzvYL,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-qSNp5",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-fXAPy",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-fXAPy{fieldName:query,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}",
        "selected": false,
        "source": "ChatInput-qSNp5",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
        "target": "Prompt-fXAPy",
        "targetHandle": "{fieldName:query,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-qSNp5",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-6jr8o",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-6jr8o{fieldName:query,id:Prompt-6jr8o,inputTypes:[Message,Text],type:str}",
        "selected": false,
        "source": "ChatInput-qSNp5",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
        "target": "Prompt-6jr8o",
        "targetHandle": "{fieldName:query,id:Prompt-6jr8o,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-fXAPy",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-knIJ9",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-fXAPy{dataType:Prompt,id:Prompt-fXAPy,name:prompt,output_types:[Message]}-OpenAIModel-knIJ9{fieldName:input_value,id:OpenAIModel-knIJ9,inputTypes:[Message],type:str}",
        "selected": false,
        "source": "Prompt-fXAPy",
        "sourceHandle": "{dataType:Prompt,id:Prompt-fXAPy,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-knIJ9",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-knIJ9,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-UzvYL",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "role",
            "id": "Prompt-fXAPy",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-UzvYL{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}-Prompt-fXAPy{fieldName:role,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}",
        "selected": false,
        "source": "OpenAIModel-UzvYL",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}",
        "target": "Prompt-fXAPy",
        "targetHandle": "{fieldName:role,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-tdfhI",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-4VkJT",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-tdfhI{dataType:Prompt,id:Prompt-tdfhI,name:prompt,output_types:[Message]}-OpenAIModel-4VkJT{fieldName:input_value,id:OpenAIModel-4VkJT,inputTypes:[Message],type:str}",
        "selected": false,
        "source": "Prompt-tdfhI",
        "sourceHandle": "{dataType:Prompt,id:Prompt-tdfhI,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-4VkJT",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-4VkJT,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-knIJ9",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "goal",
            "id": "Prompt-tdfhI",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-knIJ9{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}-Prompt-tdfhI{fieldName:goal,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}",
        "source": "OpenAIModel-knIJ9",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}",
        "target": "Prompt-tdfhI",
        "targetHandle": "{fieldName:goal,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-UzvYL",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "role",
            "id": "Prompt-tdfhI",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-UzvYL{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}-Prompt-tdfhI{fieldName:role,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}",
        "source": "OpenAIModel-UzvYL",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}",
        "target": "Prompt-tdfhI",
        "targetHandle": "{fieldName:role,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-qSNp5",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-tdfhI",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-tdfhI{fieldName:query,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}",
        "source": "ChatInput-qSNp5",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
        "target": "Prompt-tdfhI",
        "targetHandle": "{fieldName:query,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-4VkJT",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "backstory",
            "id": "CrewAIAgentComponent-Sovbo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-4VkJT{dataType:OpenAIModel,id:OpenAIModel-4VkJT,name:text_output,output_types:[Message]}-CrewAIAgentComponent-Sovbo{fieldName:backstory,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
        "source": "OpenAIModel-4VkJT",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-4VkJT,name:text_output,output_types:[Message]}",
        "target": "CrewAIAgentComponent-Sovbo",
        "targetHandle": "{fieldName:backstory,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SearchAPI",
            "id": "SearchAPI-92fIN",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-Sovbo",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SearchAPI-92fIN{dataType:SearchAPI,id:SearchAPI-92fIN,name:api_build_tool,output_types:[Tool]}-CrewAIAgentComponent-Sovbo{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}",
        "source": "SearchAPI-92fIN",
        "sourceHandle": "{dataType:SearchAPI,id:SearchAPI-92fIN,name:api_build_tool,output_types:[Tool]}",
        "target": "CrewAIAgentComponent-Sovbo",
        "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-UzvYL",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "role",
            "id": "CrewAIAgentComponent-Sovbo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "source": "OpenAIModel-UzvYL",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}",
        "target": "CrewAIAgentComponent-Sovbo",
        "targetHandle": "{fieldName:role,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-OpenAIModel-UzvYL{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}-CrewAIAgentComponent-Sovbo{fieldName:role,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}"
      },
      {
        "source": "OpenAIModel-knIJ9",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}",
        "target": "CrewAIAgentComponent-Sovbo",
        "targetHandle": "{fieldName:goal,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "goal",
            "id": "CrewAIAgentComponent-Sovbo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-knIJ9",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-knIJ9{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}-CrewAIAgentComponent-Sovbo{fieldName:goal,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "RecursiveCharacterTextSplitter-aqflH",
        "sourceHandle": "{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-aqflH,name:data,output_types:[Data]}",
        "target": "APIRequest-SFKVs",
        "targetHandle": "{fieldName:headers,id:APIRequest-SFKVs,inputTypes:[Data],type:NestedDict}",
        "data": {
          "targetHandle": {
            "fieldName": "headers",
            "id": "APIRequest-SFKVs",
            "inputTypes": [
              "Data"
            ],
            "type": "NestedDict"
          },
          "sourceHandle": {
            "dataType": "RecursiveCharacterTextSplitter",
            "id": "RecursiveCharacterTextSplitter-aqflH",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-RecursiveCharacterTextSplitter-aqflH{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-aqflH,name:data,output_types:[Data]}-APIRequest-SFKVs{fieldName:headers,id:APIRequest-SFKVs,inputTypes:[Data],type:NestedDict}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 1761.9091190225383,
      "y": -561.7308773494083,
      "zoom": 0.852960938209022
    }
  },
  "metadata": {
    "HierarchicalCrewComponent": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 5
    },
    "ChatOutput": {
      "count": 1
    },
    "HierarchicalTaskComponent": {
      "count": 1
    },
    "CrewAIAgentComponent": {
      "count": 2
    },
    "Prompt": {
      "count": 4
    },
    "ChatInput": {
      "count": 1
    },
    "YFinanceTool": {
      "count": 1
    },
    "SearchAPI": {
      "count": 1
    },
    "APIRequest": {
      "count": 1
    },
    "RecursiveCharacterTextSplitter": {
      "count": 1
    },
    "CohereRerank": {
      "count": 1
    },
    "total": 20
  },
  "original": {
    "id": "d514d136-d714-4a9a-9d53-e26cba2e54f9",
    "name": "Complex Agent (3)",
    "description": "This Agent is created on the fly based on what the user asks and a Manager Agent calls it if needed.",
    "is_component": false,
    "liked_by_count": "4",
    "downloads_count": "41",
    "metadata": {
      "HierarchicalCrewComponent": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 5
      },
      "ChatOutput": {
        "count": 1
      },
      "HierarchicalTaskComponent": {
        "count": 1
      },
      "CrewAIAgentComponent": {
        "count": 2
      },
      "Prompt": {
        "count": 4
      },
      "ChatInput": {
        "count": 1
      },
      "YFinanceTool": {
        "count": 1
      },
      "SearchAPI": {
        "count": 1
      },
      "APIRequest": {
        "count": 1
      },
      "RecursiveCharacterTextSplitter": {
        "count": 1
      },
      "CohereRerank": {
        "count": 1
      },
      "total": 20
    },
    "last_tested_version": "1.0.13",
    "private": false,
    "data": {
      "nodes": [
        {
          "data": {
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "display_name": "Hierarchical Crew",
            "id": "HierarchicalCrewComponent-4Uj1M",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
              "display_name": "Hierarchical Crew",
              "documentation": "",
              "edited": false,
              "field_order": [
                "verbose",
                "memory",
                "use_cache",
                "max_rpm",
                "share_crew",
                "function_calling_llm",
                "agents",
                "tasks",
                "manager_llm",
                "manager_agent"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Output",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "agents": {
                  "advanced": false,
                  "display_name": "Agents",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Agent"
                  ],
                  "list": true,
                  "name": "agents",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n"
                },
                "function_calling_llm": {
                  "advanced": true,
                  "display_name": "Function Calling LLM",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "function_calling_llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "manager_agent": {
                  "advanced": false,
                  "display_name": "Manager Agent",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Agent"
                  ],
                  "list": false,
                  "name": "manager_agent",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "manager_llm": {
                  "advanced": false,
                  "display_name": "Manager LLM",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "manager_llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "max_rpm": {
                  "advanced": true,
                  "display_name": "Max RPM",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "max_rpm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 100
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "share_crew": {
                  "advanced": true,
                  "display_name": "Share Crew",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "share_crew",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "tasks": {
                  "advanced": false,
                  "display_name": "Tasks",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "HierarchicalTask"
                  ],
                  "list": true,
                  "name": "tasks",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "use_cache": {
                  "advanced": true,
                  "display_name": "Cache",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "use_cache",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "verbose": {
                  "advanced": true,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 0
                }
              }
            },
            "type": "HierarchicalCrewComponent"
          },
          "height": 499,
          "id": "HierarchicalCrewComponent-4Uj1M",
          "position": {
            "x": 2444.845721347115,
            "y": 1410.1850661630874
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-M9PCX",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-3.5-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "openai_api_key": {
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [],
                  "load_from_db": false,
                  "name": "openai_api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              }
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 639,
          "id": "OpenAIModel-M9PCX",
          "position": {
            "x": 993.5222179419411,
            "y": 2121.1120144471624
          },
          "positionAbsolute": {
            "x": 993.5222179419411,
            "y": 2121.1120144471624
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "id": "ChatOutput-MqBuM",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Display a chat message in the Playground.",
              "display_name": "Chat Output",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "frozen": false,
              "icon": "ChatOutput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "data_template": {
                  "advanced": true,
                  "display_name": "Data Template",
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "data_template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "{text}"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Machine"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "AI"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "should_store_message": {
                  "advanced": true,
                  "display_name": "Store Messages",
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "should_store_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              }
            },
            "type": "ChatOutput"
          },
          "height": 317,
          "id": "ChatOutput-MqBuM",
          "position": {
            "x": 2947.7605810360546,
            "y": 1557.6959660020289
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "display_name": "Hierarchical Task",
            "id": "HierarchicalTaskComponent-uvvXY",
            "node": {
              "base_classes": [
                "HierarchicalTask"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Each task must have a description, an expected output and an agent responsible for execution.",
              "display_name": "Hierarchical Task",
              "documentation": "",
              "edited": false,
              "field_order": [
                "task_description",
                "expected_output",
                "tools"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Task",
                  "method": "build_task",
                  "name": "task_output",
                  "selected": "HierarchicalTask",
                  "types": [
                    "HierarchicalTask"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n"
                },
                "expected_output": {
                  "advanced": false,
                  "display_name": "Expected Output",
                  "dynamic": false,
                  "info": "Clear definition of expected task outcome.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "expected_output",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Succinct response that answers the User's query."
                },
                "task_description": {
                  "advanced": false,
                  "display_name": "Description",
                  "dynamic": false,
                  "info": "Descriptive text detailing task's purpose and execution.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "task_description",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "tools": {
                  "advanced": true,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                }
              }
            },
            "type": "HierarchicalTaskComponent"
          },
          "height": 463,
          "id": "HierarchicalTaskComponent-uvvXY",
          "position": {
            "x": 1940.5188074417165,
            "y": 682.2998623189735
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-Sovbo",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Represents an agent of CrewAI.",
              "display_name": "CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": true,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                }
              }
            },
            "type": "CrewAIAgentComponent"
          },
          "dragging": false,
          "height": 689,
          "id": "CrewAIAgentComponent-Sovbo",
          "position": {
            "x": 1397.4912377259789,
            "y": 1242.739374306084
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-YuOXi",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Represents an agent of CrewAI.",
              "display_name": "CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "You are polite and helpful. You've always been a beacon of politeness."
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "You can answer general questions from the User and may call others for help if needed."
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Manager"
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": true,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                }
              }
            },
            "type": "CrewAIAgentComponent"
          },
          "dragging": false,
          "height": 689,
          "id": "CrewAIAgentComponent-YuOXi",
          "position": {
            "x": 1897.563645835175,
            "y": 2043.8342912334688
          },
          "positionAbsolute": {
            "x": 1897.563645835175,
            "y": 2043.8342912334688
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-rjBJH",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-4o"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "openai_api_key": {
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [],
                  "load_from_db": false,
                  "name": "openai_api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              }
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 639,
          "id": "OpenAIModel-rjBJH",
          "position": {
            "x": 1689.7403176652529,
            "y": 2778.554803586579
          },
          "positionAbsolute": {
            "x": 1689.7403176652529,
            "y": 2778.554803586579
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-4Y9vu",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {
                "template": [
                  "query"
                ]
              },
              "description": "Create a prompt template with dynamic variables.",
              "display_name": "Prompt",
              "documentation": "",
              "edited": false,
              "error": null,
              "field_order": [
                "template"
              ],
              "frozen": false,
              "full_path": null,
              "icon": "prompts",
              "is_composition": null,
              "is_input": null,
              "is_output": null,
              "name": "",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Prompt Message",
                  "hidden": null,
                  "method": "build_prompt",
                  "name": "prompt",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "query": {
                  "advanced": false,
                  "display_name": "query",
                  "dynamic": false,
                  "field_type": "str",
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "query",
                  "password": false,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed. If it is just a general query (e.g a greeting) you can respond them directly."
                }
              }
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 431,
          "id": "Prompt-4Y9vu",
          "position": {
            "x": 1314.943965489173,
            "y": 624.296875
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "ChatInput-qSNp5",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Get chat inputs from the Playground.",
              "display_name": "Chat Input",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "frozen": false,
              "icon": "ChatInput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "files": {
                  "advanced": true,
                  "display_name": "Files",
                  "dynamic": false,
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "file_path": "",
                  "info": "Files to be sent with the message.",
                  "list": true,
                  "name": "files",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "file",
                  "value": ""
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Could you search info about AAPL?"
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "User"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "User"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "should_store_message": {
                  "advanced": true,
                  "display_name": "Store Messages",
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "should_store_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              }
            },
            "type": "ChatInput"
          },
          "dragging": false,
          "height": 317,
          "id": "ChatInput-qSNp5",
          "position": {
            "x": -812.219234501281,
            "y": 283.9527676042414
          },
          "positionAbsolute": {
            "x": -812.219234501281,
            "y": 283.9527676042414
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Tool for interacting with Yahoo Finance News.",
            "display_name": "Yahoo Finance News Tool",
            "id": "YFinanceTool-dNohd",
            "node": {
              "base_classes": [
                "Tool"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Tool for interacting with Yahoo Finance News.",
              "display_name": "Yahoo Finance News Tool",
              "documentation": "",
              "edited": false,
              "field_order": [],
              "frozen": false,
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Tool",
                  "method": "build_tool",
                  "name": "tool",
                  "selected": "Tool",
                  "types": [
                    "Tool"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from typing import cast\n\nfrom langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.io import Output\n\n\nclass YfinanceToolComponent(Component):\n    display_name = \"Yahoo Finance News Tool\"\n    description = \"Tool for interacting with Yahoo Finance News.\"\n    name = \"YFinanceTool\"\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\n    ]\n\n    def build_tool(self) -> Tool:\n        return cast(Tool, YahooFinanceNewsTool())\n"
                }
              }
            },
            "type": "YFinanceTool"
          },
          "dragging": false,
          "height": 227,
          "id": "YFinanceTool-dNohd",
          "position": {
            "x": 339.85802955438953,
            "y": 941.0061737791777
          },
          "positionAbsolute": {
            "x": 339.85802955438953,
            "y": 941.0061737791777
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-UzvYL",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-3.5-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "openai_api_key": {
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [],
                  "load_from_db": false,
                  "name": "openai_api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              }
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 639,
          "id": "OpenAIModel-UzvYL",
          "position": {
            "x": -1421.3072930401338,
            "y": 944.2116827656167
          },
          "positionAbsolute": {
            "x": -1421.3072930401338,
            "y": 944.2116827656167
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-6jr8o",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {
                "template": [
                  "query"
                ]
              },
              "description": "Create a prompt template with dynamic variables.",
              "display_name": "Role Prompt",
              "documentation": "",
              "edited": false,
              "error": null,
              "field_order": [
                "template"
              ],
              "frozen": false,
              "full_path": null,
              "icon": "prompts",
              "is_composition": null,
              "is_input": null,
              "is_output": null,
              "name": "",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Prompt Message",
                  "hidden": null,
                  "method": "build_prompt",
                  "name": "prompt",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "query": {
                  "advanced": false,
                  "display_name": "query",
                  "dynamic": false,
                  "field_type": "str",
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "query",
                  "password": false,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Define a Role that could execute or answer well the user's query.\n\nUser's query: {query}\n\nRole should be two words max. Something like \"Researcher\" or \"Software Developer\".\n"
                }
              }
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 431,
          "id": "Prompt-6jr8o",
          "position": {
            "x": -1968.539387148609,
            "y": 742.2153329137714
          },
          "positionAbsolute": {
            "x": -1968.539387148609,
            "y": 742.2153329137714
          },
          "selected": true,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-knIJ9",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "json_mode",
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "combobox": false,
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "gpt-3.5-turbo",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput",
                  "load_from_db": false
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "output_schema",
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1,
                  "name": "seed",
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput",
                  "load_from_db": false
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.1,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false
            },
            "type": "OpenAIModel",
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI"
          },
          "dragging": false,
          "height": 639,
          "id": "OpenAIModel-knIJ9",
          "position": {
            "x": -522.221251851577,
            "y": 2109.2822016163946
          },
          "positionAbsolute": {
            "x": -522.221251851577,
            "y": 2109.2822016163946
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-fXAPy",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {
                "template": [
                  "query",
                  "role"
                ]
              },
              "description": "Create a prompt template with dynamic variables.",
              "display_name": "Goal Prompt",
              "documentation": "",
              "edited": false,
              "error": null,
              "field_order": [
                "template"
              ],
              "frozen": false,
              "full_path": null,
              "icon": "prompts",
              "is_composition": null,
              "is_input": null,
              "is_output": null,
              "name": "",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Prompt Message",
                  "hidden": null,
                  "method": "build_prompt",
                  "name": "prompt",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "query": {
                  "advanced": false,
                  "display_name": "query",
                  "dynamic": false,
                  "field_type": "str",
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "query",
                  "password": false,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "role": {
                  "advanced": false,
                  "display_name": "role",
                  "dynamic": false,
                  "field_type": "str",
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "password": false,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Define the Goal of this Role, given the User's Query. \nUser's query: {query}\n\nRole: {role}\n\nThe goal should be concise and specific.\nGoal: \n"
                }
              }
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 525,
          "id": "Prompt-fXAPy",
          "position": {
            "x": -1127.1897676702288,
            "y": 1693.922415635935
          },
          "positionAbsolute": {
            "x": -1127.1897676702288,
            "y": 1693.922415635935
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-4VkJT",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-3.5-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "openai_api_key": {
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [],
                  "load_from_db": false,
                  "name": "openai_api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              }
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 639,
          "id": "OpenAIModel-4VkJT",
          "position": {
            "x": -173.231944282948,
            "y": 3277.114857802737
          },
          "positionAbsolute": {
            "x": -173.231944282948,
            "y": 3277.114857802737
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-tdfhI",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "goal": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "goal",
                  "display_name": "goal",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "query": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "query",
                  "display_name": "query",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "role": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "role",
                  "display_name": "role",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Define a Backstory of this Role and Goal, given the User's Query. \nUser's query: {query}\n\nRole: {role}\nGoal: {goal}\n\nThe backstory should be specific and well aligned with the rest of the information.\nBackstory:"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "query",
                  "role",
                  "goal"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 619,
          "id": "Prompt-tdfhI",
          "position": {
            "x": -559.9999554636487,
            "y": 2893.2894056013133
          },
          "positionAbsolute": {
            "x": -559.9999554636487,
            "y": 2893.2894056013133
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Call the searchapi.io API",
            "display_name": "Search API",
            "id": "SearchAPI-92fIN",
            "node": {
              "base_classes": [
                "Data",
                "Tool"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Call the searchapi.io API",
              "display_name": "Search API",
              "documentation": "https://www.searchapi.io/docs/google",
              "edited": false,
              "field_order": [
                "engine",
                "api_key",
                "input_value",
                "search_params"
              ],
              "frozen": false,
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Data",
                  "method": "run_model",
                  "name": "api_run_model",
                  "selected": "Data",
                  "types": [
                    "Data"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Tool",
                  "method": "build_tool",
                  "name": "api_build_tool",
                  "selected": "Tool",
                  "types": [
                    "Tool"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "advanced": false,
                  "display_name": "SearchAPI API Key",
                  "dynamic": false,
                  "info": "",
                  "input_types": [],
                  "load_from_db": false,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from typing import Union\n\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import SecretStrInput, MultilineInput, DictInput, MessageTextInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\n\n\nclass SearchAPIComponent(LCToolComponent):\n    display_name: str = \"Search API\"\n    description: str = \"Call the searchapi.io API\"\n    name = \"SearchAPI\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n\n    inputs = [\n        MessageTextInput(name=\"engine\", display_name=\"Engine\", value=\"google\"),\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\n    ]\n\n    def run_model(self) -> Union[Data, list[Data]]:\n        wrapper = self._build_wrapper()\n        results = wrapper.results(query=self.input_value, **(self.search_params or {}))\n        list_results = results.get(\"organic_results\", [])\n        data = [Data(data=result, text=result[\"snippet\"]) for result in list_results]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return Tool(\n            name=\"search_api\",\n            description=\"Search for recent results.\",\n            func=lambda x: wrapper.run(query=x, **(self.search_params or {})),\n        )\n\n    def _build_wrapper(self):\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\n"
                },
                "engine": {
                  "advanced": false,
                  "display_name": "Engine",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "engine",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "google"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "search_params": {
                  "advanced": true,
                  "display_name": "Search parameters",
                  "dynamic": false,
                  "info": "",
                  "list": true,
                  "name": "search_params",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                }
              }
            },
            "type": "SearchAPI"
          },
          "dragging": false,
          "height": 561,
          "id": "SearchAPI-92fIN",
          "position": {
            "x": 401.20112810226453,
            "y": 226.06794616816035
          },
          "positionAbsolute": {
            "x": 401.20112810226453,
            "y": 226.06794616816035
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "APIRequest-SFKVs",
          "type": "genericNode",
          "position": {
            "x": 49.02363588374208,
            "y": 1342.3639425303813
          },
          "data": {
            "type": "APIRequest",
            "node": {
              "template": {
                "_type": "Component",
                "query_params": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "query_params",
                  "display_name": "Query Parameters",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The query parameters to append to the URL.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "body": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "body",
                  "display_name": "Body",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
                  "title_case": false,
                  "type": "NestedDict",
                  "_input_type": "NestedDictInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import asyncio\nimport json\nfrom typing import Any, List, Optional\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport httpx\nfrom loguru import logger\n\nfrom axiestudio.base.curl.parse import parse_context\nfrom axiestudio.custom import Component\nfrom axiestudio.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = (\n        \"This component allows you to make HTTP requests to one or more URLs. \"\n        \"You can provide headers and body as either dictionaries or Data objects. \"\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\n        \"**Note:** Check advanced options for more settings.\"\n    )\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n        ),\n        MessageTextInput(\n            name=\"curl\",\n            display_name=\"Curl\",\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\n            value=\"GET\",\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\n        ),\n        NestedDictInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        NestedDictInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=5,\n            info=\"The timeout to use for the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n    ]\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        try:\n            parsed = parse_context(curl)\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"value\"] = dict(parsed.headers)\n\n            if parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    build_config[\"body\"][\"value\"] = json_data\n                except json.JSONDecodeError as e:\n                    logger.error(f\"Error decoding JSON data: {e}\")\n            else:\n                build_config[\"body\"][\"value\"] = {}\n        except Exception as exc:\n            logger.error(f\"Error parsing curl: {exc}\")\n            raise ValueError(f\"Error parsing curl: {exc}\")\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"curl\" and field_value:\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: Optional[dict] = None,\n        body: Optional[dict] = None,\n        timeout: int = 5,\n    ) -> Data:\n        method = method.upper()\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\n            raise ValueError(f\"Unsupported method: {method}\")\n\n        if isinstance(body, str) and body:\n            try:\n                body = json.loads(body)\n            except Exception as e:\n                logger.error(f\"Error decoding JSON data: {e}\")\n                body = None\n                raise ValueError(f\"Error decoding JSON data: {e}\")\n\n        data = body if body else None\n\n        try:\n            response = await client.request(method, url, headers=headers, json=data, timeout=timeout)\n            try:\n                result = response.json()\n            except Exception:\n                result = response.text\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": response.status_code,\n                    \"result\": result,\n                },\n            )\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> List[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        curl = self.curl\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        query_params = self.query_params.data if self.query_params else {}\n\n        if curl:\n            self._build_config = self.parse_curl(curl, dotdict())\n\n        if isinstance(headers, Data):\n            headers = headers.data\n\n        if isinstance(body, Data):\n            body = body.data\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\n            )\n        self.status = results\n        return results\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "curl": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "curl",
                  "display_name": "Curl",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "headers": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "headers",
                  "display_name": "Headers",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
                  "title_case": false,
                  "type": "NestedDict",
                  "_input_type": "NestedDictInput"
                },
                "method": {
                  "combobox": false,
                  "trace_as_metadata": true,
                  "options": [
                    "GET",
                    "POST",
                    "PATCH",
                    "PUT"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "GET",
                  "name": "method",
                  "display_name": "Method",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "5",
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The timeout to use for the request.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "urls": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": [
                    "",
                    ""
                  ],
                  "name": "urls",
                  "display_name": "URLs",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter one or more URLs, separated by commas.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
              "icon": "Globe",
              "base_classes": [
                "Data"
              ],
              "display_name": "API Request",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "make_requests",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "urls",
                "curl",
                "method",
                "headers",
                "body",
                "query_params",
                "timeout"
              ],
              "beta": false,
              "edited": false
            },
            "id": "APIRequest-SFKVs"
          },
          "selected": false,
          "width": 384,
          "height": 1087,
          "dragging": false
        },
        {
          "id": "RecursiveCharacterTextSplitter-aqflH",
          "type": "genericNode",
          "position": {
            "x": -714.489026289207,
            "y": 1471.1842490855413
          },
          "data": {
            "type": "RecursiveCharacterTextSplitter",
            "node": {
              "template": {
                "_type": "Component",
                "data_input": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "data_input",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The texts to split.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "chunk_overlap": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 200,
                  "name": "chunk_overlap",
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The amount of overlap between chunks.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1000,
                  "name": "chunk_size",
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum length of each chunk.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom axiestudio.base.textsplitters.model import LCTextSplitterComponent\nfrom axiestudio.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom axiestudio.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separators": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "separators",
                  "display_name": "Separators",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Split text trying to keep all related text together.",
              "base_classes": [
                "Data"
              ],
              "display_name": "Recursive Character Text Splitter",
              "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "split_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "chunk_size",
                "chunk_overlap",
                "data_input",
                "separators"
              ],
              "beta": false,
              "edited": false
            },
            "id": "RecursiveCharacterTextSplitter-aqflH"
          },
          "selected": false,
          "width": 384,
          "height": 573,
          "positionAbsolute": {
            "x": -714.489026289207,
            "y": 1471.1842490855413
          },
          "dragging": false
        },
        {
          "id": "CohereRerank-TuwVP",
          "type": "genericNode",
          "position": {
            "x": 696.7293491502287,
            "y": 1238.3748920468363
          },
          "data": {
            "type": "CohereRerank",
            "node": {
              "template": {
                "_type": "Component",
                "retriever": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "retriever",
                  "display_name": "Retriever",
                  "advanced": false,
                  "input_types": [
                    "Retriever"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, cast\n\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain_cohere import CohereRerank\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.field_typing import Retriever\nfrom axiestudio.io import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, SecretStrInput\nfrom axiestudio.schema import Data\n\n\nclass CohereRerankComponent(LCVectorStoreComponent):\n    display_name = \"Cohere Rerank\"\n    description = \"Rerank documents using the Cohere API and a retriever.\"\n    name = \"CohereRerank\"\n    icon = \"Cohere\"\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n                \"rerank-english-v2.0\",\n                \"rerank-multilingual-v2.0\",\n            ],\n            value=\"rerank-english-v3.0\",\n        ),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        IntInput(name=\"top_n\", display_name=\"Top N\", value=3),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", value=\"axiestudio\", advanced=True),\n        HandleInput(name=\"retriever\", display_name=\"Retriever\", input_types=[\"Retriever\"]),\n    ]\n\n    def build_base_retriever(self) -> Retriever:  # type: ignore[type-var]\n        cohere_reranker = CohereRerank(\n            cohere_api_key=self.api_key, model=self.model, top_n=self.top_n, user_agent=self.user_agent\n        )\n        retriever = ContextualCompressionRetriever(base_compressor=cohere_reranker, base_retriever=self.retriever)\n        return cast(Retriever, retriever)\n\n    async def search_documents(self) -> List[Data]:  # type: ignore\n        retriever = self.build_base_retriever()\n        documents = await retriever.ainvoke(self.search_query)\n        data = self.to_data(documents)\n        self.status = data\n        return data\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "model": {
                  "combobox": false,
                  "trace_as_metadata": true,
                  "options": [
                    "rerank-english-v3.0",
                    "rerank-multilingual-v3.0",
                    "rerank-english-v2.0",
                    "rerank-multilingual-v2.0"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "rerank-english-v3.0",
                  "name": "model",
                  "display_name": "Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "search_query",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "top_n": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 3,
                  "name": "top_n",
                  "display_name": "Top N",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "user_agent": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "axiestudio",
                  "name": "user_agent",
                  "display_name": "User Agent",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Rerank documents using the Cohere API and a retriever.",
              "icon": "Cohere",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "Cohere Rerank",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "search_query",
                "model",
                "api_key",
                "top_n",
                "user_agent",
                "retriever"
              ],
              "beta": false,
              "edited": false
            },
            "id": "CohereRerank-TuwVP"
          },
          "selected": false,
          "width": 384,
          "height": 779,
          "positionAbsolute": {
            "x": 696.7293491502287,
            "y": 1238.3748920468363
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "HierarchicalCrewComponent",
              "id": "HierarchicalCrewComponent-4Uj1M",
              "name": "output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-MqBuM",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-HierarchicalCrewComponent-4Uj1M{dataType:HierarchicalCrewComponent,id:HierarchicalCrewComponent-4Uj1M,name:output,output_types:[Message]}-ChatOutput-MqBuM{fieldName:input_value,id:ChatOutput-MqBuM,inputTypes:[Message],type:str}",
          "selected": false,
          "source": "HierarchicalCrewComponent-4Uj1M",
          "sourceHandle": "{dataType:HierarchicalCrewComponent,id:HierarchicalCrewComponent-4Uj1M,name:output,output_types:[Message]}",
          "target": "ChatOutput-MqBuM",
          "targetHandle": "{fieldName:input_value,id:ChatOutput-MqBuM,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "HierarchicalTaskComponent",
              "id": "HierarchicalTaskComponent-uvvXY",
              "name": "task_output",
              "output_types": [
                "HierarchicalTask"
              ]
            },
            "targetHandle": {
              "fieldName": "tasks",
              "id": "HierarchicalCrewComponent-4Uj1M",
              "inputTypes": [
                "HierarchicalTask"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-HierarchicalTaskComponent-uvvXY{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-uvvXY,name:task_output,output_types:[HierarchicalTask]}-HierarchicalCrewComponent-4Uj1M{fieldName:tasks,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[HierarchicalTask],type:other}",
          "selected": false,
          "source": "HierarchicalTaskComponent-uvvXY",
          "sourceHandle": "{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-uvvXY,name:task_output,output_types:[HierarchicalTask]}",
          "target": "HierarchicalCrewComponent-4Uj1M",
          "targetHandle": "{fieldName:tasks,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[HierarchicalTask],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-Sovbo",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            },
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-4Uj1M",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-Sovbo{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Sovbo,name:output,output_types:[Agent]}-HierarchicalCrewComponent-4Uj1M{fieldName:agents,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}",
          "selected": false,
          "source": "CrewAIAgentComponent-Sovbo",
          "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Sovbo,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-4Uj1M",
          "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-M9PCX",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            },
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-Sovbo",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-OpenAIModel-M9PCX{dataType:OpenAIModel,id:OpenAIModel-M9PCX,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-Sovbo{fieldName:llm,id:CrewAIAgentComponent-Sovbo,inputTypes:[LanguageModel],type:other}",
          "selected": false,
          "source": "OpenAIModel-M9PCX",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-M9PCX,name:model_output,output_types:[LanguageModel]}",
          "target": "CrewAIAgentComponent-Sovbo",
          "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-Sovbo,inputTypes:[LanguageModel],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-YuOXi",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            },
            "targetHandle": {
              "fieldName": "manager_agent",
              "id": "HierarchicalCrewComponent-4Uj1M",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-YuOXi{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-YuOXi,name:output,output_types:[Agent]}-HierarchicalCrewComponent-4Uj1M{fieldName:manager_agent,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}",
          "selected": false,
          "source": "CrewAIAgentComponent-YuOXi",
          "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-YuOXi,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-4Uj1M",
          "targetHandle": "{fieldName:manager_agent,id:HierarchicalCrewComponent-4Uj1M,inputTypes:[Agent],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-rjBJH",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            },
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-YuOXi",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-OpenAIModel-rjBJH{dataType:OpenAIModel,id:OpenAIModel-rjBJH,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-YuOXi{fieldName:llm,id:CrewAIAgentComponent-YuOXi,inputTypes:[LanguageModel],type:other}",
          "selected": false,
          "source": "OpenAIModel-rjBJH",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-rjBJH,name:model_output,output_types:[LanguageModel]}",
          "target": "CrewAIAgentComponent-YuOXi",
          "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-YuOXi,inputTypes:[LanguageModel],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-4Y9vu",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "task_description",
              "id": "HierarchicalTaskComponent-uvvXY",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Prompt-4Y9vu{dataType:Prompt,id:Prompt-4Y9vu,name:prompt,output_types:[Message]}-HierarchicalTaskComponent-uvvXY{fieldName:task_description,id:HierarchicalTaskComponent-uvvXY,inputTypes:[Message],type:str}",
          "selected": false,
          "source": "Prompt-4Y9vu",
          "sourceHandle": "{dataType:Prompt,id:Prompt-4Y9vu,name:prompt,output_types:[Message]}",
          "target": "HierarchicalTaskComponent-uvvXY",
          "targetHandle": "{fieldName:task_description,id:HierarchicalTaskComponent-uvvXY,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-qSNp5",
              "name": "message",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "query",
              "id": "Prompt-4Y9vu",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-4Y9vu{fieldName:query,id:Prompt-4Y9vu,inputTypes:[Message,Text],type:str}",
          "selected": false,
          "source": "ChatInput-qSNp5",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
          "target": "Prompt-4Y9vu",
          "targetHandle": "{fieldName:query,id:Prompt-4Y9vu,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "YFinanceTool",
              "id": "YFinanceTool-dNohd",
              "name": "tool",
              "output_types": [
                "Tool"
              ]
            },
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-Sovbo",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-YFinanceTool-dNohd{dataType:YFinanceTool,id:YFinanceTool-dNohd,name:tool,output_types:[Tool]}-CrewAIAgentComponent-Sovbo{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}",
          "selected": false,
          "source": "YFinanceTool-dNohd",
          "sourceHandle": "{dataType:YFinanceTool,id:YFinanceTool-dNohd,name:tool,output_types:[Tool]}",
          "target": "CrewAIAgentComponent-Sovbo",
          "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-6jr8o",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-UzvYL",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Prompt-6jr8o{dataType:Prompt,id:Prompt-6jr8o,name:prompt,output_types:[Message]}-OpenAIModel-UzvYL{fieldName:input_value,id:OpenAIModel-UzvYL,inputTypes:[Message],type:str}",
          "selected": false,
          "source": "Prompt-6jr8o",
          "sourceHandle": "{dataType:Prompt,id:Prompt-6jr8o,name:prompt,output_types:[Message]}",
          "target": "OpenAIModel-UzvYL",
          "targetHandle": "{fieldName:input_value,id:OpenAIModel-UzvYL,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-qSNp5",
              "name": "message",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "query",
              "id": "Prompt-fXAPy",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-fXAPy{fieldName:query,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}",
          "selected": false,
          "source": "ChatInput-qSNp5",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
          "target": "Prompt-fXAPy",
          "targetHandle": "{fieldName:query,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-qSNp5",
              "name": "message",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "query",
              "id": "Prompt-6jr8o",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-6jr8o{fieldName:query,id:Prompt-6jr8o,inputTypes:[Message,Text],type:str}",
          "selected": false,
          "source": "ChatInput-qSNp5",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
          "target": "Prompt-6jr8o",
          "targetHandle": "{fieldName:query,id:Prompt-6jr8o,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-fXAPy",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-knIJ9",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Prompt-fXAPy{dataType:Prompt,id:Prompt-fXAPy,name:prompt,output_types:[Message]}-OpenAIModel-knIJ9{fieldName:input_value,id:OpenAIModel-knIJ9,inputTypes:[Message],type:str}",
          "selected": false,
          "source": "Prompt-fXAPy",
          "sourceHandle": "{dataType:Prompt,id:Prompt-fXAPy,name:prompt,output_types:[Message]}",
          "target": "OpenAIModel-knIJ9",
          "targetHandle": "{fieldName:input_value,id:OpenAIModel-knIJ9,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-UzvYL",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "role",
              "id": "Prompt-fXAPy",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-OpenAIModel-UzvYL{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}-Prompt-fXAPy{fieldName:role,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}",
          "selected": false,
          "source": "OpenAIModel-UzvYL",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}",
          "target": "Prompt-fXAPy",
          "targetHandle": "{fieldName:role,id:Prompt-fXAPy,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-tdfhI",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-4VkJT",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Prompt-tdfhI{dataType:Prompt,id:Prompt-tdfhI,name:prompt,output_types:[Message]}-OpenAIModel-4VkJT{fieldName:input_value,id:OpenAIModel-4VkJT,inputTypes:[Message],type:str}",
          "selected": false,
          "source": "Prompt-tdfhI",
          "sourceHandle": "{dataType:Prompt,id:Prompt-tdfhI,name:prompt,output_types:[Message]}",
          "target": "OpenAIModel-4VkJT",
          "targetHandle": "{fieldName:input_value,id:OpenAIModel-4VkJT,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-knIJ9",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "goal",
              "id": "Prompt-tdfhI",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-OpenAIModel-knIJ9{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}-Prompt-tdfhI{fieldName:goal,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}",
          "source": "OpenAIModel-knIJ9",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}",
          "target": "Prompt-tdfhI",
          "targetHandle": "{fieldName:goal,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-UzvYL",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "role",
              "id": "Prompt-tdfhI",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-OpenAIModel-UzvYL{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}-Prompt-tdfhI{fieldName:role,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}",
          "source": "OpenAIModel-UzvYL",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}",
          "target": "Prompt-tdfhI",
          "targetHandle": "{fieldName:role,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-qSNp5",
              "name": "message",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "query",
              "id": "Prompt-tdfhI",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-ChatInput-qSNp5{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}-Prompt-tdfhI{fieldName:query,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}",
          "source": "ChatInput-qSNp5",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-qSNp5,name:message,output_types:[Message]}",
          "target": "Prompt-tdfhI",
          "targetHandle": "{fieldName:query,id:Prompt-tdfhI,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-4VkJT",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "backstory",
              "id": "CrewAIAgentComponent-Sovbo",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-OpenAIModel-4VkJT{dataType:OpenAIModel,id:OpenAIModel-4VkJT,name:text_output,output_types:[Message]}-CrewAIAgentComponent-Sovbo{fieldName:backstory,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
          "source": "OpenAIModel-4VkJT",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-4VkJT,name:text_output,output_types:[Message]}",
          "target": "CrewAIAgentComponent-Sovbo",
          "targetHandle": "{fieldName:backstory,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "SearchAPI",
              "id": "SearchAPI-92fIN",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            },
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-Sovbo",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-SearchAPI-92fIN{dataType:SearchAPI,id:SearchAPI-92fIN,name:api_build_tool,output_types:[Tool]}-CrewAIAgentComponent-Sovbo{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}",
          "source": "SearchAPI-92fIN",
          "sourceHandle": "{dataType:SearchAPI,id:SearchAPI-92fIN,name:api_build_tool,output_types:[Tool]}",
          "target": "CrewAIAgentComponent-Sovbo",
          "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-Sovbo,inputTypes:[Tool],type:other}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-UzvYL",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "role",
              "id": "CrewAIAgentComponent-Sovbo",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "selected": false,
          "source": "OpenAIModel-UzvYL",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}",
          "target": "CrewAIAgentComponent-Sovbo",
          "targetHandle": "{fieldName:role,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
          "id": "reactflow__edge-OpenAIModel-UzvYL{dataType:OpenAIModel,id:OpenAIModel-UzvYL,name:text_output,output_types:[Message]}-CrewAIAgentComponent-Sovbo{fieldName:role,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}"
        },
        {
          "source": "OpenAIModel-knIJ9",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}",
          "target": "CrewAIAgentComponent-Sovbo",
          "targetHandle": "{fieldName:goal,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "goal",
              "id": "CrewAIAgentComponent-Sovbo",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-knIJ9",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-knIJ9{dataType:OpenAIModel,id:OpenAIModel-knIJ9,name:text_output,output_types:[Message]}-CrewAIAgentComponent-Sovbo{fieldName:goal,id:CrewAIAgentComponent-Sovbo,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "RecursiveCharacterTextSplitter-aqflH",
          "sourceHandle": "{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-aqflH,name:data,output_types:[Data]}",
          "target": "APIRequest-SFKVs",
          "targetHandle": "{fieldName:headers,id:APIRequest-SFKVs,inputTypes:[Data],type:NestedDict}",
          "data": {
            "targetHandle": {
              "fieldName": "headers",
              "id": "APIRequest-SFKVs",
              "inputTypes": [
                "Data"
              ],
              "type": "NestedDict"
            },
            "sourceHandle": {
              "dataType": "RecursiveCharacterTextSplitter",
              "id": "RecursiveCharacterTextSplitter-aqflH",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-RecursiveCharacterTextSplitter-aqflH{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-aqflH,name:data,output_types:[Data]}-APIRequest-SFKVs{fieldName:headers,id:APIRequest-SFKVs,inputTypes:[Data],type:NestedDict}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 1761.9091190225383,
        "y": -561.7308773494083,
        "zoom": 0.852960938209022
      }
    },
    "date_created": "2024-07-29T07:01:36.886Z",
    "date_updated": "2024-07-29T07:01:36.972Z",
    "status": "Public",
    "sort": null,
    "user_updated": "b17846b4-4c66-41c9-93f1-4462c700dd97",
    "user_created": {
      "username": "noneu",
      "first_name": "eric",
      "last_name": "wong",
      "id": "b17846b4-4c66-41c9-93f1-4462c700dd97"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.180Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 176,
    "converter_version": "1.0.0"
  }
}