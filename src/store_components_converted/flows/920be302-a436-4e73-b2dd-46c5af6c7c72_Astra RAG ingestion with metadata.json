{
  "id": "920be302-a436-4e73-b2dd-46c5af6c7c72",
  "name": "Astra RAG ingestion with metadata",
  "description": "This flow illustrates the RAG ingestion process and enables metadata configuration details necessary for ingestion. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "boreilly",
    "first_name": "Betul",
    "last_name": "O'Reilly",
    "id": "76f05705-dfce-454b-8d27-4f5f02d94090",
    "full_name": "Betul O'Reilly"
  },
  "store_url": "https://www.langflow.store/store/component/920be302-a436-4e73-b2dd-46c5af6c7c72",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-11-04T13:37:46.476Z",
    "updated": "2024-11-04T13:37:46.576Z",
    "downloaded": "2025-08-19T17:50:07.385Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.18",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "SplitText-lPyKW",
        "type": "genericNode",
        "position": {
          "x": 2101.296326300341,
          "y": 54.21875
        },
        "data": {
          "description": "Split text into chunks based on specified criteria.",
          "display_name": "Split Text",
          "id": "SplitText-lPyKW",
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, IntInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        data = []\n        for doc in docs:\n            data.append(Data(text=doc.page_content, data=doc.metadata))\n        return data\n\n    def split_text(self) -> List[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = []\n        for _input in self.data_inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "\n",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Data"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "SplitText"
        },
        "selected": false,
        "width": 384,
        "height": 550
      },
      {
        "id": "File-m1Sk9",
        "type": "genericNode",
        "position": {
          "x": 566.1567912366198,
          "y": 234.5783049628651
        },
        "data": {
          "description": "A generic file loader.",
          "display_name": "File",
          "id": "File-m1Sk9",
          "node": {
            "template": {
              "_type": "Component",
              "path": {
                "trace_as_metadata": true,
                "file_path": "d7b63ed2-91e6-47bf-bf0e-89a552f12feb/2024-11-04_14-36-37_Onboarding Questions - Google Docs.pdf",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "",
                "display_name": "Path",
                "advanced": false,
                "dynamic": false,
                "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pathlib import Path\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, FileInput, Output\nfrom axiestudio.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data if data else \"No data\"\n        return data or Data()\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "A generic file loader.",
            "icon": "file-text",
            "base_classes": [
              "Data"
            ],
            "display_name": "File",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_file",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path",
              "silent_errors"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "File"
        },
        "selected": false,
        "width": 384,
        "height": 302
      },
      {
        "id": "AstraVectorStoreComponent-HBw7g",
        "type": "genericNode",
        "position": {
          "x": 2735.5225490940675,
          "y": 136.24107902189598
        },
        "data": {
          "description": "ðŸ’¡ Select a Database and a Collection, or create new ones. Click  â–¶ï¸ **Play** to load your data.*If you're using OS Langflow, Paste your Astra DB Application Token here.*",
          "display_name": "Astra DB",
          "edited": false,
          "id": "AstraVectorStoreComponent-HBw7g",
          "node": {
            "base_classes": [
              "Data",
              "Retriever"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "ðŸ’¡ Select a Database and a Collection, or create new ones. Click â–¶ï¸ **Play** to load your data.*If you're using OS Langflow, Paste your Astra DB Application Token here.*",
            "display_name": "Astra DB",
            "documentation": "https://docs.axiestudio.org/starter-projects-vector-store-rag",
            "edited": false,
            "field_order": [
              "collection_name",
              "token",
              "api_endpoint",
              "search_input",
              "ingest_data",
              "namespace",
              "metric",
              "batch_size",
              "bulk_insert_batch_concurrency",
              "bulk_insert_overwrite_concurrency",
              "bulk_delete_concurrency",
              "setup_mode",
              "pre_delete_collection",
              "metadata_indexing_include",
              "embedding",
              "metadata_indexing_exclude",
              "collection_indexing_policy",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "search_filter"
            ],
            "frozen": false,
            "icon": "AstraDB",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "name": "base_retriever",
                "required_inputs": [],
                "selected": "Retriever",
                "types": [
                  "Retriever"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "api_endpoint",
                  "batch_size",
                  "bulk_delete_concurrency",
                  "bulk_insert_batch_concurrency",
                  "bulk_insert_overwrite_concurrency",
                  "collection_indexing_policy",
                  "collection_name",
                  "embedding",
                  "ingest_data",
                  "metadata_indexing_exclude",
                  "metadata_indexing_include",
                  "metric",
                  "namespace",
                  "number_of_results",
                  "pre_delete_collection",
                  "search_filter",
                  "search_input",
                  "search_score_threshold",
                  "search_type",
                  "setup_mode",
                  "token"
                ],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "name": "vector_store",
                "required_inputs": [],
                "selected": "VectorStore",
                "types": [
                  "VectorStore"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "advanced": false,
                "display_name": "API Endpoint",
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_endpoint",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "batch_size": {
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Optional number of data to process in a single batch.",
                "list": false,
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_delete_concurrency": {
                "advanced": true,
                "display_name": "Bulk Delete Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk delete operations.",
                "list": false,
                "name": "bulk_delete_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_batch_concurrency": {
                "advanced": true,
                "display_name": "Bulk Insert Batch Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations.",
                "list": false,
                "name": "bulk_insert_batch_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_overwrite_concurrency": {
                "advanced": true,
                "display_name": "Bulk Insert Overwrite Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                "list": false,
                "name": "bulk_insert_overwrite_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\n\nfrom astrapy.admin import parse_api_endpoint\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.helpers import docs_to_data\nfrom axiestudio.inputs import DictInput, FloatInput, MessageTextInput\nfrom axiestudio.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom axiestudio.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://docs.axiestudio.org/starter-projects-vector-store-rag\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    VECTORIZE_PROVIDERS_MAPPING = {\n        \"Azure OpenAI\": [\"azureOpenAI\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Hugging Face - Dedicated\": [\"huggingfaceDedicated\", [\"endpoint-defined-model\"]],\n        \"Hugging Face - Serverless\": [\n            \"huggingface\",\n            [\n                \"sentence-transformers/all-MiniLM-L6-v2\",\n                \"intfloat/multilingual-e5-large\",\n                \"intfloat/multilingual-e5-large-instruct\",\n                \"BAAI/bge-small-en-v1.5\",\n                \"BAAI/bge-base-en-v1.5\",\n                \"BAAI/bge-large-en-v1.5\",\n            ],\n        ],\n        \"Jina AI\": [\n            \"jinaAI\",\n            [\n                \"jina-embeddings-v2-base-en\",\n                \"jina-embeddings-v2-base-de\",\n                \"jina-embeddings-v2-base-es\",\n                \"jina-embeddings-v2-base-code\",\n                \"jina-embeddings-v2-base-zh\",\n            ],\n        ],\n        \"Mistral AI\": [\"mistral\", [\"mistral-embed\"]],\n        \"NVIDIA\": [\"nvidia\", [\"NV-Embed-QA\"]],\n        \"OpenAI\": [\"openai\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Upstage\": [\"upstageAI\", [\"solar-embedding-1-large\"]],\n        \"Voyage AI\": [\n            \"voyageAI\",\n            [\"voyage-large-2-instruct\", \"voyage-law-2\", \"voyage-code-2\", \"voyage-large-2\", \"voyage-2\"],\n        ],\n    }\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"embedding_service\",\n            display_name=\"Embedding Model or Astra Vectorize\",\n            info=\"Determines whether to use Astra Vectorize for the collection.\",\n            options=[\"Embedding Model\", \"Astra Vectorize\"],\n            real_time_refresh=True,\n            value=\"Embedding Model\",\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    def insert_in_dict(self, build_config, field_name, new_parameters):\n        # Insert the new key-value pair after the found key\n        for new_field_name, new_parameter in new_parameters.items():\n            # Get all the items as a list of tuples (key, value)\n            items = list(build_config.items())\n\n            # Find the index of the key to insert after\n            idx = len(items)\n            for i, (key, _value) in enumerate(items):\n                if key == field_name:\n                    idx = i + 1\n                    break\n\n            items.insert(idx, (new_field_name, new_parameter))\n\n            # Clear the original dictionary and update with the modified items\n            build_config.clear()\n            build_config.update(items)\n\n        return build_config\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name == \"embedding_service\":\n            if field_value == \"Astra Vectorize\":\n                for field in [\"embedding\"]:\n                    if field in build_config:\n                        del build_config[field]\n\n                new_parameter = DropdownInput(\n                    name=\"provider\",\n                    display_name=\"Vectorize Provider\",\n                    options=self.VECTORIZE_PROVIDERS_MAPPING.keys(),\n                    value=\"\",\n                    required=True,\n                    real_time_refresh=True,\n                ).to_dict()\n\n                self.insert_in_dict(build_config, \"embedding_service\", {\"provider\": new_parameter})\n            else:\n                for field in [\n                    \"provider\",\n                    \"z_00_model_name\",\n                    \"z_01_model_parameters\",\n                    \"z_02_api_key_name\",\n                    \"z_03_provider_api_key\",\n                    \"z_04_authentication\",\n                ]:\n                    if field in build_config:\n                        del build_config[field]\n\n                new_parameter = HandleInput(\n                    name=\"embedding\",\n                    display_name=\"Embedding Model\",\n                    input_types=[\"Embeddings\"],\n                    info=\"Allows an embedding model configuration.\",\n                ).to_dict()\n\n                self.insert_in_dict(build_config, \"embedding_service\", {\"embedding\": new_parameter})\n\n        elif field_name == \"provider\":\n            for field in [\n                \"z_00_model_name\",\n                \"z_01_model_parameters\",\n                \"z_02_api_key_name\",\n                \"z_03_provider_api_key\",\n                \"z_04_authentication\",\n            ]:\n                if field in build_config:\n                    del build_config[field]\n\n            model_options = self.VECTORIZE_PROVIDERS_MAPPING[field_value][1]\n\n            new_parameter_0 = DropdownInput(\n                name=\"z_00_model_name\",\n                display_name=\"Model Name\",\n                info=\"The embedding model to use for the selected provider. Each provider has a different set of \"\n                \"models available (full list at \"\n                \"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\\n\\n\"\n                f\"{', '.join(model_options)}\",\n                options=model_options,\n                required=True,\n            ).to_dict()\n\n            new_parameter_1 = DictInput(\n                name=\"z_01_model_parameters\",\n                display_name=\"Model Parameters\",\n                is_list=True,\n            ).to_dict()\n\n            new_parameter_2 = MessageTextInput(\n                name=\"z_02_api_key_name\",\n                display_name=\"API Key name\",\n                info=\"The name of the embeddings provider API key stored on Astra. \"\n                \"If set, it will override the 'ProviderKey' in the authentication parameters.\",\n            ).to_dict()\n\n            new_parameter_3 = SecretStrInput(\n                name=\"z_03_provider_api_key\",\n                display_name=\"Provider API Key\",\n                info=\"An alternative to the Astra Authentication that passes an API key for the provider \"\n                \"with each request to Astra DB. \"\n                \"This may be used when Vectorize is configured for the collection, \"\n                \"but no corresponding provider secret is stored within Astra's key management system.\",\n            ).to_dict()\n\n            new_parameter_4 = DictInput(\n                name=\"z_04_authentication\",\n                display_name=\"Authentication parameters\",\n                is_list=True,\n            ).to_dict()\n\n            self.insert_in_dict(\n                build_config,\n                \"provider\",\n                {\n                    \"z_00_model_name\": new_parameter_0,\n                    \"z_01_model_parameters\": new_parameter_1,\n                    \"z_02_api_key_name\": new_parameter_2,\n                    \"z_03_provider_api_key\": new_parameter_3,\n                    \"z_04_authentication\": new_parameter_4,\n                },\n            )\n\n        return build_config\n\n    def build_vectorize_options(self, **kwargs):\n        for attribute in [\n            \"provider\",\n            \"z_00_model_name\",\n            \"z_01_model_parameters\",\n            \"z_02_api_key_name\",\n            \"z_03_provider_api_key\",\n            \"z_04_authentication\",\n        ]:\n            if not hasattr(self, attribute):\n                setattr(self, attribute, None)\n\n        # Fetch values from kwargs if any self.* attributes are None\n        provider_value = self.VECTORIZE_PROVIDERS_MAPPING.get(self.provider, [None])[0] or kwargs.get(\"provider\")\n        authentication = {**(self.z_04_authentication or kwargs.get(\"z_04_authentication\", {}))}\n\n        api_key_name = self.z_02_api_key_name or kwargs.get(\"z_02_api_key_name\")\n        provider_key = self.z_03_provider_api_key or kwargs.get(\"z_03_provider_api_key\")\n        if api_key_name:\n            authentication[\"providerKey\"] = api_key_name\n\n        return {\n            # must match astrapy.info.CollectionVectorServiceOptions\n            \"collection_vector_service_options\": {\n                \"provider\": provider_value,\n                \"modelName\": self.z_00_model_name or kwargs.get(\"z_00_model_name\"),\n                \"authentication\": authentication,\n                \"parameters\": self.z_01_model_parameters or kwargs.get(\"z_01_model_parameters\", {}),\n            },\n            \"collection_embedding_api_key\": provider_key,\n        }\n\n    @check_cached_vector_store\n    def build_vector_store(self, vectorize_options=None):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        if self.embedding:\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = vectorize_options or self.build_vectorize_options()\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(\n                    dict_options.get(\"collection_vector_service_options\", {})\n                ),\n            }\n\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"environment\": parse_api_endpoint(self.api_endpoint).environment,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self):\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_input, search_type=search_type, **search_args)\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        logger.debug(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"
              },
              "collection_indexing_policy": {
                "advanced": true,
                "display_name": "Collection Indexing Policy",
                "dynamic": false,
                "info": "Optional dictionary defining the indexing policy for the collection.",
                "list": false,
                "load_from_db": false,
                "name": "collection_indexing_policy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "collection_name": {
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "list": false,
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "testmetadata"
              },
              "embedding": {
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Allows an embedding model configuration.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "embedding_service": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Embedding Model or Astra Vectorize",
                "dynamic": false,
                "info": "Determines whether to use Astra Vectorize for the collection.",
                "name": "embedding_service",
                "options": [
                  "Embedding Model",
                  "Astra Vectorize"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Embedding Model"
              },
              "ingest_data": {
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "metadata_indexing_exclude": {
                "advanced": true,
                "display_name": "Metadata Indexing Exclude",
                "dynamic": false,
                "info": "Optional list of metadata fields to exclude from the indexing.",
                "list": false,
                "load_from_db": false,
                "name": "metadata_indexing_exclude",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_include": {
                "advanced": true,
                "display_name": "Metadata Indexing Include",
                "dynamic": false,
                "info": "Optional list of metadata fields to include in the indexing.",
                "list": false,
                "load_from_db": false,
                "name": "metadata_indexing_include",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metric": {
                "advanced": true,
                "display_name": "Metric",
                "dynamic": false,
                "info": "Optional distance metric for vector comparisons in the vector store.",
                "name": "metric",
                "options": [
                  "cosine",
                  "dot_product",
                  "euclidean"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "namespace": {
                "advanced": true,
                "display_name": "Namespace",
                "dynamic": false,
                "info": "Optional namespace within Astra DB to use for the collection.",
                "list": false,
                "load_from_db": false,
                "name": "namespace",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "number_of_results": {
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "pre_delete_collection": {
                "advanced": true,
                "display_name": "Pre Delete Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                "list": false,
                "name": "pre_delete_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "search_filter": {
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": true,
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "search_input": {
                "advanced": false,
                "display_name": "Search Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_score_threshold": {
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_type": {
                "advanced": true,
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Similarity"
              },
              "setup_mode": {
                "advanced": true,
                "display_name": "Setup Mode",
                "dynamic": false,
                "info": "Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.",
                "name": "setup_mode",
                "options": [
                  "Sync",
                  "Async",
                  "Off"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Sync"
              },
              "token": {
                "advanced": false,
                "display_name": "Astra DB Application Token",
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "token",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "lf_version": "1.0.18"
          },
          "type": "AstraVectorStoreComponent"
        },
        "selected": false,
        "width": 384,
        "height": 914,
        "dragging": false
      },
      {
        "id": "OpenAIEmbeddings-zyyHB",
        "type": "genericNode",
        "position": {
          "x": 2101.699536558219,
          "y": 654.1340638638003
        },
        "data": {
          "description": "Generate embeddings using OpenAI models.",
          "display_name": "OpenAI Embeddings",
          "id": "OpenAIEmbeddings-zyyHB",
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom axiestudio.base.embeddings.model import LCEmbeddingsModel\nfrom axiestudio.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-small",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_version": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_base",
              "openai_api_key",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "OpenAIEmbeddings"
        },
        "selected": true,
        "width": 384,
        "height": 388,
        "dragging": false
      },
      {
        "id": "TextDataLoader-HTBZ0",
        "type": "genericNode",
        "position": {
          "x": 1487.39950897771,
          "y": 220.82134008321896
        },
        "data": {
          "type": "TextDataLoader",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import requests\nimport base64\nimport os\nimport tempfile\nfrom axiestudio.custom import Component\nfrom axiestudio.schema import Data\nfrom axiestudio.io import MessageTextInput, Output, DictInput\nimport logging\n\nclass TextDataLoader(Component):\n    display_name = \"Text to Data Loader\"\n    description = \"Converts Text into a Data object with metadata.\"\n    icon = \"file-text\"\n    name = \"TextDataLoader\"\n\n    inputs = [\n        MessageTextInput(name=\"text\", display_name=\"Text\", required=True),\n        DictInput(\n            name=\"metadata\",\n            display_name=\"Metadata\",\n            info='Metadata to add to the Data object. When calling as a tweak, this should be as a list of dictionaries, i.e. [{\"key1\":123},{\"key2\":\"abc\"}]',\n            is_list=True,\n        ),\n    ]\n    \n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"process_text\"),\n    ]\n    \n    def process_text(self) -> Data:\n        # Ensure metadata is a dictionary and handle cases where it's empty\n        metadata = self.metadata or {}\n\n        # Filter out entries with empty keys\n        metadata = {k: v for k, v in metadata.items() if k} or {}\n        \n        return_data = Data(\n            text=self.text, \n            **metadata\n        )   \n\n        self.status = return_data\n        return return_data",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "metadata": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "metadata",
                "value": [
                  {
                    "user_id": 8555
                  },
                  {
                    "project_id": 6445
                  }
                ],
                "display_name": "Metadata",
                "advanced": false,
                "dynamic": false,
                "info": "Metadata to add to the Data object. When calling as a tweak, this should be as a list of dictionaries, i.e. [{\"key1\":123},{\"key2\":\"abc\"}]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "text",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Converts Text into a Data object with metadata.",
            "icon": "file-text",
            "base_classes": [
              "Data"
            ],
            "display_name": "Text to Data Loader",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "process_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text",
              "metadata"
            ],
            "beta": false,
            "edited": true,
            "metadata": {},
            "lf_version": "1.0.18"
          },
          "id": "TextDataLoader-HTBZ0"
        },
        "selected": false,
        "width": 384,
        "height": 466
      },
      {
        "id": "ParseData-3dmVt",
        "type": "genericNode",
        "position": {
          "x": 999.5877166878765,
          "y": 202.31126039913283
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "ParseData-3dmVt",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "selected": false,
        "width": 384,
        "height": 378
      }
    ],
    "edges": [
      {
        "source": "SplitText-lPyKW",
        "target": "AstraVectorStoreComponent-HBw7g",
        "sourceHandle": "{Å“dataTypeÅ“:Å“SplitTextÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“nameÅ“:Å“chunksÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "targetHandle": "{Å“fieldNameÅ“:Å“ingest_dataÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "id": "reactflow__edge-SplitText-lPyKW{Å“dataTypeÅ“:Å“SplitTextÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“nameÅ“:Å“chunksÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-AstraVectorStoreComponent-HBw7g{Å“fieldNameÅ“:Å“ingest_dataÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-lPyKW",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "AstraVectorStoreComponent-HBw7g",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false
      },
      {
        "source": "OpenAIEmbeddings-zyyHB",
        "target": "AstraVectorStoreComponent-HBw7g",
        "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIEmbeddingsÅ“,Å“idÅ“:Å“OpenAIEmbeddings-zyyHBÅ“,Å“nameÅ“:Å“embeddingsÅ“,Å“output_typesÅ“:[Å“EmbeddingsÅ“]}",
        "targetHandle": "{Å“fieldNameÅ“:Å“embeddingÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“EmbeddingsÅ“],Å“typeÅ“:Å“otherÅ“}",
        "id": "reactflow__edge-OpenAIEmbeddings-zyyHB{Å“dataTypeÅ“:Å“OpenAIEmbeddingsÅ“,Å“idÅ“:Å“OpenAIEmbeddings-zyyHBÅ“,Å“nameÅ“:Å“embeddingsÅ“,Å“output_typesÅ“:[Å“EmbeddingsÅ“]}-AstraVectorStoreComponent-HBw7g{Å“fieldNameÅ“:Å“embeddingÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“EmbeddingsÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-zyyHB",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "AstraVectorStoreComponent-HBw7g",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "selected": false
      },
      {
        "source": "File-m1Sk9",
        "target": "ParseData-3dmVt",
        "sourceHandle": "{Å“dataTypeÅ“:Å“FileÅ“,Å“idÅ“:Å“File-m1Sk9Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "targetHandle": "{Å“fieldNameÅ“:Å“dataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "id": "reactflow__edge-File-m1Sk9{Å“dataTypeÅ“:Å“FileÅ“,Å“idÅ“:Å“File-m1Sk9Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-ParseData-3dmVt{Å“fieldNameÅ“:Å“dataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-3dmVt",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "File",
            "id": "File-m1Sk9",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false
      },
      {
        "source": "ParseData-3dmVt",
        "target": "TextDataLoader-HTBZ0",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "targetHandle": "{Å“fieldNameÅ“:Å“textÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "id": "reactflow__edge-ParseData-3dmVt{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-TextDataLoader-HTBZ0{Å“fieldNameÅ“:Å“textÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "text",
            "id": "TextDataLoader-HTBZ0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3dmVt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false
      },
      {
        "source": "TextDataLoader-HTBZ0",
        "target": "SplitText-lPyKW",
        "sourceHandle": "{Å“dataTypeÅ“:Å“TextDataLoaderÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "targetHandle": "{Å“fieldNameÅ“:Å“data_inputsÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "id": "reactflow__edge-TextDataLoader-HTBZ0{Å“dataTypeÅ“:Å“TextDataLoaderÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-SplitText-lPyKW{Å“fieldNameÅ“:Å“data_inputsÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-lPyKW",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "TextDataLoader",
            "id": "TextDataLoader-HTBZ0",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false
      }
    ],
    "viewport": {
      "x": -58.7379135091918,
      "y": 267.6626969228291,
      "zoom": 0.49181878012062724
    }
  },
  "metadata": {
    "SplitText": {
      "count": 1
    },
    "File": {
      "count": 1
    },
    "AstraVectorStoreComponent": {
      "count": 1
    },
    "OpenAIEmbeddings": {
      "count": 1
    },
    "TextDataLoader": {
      "count": 1
    },
    "ParseData": {
      "count": 1
    },
    "total": 6
  },
  "original": {
    "id": "920be302-a436-4e73-b2dd-46c5af6c7c72",
    "name": "Astra RAG ingestion with metadata",
    "description": "This flow illustrates the RAG ingestion process and enables metadata configuration details necessary for ingestion.",
    "is_component": false,
    "liked_by_count": "2",
    "downloads_count": "23",
    "metadata": {
      "SplitText": {
        "count": 1
      },
      "File": {
        "count": 1
      },
      "AstraVectorStoreComponent": {
        "count": 1
      },
      "OpenAIEmbeddings": {
        "count": 1
      },
      "TextDataLoader": {
        "count": 1
      },
      "ParseData": {
        "count": 1
      },
      "total": 6
    },
    "last_tested_version": "1.0.18",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "SplitText-lPyKW",
          "type": "genericNode",
          "position": {
            "x": 2101.296326300341,
            "y": 54.21875
          },
          "data": {
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "id": "SplitText-lPyKW",
            "node": {
              "template": {
                "_type": "Component",
                "data_inputs": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_inputs",
                  "value": "",
                  "display_name": "Data Inputs",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to split.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "chunk_overlap": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_overlap",
                  "value": 200,
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Number of characters to overlap between chunks.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of characters in each chunk.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, IntInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        data = []\n        for doc in docs:\n            data.append(Data(text=doc.page_content, data=doc.metadata))\n        return data\n\n    def split_text(self) -> List[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = []\n        for _input in self.data_inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separator": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "separator",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The character to split on. Defaults to newline.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Split text into chunks based on specified criteria.",
              "icon": "scissors-line-dashed",
              "base_classes": [
                "Data"
              ],
              "display_name": "Split Text",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "chunks",
                  "display_name": "Chunks",
                  "method": "split_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data_inputs",
                "chunk_overlap",
                "chunk_size",
                "separator"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "SplitText"
          },
          "selected": false,
          "width": 384,
          "height": 550
        },
        {
          "id": "File-m1Sk9",
          "type": "genericNode",
          "position": {
            "x": 566.1567912366198,
            "y": 234.5783049628651
          },
          "data": {
            "description": "A generic file loader.",
            "display_name": "File",
            "id": "File-m1Sk9",
            "node": {
              "template": {
                "_type": "Component",
                "path": {
                  "trace_as_metadata": true,
                  "file_path": "d7b63ed2-91e6-47bf-bf0e-89a552f12feb/2024-11-04_14-36-37_Onboarding Questions - Google Docs.pdf",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx"
                  ],
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "path",
                  "value": "",
                  "display_name": "Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pathlib import Path\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, FileInput, Output\nfrom axiestudio.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data if data else \"No data\"\n        return data or Data()\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "silent_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "silent_errors",
                  "value": false,
                  "display_name": "Silent Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, errors will not raise an exception.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "A generic file loader.",
              "icon": "file-text",
              "base_classes": [
                "Data"
              ],
              "display_name": "File",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "load_file",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "path",
                "silent_errors"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "File"
          },
          "selected": false,
          "width": 384,
          "height": 302
        },
        {
          "id": "AstraVectorStoreComponent-HBw7g",
          "type": "genericNode",
          "position": {
            "x": 2735.5225490940675,
            "y": 136.24107902189598
          },
          "data": {
            "description": "ðŸ’¡ Select a Database and a Collection, or create new ones. Click  â–¶ï¸ **Play** to load your data.*If you're using OS Langflow, Paste your Astra DB Application Token here.*",
            "display_name": "Astra DB",
            "edited": false,
            "id": "AstraVectorStoreComponent-HBw7g",
            "node": {
              "base_classes": [
                "Data",
                "Retriever"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "ðŸ’¡ Select a Database and a Collection, or create new ones. Click â–¶ï¸ **Play** to load your data.*If you're using OS Langflow, Paste your Astra DB Application Token here.*",
              "display_name": "Astra DB",
              "documentation": "https://docs.axiestudio.org/starter-projects-vector-store-rag",
              "edited": false,
              "field_order": [
                "collection_name",
                "token",
                "api_endpoint",
                "search_input",
                "ingest_data",
                "namespace",
                "metric",
                "batch_size",
                "bulk_insert_batch_concurrency",
                "bulk_insert_overwrite_concurrency",
                "bulk_delete_concurrency",
                "setup_mode",
                "pre_delete_collection",
                "metadata_indexing_include",
                "embedding",
                "metadata_indexing_exclude",
                "collection_indexing_policy",
                "number_of_results",
                "search_type",
                "search_score_threshold",
                "search_filter"
              ],
              "frozen": false,
              "icon": "AstraDB",
              "metadata": {},
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "name": "base_retriever",
                  "required_inputs": [],
                  "selected": "Retriever",
                  "types": [
                    "Retriever"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "name": "search_results",
                  "required_inputs": [
                    "api_endpoint",
                    "batch_size",
                    "bulk_delete_concurrency",
                    "bulk_insert_batch_concurrency",
                    "bulk_insert_overwrite_concurrency",
                    "collection_indexing_policy",
                    "collection_name",
                    "embedding",
                    "ingest_data",
                    "metadata_indexing_exclude",
                    "metadata_indexing_include",
                    "metric",
                    "namespace",
                    "number_of_results",
                    "pre_delete_collection",
                    "search_filter",
                    "search_input",
                    "search_score_threshold",
                    "search_type",
                    "setup_mode",
                    "token"
                  ],
                  "selected": "Data",
                  "types": [
                    "Data"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "name": "vector_store",
                  "required_inputs": [],
                  "selected": "VectorStore",
                  "types": [
                    "VectorStore"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_endpoint": {
                  "advanced": false,
                  "display_name": "API Endpoint",
                  "dynamic": false,
                  "info": "API endpoint URL for the Astra DB service.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_endpoint",
                  "password": true,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "batch_size": {
                  "advanced": true,
                  "display_name": "Batch Size",
                  "dynamic": false,
                  "info": "Optional number of data to process in a single batch.",
                  "list": false,
                  "name": "batch_size",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "bulk_delete_concurrency": {
                  "advanced": true,
                  "display_name": "Bulk Delete Concurrency",
                  "dynamic": false,
                  "info": "Optional concurrency level for bulk delete operations.",
                  "list": false,
                  "name": "bulk_delete_concurrency",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "bulk_insert_batch_concurrency": {
                  "advanced": true,
                  "display_name": "Bulk Insert Batch Concurrency",
                  "dynamic": false,
                  "info": "Optional concurrency level for bulk insert operations.",
                  "list": false,
                  "name": "bulk_insert_batch_concurrency",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "bulk_insert_overwrite_concurrency": {
                  "advanced": true,
                  "display_name": "Bulk Insert Overwrite Concurrency",
                  "dynamic": false,
                  "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                  "list": false,
                  "name": "bulk_insert_overwrite_concurrency",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import os\n\nfrom astrapy.admin import parse_api_endpoint\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.helpers import docs_to_data\nfrom axiestudio.inputs import DictInput, FloatInput, MessageTextInput\nfrom axiestudio.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom axiestudio.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://docs.axiestudio.org/starter-projects-vector-store-rag\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    VECTORIZE_PROVIDERS_MAPPING = {\n        \"Azure OpenAI\": [\"azureOpenAI\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Hugging Face - Dedicated\": [\"huggingfaceDedicated\", [\"endpoint-defined-model\"]],\n        \"Hugging Face - Serverless\": [\n            \"huggingface\",\n            [\n                \"sentence-transformers/all-MiniLM-L6-v2\",\n                \"intfloat/multilingual-e5-large\",\n                \"intfloat/multilingual-e5-large-instruct\",\n                \"BAAI/bge-small-en-v1.5\",\n                \"BAAI/bge-base-en-v1.5\",\n                \"BAAI/bge-large-en-v1.5\",\n            ],\n        ],\n        \"Jina AI\": [\n            \"jinaAI\",\n            [\n                \"jina-embeddings-v2-base-en\",\n                \"jina-embeddings-v2-base-de\",\n                \"jina-embeddings-v2-base-es\",\n                \"jina-embeddings-v2-base-code\",\n                \"jina-embeddings-v2-base-zh\",\n            ],\n        ],\n        \"Mistral AI\": [\"mistral\", [\"mistral-embed\"]],\n        \"NVIDIA\": [\"nvidia\", [\"NV-Embed-QA\"]],\n        \"OpenAI\": [\"openai\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Upstage\": [\"upstageAI\", [\"solar-embedding-1-large\"]],\n        \"Voyage AI\": [\n            \"voyageAI\",\n            [\"voyage-large-2-instruct\", \"voyage-law-2\", \"voyage-code-2\", \"voyage-large-2\", \"voyage-2\"],\n        ],\n    }\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"embedding_service\",\n            display_name=\"Embedding Model or Astra Vectorize\",\n            info=\"Determines whether to use Astra Vectorize for the collection.\",\n            options=[\"Embedding Model\", \"Astra Vectorize\"],\n            real_time_refresh=True,\n            value=\"Embedding Model\",\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    def insert_in_dict(self, build_config, field_name, new_parameters):\n        # Insert the new key-value pair after the found key\n        for new_field_name, new_parameter in new_parameters.items():\n            # Get all the items as a list of tuples (key, value)\n            items = list(build_config.items())\n\n            # Find the index of the key to insert after\n            idx = len(items)\n            for i, (key, _value) in enumerate(items):\n                if key == field_name:\n                    idx = i + 1\n                    break\n\n            items.insert(idx, (new_field_name, new_parameter))\n\n            # Clear the original dictionary and update with the modified items\n            build_config.clear()\n            build_config.update(items)\n\n        return build_config\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name == \"embedding_service\":\n            if field_value == \"Astra Vectorize\":\n                for field in [\"embedding\"]:\n                    if field in build_config:\n                        del build_config[field]\n\n                new_parameter = DropdownInput(\n                    name=\"provider\",\n                    display_name=\"Vectorize Provider\",\n                    options=self.VECTORIZE_PROVIDERS_MAPPING.keys(),\n                    value=\"\",\n                    required=True,\n                    real_time_refresh=True,\n                ).to_dict()\n\n                self.insert_in_dict(build_config, \"embedding_service\", {\"provider\": new_parameter})\n            else:\n                for field in [\n                    \"provider\",\n                    \"z_00_model_name\",\n                    \"z_01_model_parameters\",\n                    \"z_02_api_key_name\",\n                    \"z_03_provider_api_key\",\n                    \"z_04_authentication\",\n                ]:\n                    if field in build_config:\n                        del build_config[field]\n\n                new_parameter = HandleInput(\n                    name=\"embedding\",\n                    display_name=\"Embedding Model\",\n                    input_types=[\"Embeddings\"],\n                    info=\"Allows an embedding model configuration.\",\n                ).to_dict()\n\n                self.insert_in_dict(build_config, \"embedding_service\", {\"embedding\": new_parameter})\n\n        elif field_name == \"provider\":\n            for field in [\n                \"z_00_model_name\",\n                \"z_01_model_parameters\",\n                \"z_02_api_key_name\",\n                \"z_03_provider_api_key\",\n                \"z_04_authentication\",\n            ]:\n                if field in build_config:\n                    del build_config[field]\n\n            model_options = self.VECTORIZE_PROVIDERS_MAPPING[field_value][1]\n\n            new_parameter_0 = DropdownInput(\n                name=\"z_00_model_name\",\n                display_name=\"Model Name\",\n                info=\"The embedding model to use for the selected provider. Each provider has a different set of \"\n                \"models available (full list at \"\n                \"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\\n\\n\"\n                f\"{', '.join(model_options)}\",\n                options=model_options,\n                required=True,\n            ).to_dict()\n\n            new_parameter_1 = DictInput(\n                name=\"z_01_model_parameters\",\n                display_name=\"Model Parameters\",\n                is_list=True,\n            ).to_dict()\n\n            new_parameter_2 = MessageTextInput(\n                name=\"z_02_api_key_name\",\n                display_name=\"API Key name\",\n                info=\"The name of the embeddings provider API key stored on Astra. \"\n                \"If set, it will override the 'ProviderKey' in the authentication parameters.\",\n            ).to_dict()\n\n            new_parameter_3 = SecretStrInput(\n                name=\"z_03_provider_api_key\",\n                display_name=\"Provider API Key\",\n                info=\"An alternative to the Astra Authentication that passes an API key for the provider \"\n                \"with each request to Astra DB. \"\n                \"This may be used when Vectorize is configured for the collection, \"\n                \"but no corresponding provider secret is stored within Astra's key management system.\",\n            ).to_dict()\n\n            new_parameter_4 = DictInput(\n                name=\"z_04_authentication\",\n                display_name=\"Authentication parameters\",\n                is_list=True,\n            ).to_dict()\n\n            self.insert_in_dict(\n                build_config,\n                \"provider\",\n                {\n                    \"z_00_model_name\": new_parameter_0,\n                    \"z_01_model_parameters\": new_parameter_1,\n                    \"z_02_api_key_name\": new_parameter_2,\n                    \"z_03_provider_api_key\": new_parameter_3,\n                    \"z_04_authentication\": new_parameter_4,\n                },\n            )\n\n        return build_config\n\n    def build_vectorize_options(self, **kwargs):\n        for attribute in [\n            \"provider\",\n            \"z_00_model_name\",\n            \"z_01_model_parameters\",\n            \"z_02_api_key_name\",\n            \"z_03_provider_api_key\",\n            \"z_04_authentication\",\n        ]:\n            if not hasattr(self, attribute):\n                setattr(self, attribute, None)\n\n        # Fetch values from kwargs if any self.* attributes are None\n        provider_value = self.VECTORIZE_PROVIDERS_MAPPING.get(self.provider, [None])[0] or kwargs.get(\"provider\")\n        authentication = {**(self.z_04_authentication or kwargs.get(\"z_04_authentication\", {}))}\n\n        api_key_name = self.z_02_api_key_name or kwargs.get(\"z_02_api_key_name\")\n        provider_key = self.z_03_provider_api_key or kwargs.get(\"z_03_provider_api_key\")\n        if api_key_name:\n            authentication[\"providerKey\"] = api_key_name\n\n        return {\n            # must match astrapy.info.CollectionVectorServiceOptions\n            \"collection_vector_service_options\": {\n                \"provider\": provider_value,\n                \"modelName\": self.z_00_model_name or kwargs.get(\"z_00_model_name\"),\n                \"authentication\": authentication,\n                \"parameters\": self.z_01_model_parameters or kwargs.get(\"z_01_model_parameters\", {}),\n            },\n            \"collection_embedding_api_key\": provider_key,\n        }\n\n    @check_cached_vector_store\n    def build_vector_store(self, vectorize_options=None):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        if self.embedding:\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = vectorize_options or self.build_vectorize_options()\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(\n                    dict_options.get(\"collection_vector_service_options\", {})\n                ),\n            }\n\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"environment\": parse_api_endpoint(self.api_endpoint).environment,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self):\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_input, search_type=search_type, **search_args)\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        logger.debug(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"
                },
                "collection_indexing_policy": {
                  "advanced": true,
                  "display_name": "Collection Indexing Policy",
                  "dynamic": false,
                  "info": "Optional dictionary defining the indexing policy for the collection.",
                  "list": false,
                  "load_from_db": false,
                  "name": "collection_indexing_policy",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "collection_name": {
                  "advanced": false,
                  "display_name": "Collection Name",
                  "dynamic": false,
                  "info": "The name of the collection within Astra DB where the vectors will be stored.",
                  "list": false,
                  "load_from_db": false,
                  "name": "collection_name",
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "testmetadata"
                },
                "embedding": {
                  "advanced": false,
                  "display_name": "Embedding Model",
                  "dynamic": false,
                  "info": "Allows an embedding model configuration.",
                  "input_types": [
                    "Embeddings"
                  ],
                  "list": false,
                  "name": "embedding",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "embedding_service": {
                  "_input_type": "DropdownInput",
                  "advanced": false,
                  "combobox": false,
                  "display_name": "Embedding Model or Astra Vectorize",
                  "dynamic": false,
                  "info": "Determines whether to use Astra Vectorize for the collection.",
                  "name": "embedding_service",
                  "options": [
                    "Embedding Model",
                    "Astra Vectorize"
                  ],
                  "placeholder": "",
                  "real_time_refresh": true,
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Embedding Model"
                },
                "ingest_data": {
                  "advanced": false,
                  "display_name": "Ingest Data",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Data"
                  ],
                  "list": true,
                  "name": "ingest_data",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "metadata_indexing_exclude": {
                  "advanced": true,
                  "display_name": "Metadata Indexing Exclude",
                  "dynamic": false,
                  "info": "Optional list of metadata fields to exclude from the indexing.",
                  "list": false,
                  "load_from_db": false,
                  "name": "metadata_indexing_exclude",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "metadata_indexing_include": {
                  "advanced": true,
                  "display_name": "Metadata Indexing Include",
                  "dynamic": false,
                  "info": "Optional list of metadata fields to include in the indexing.",
                  "list": false,
                  "load_from_db": false,
                  "name": "metadata_indexing_include",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "metric": {
                  "advanced": true,
                  "display_name": "Metric",
                  "dynamic": false,
                  "info": "Optional distance metric for vector comparisons in the vector store.",
                  "name": "metric",
                  "options": [
                    "cosine",
                    "dot_product",
                    "euclidean"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "namespace": {
                  "advanced": true,
                  "display_name": "Namespace",
                  "dynamic": false,
                  "info": "Optional namespace within Astra DB to use for the collection.",
                  "list": false,
                  "load_from_db": false,
                  "name": "namespace",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "number_of_results": {
                  "advanced": true,
                  "display_name": "Number of Results",
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "list": false,
                  "name": "number_of_results",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 4
                },
                "pre_delete_collection": {
                  "advanced": true,
                  "display_name": "Pre Delete Collection",
                  "dynamic": false,
                  "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                  "list": false,
                  "name": "pre_delete_collection",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "search_filter": {
                  "advanced": true,
                  "display_name": "Search Metadata Filter",
                  "dynamic": false,
                  "info": "Optional dictionary of filters to apply to the search query.",
                  "list": true,
                  "name": "search_filter",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "search_input": {
                  "advanced": false,
                  "display_name": "Search Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "search_input",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "search_score_threshold": {
                  "advanced": true,
                  "display_name": "Search Score Threshold",
                  "dynamic": false,
                  "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                  "list": false,
                  "name": "search_score_threshold",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0
                },
                "search_type": {
                  "advanced": true,
                  "display_name": "Search Type",
                  "dynamic": false,
                  "info": "Search type to use",
                  "name": "search_type",
                  "options": [
                    "Similarity",
                    "Similarity with score threshold",
                    "MMR (Max Marginal Relevance)"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Similarity"
                },
                "setup_mode": {
                  "advanced": true,
                  "display_name": "Setup Mode",
                  "dynamic": false,
                  "info": "Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.",
                  "name": "setup_mode",
                  "options": [
                    "Sync",
                    "Async",
                    "Off"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Sync"
                },
                "token": {
                  "advanced": false,
                  "display_name": "Astra DB Application Token",
                  "dynamic": false,
                  "info": "Authentication token for accessing Astra DB.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "token",
                  "password": true,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                }
              },
              "lf_version": "1.0.18"
            },
            "type": "AstraVectorStoreComponent"
          },
          "selected": false,
          "width": 384,
          "height": 914,
          "dragging": false
        },
        {
          "id": "OpenAIEmbeddings-zyyHB",
          "type": "genericNode",
          "position": {
            "x": 2101.699536558219,
            "y": 654.1340638638003
          },
          "data": {
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "id": "OpenAIEmbeddings-zyyHB",
            "node": {
              "template": {
                "_type": "Component",
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "client": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "client",
                  "value": "",
                  "display_name": "Client",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom axiestudio.base.embeddings.model import LCEmbeddingsModel\nfrom axiestudio.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "default_headers": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "default_headers",
                  "value": {},
                  "display_name": "Default Headers",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Default headers to use for the API request.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "default_query": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "default_query",
                  "value": {},
                  "display_name": "Default Query",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Default query parameters to use for the API request.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "deployment",
                  "value": "",
                  "display_name": "Deployment",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "dimensions": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "dimensions",
                  "value": "",
                  "display_name": "Dimensions",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "embedding_ctx_length": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding_ctx_length",
                  "value": 1536,
                  "display_name": "Embedding Context Length",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "max_retries": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_retries",
                  "value": 3,
                  "display_name": "Max Retries",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "text-embedding-3-small",
                  "display_name": "Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "openai_api_base": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_type": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_type",
                  "value": "",
                  "display_name": "OpenAI API Type",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_version": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_version",
                  "value": "",
                  "display_name": "OpenAI API Version",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_organization": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_organization",
                  "value": "",
                  "display_name": "OpenAI Organization",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_proxy": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_proxy",
                  "value": "",
                  "display_name": "OpenAI Proxy",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "request_timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "request_timeout",
                  "value": "",
                  "display_name": "Request Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "show_progress_bar": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "show_progress_bar",
                  "value": false,
                  "display_name": "Show Progress Bar",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "skip_empty": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "skip_empty",
                  "value": false,
                  "display_name": "Skip Empty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tiktoken_enable": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tiktoken_enable",
                  "value": true,
                  "display_name": "TikToken Enable",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If False, you must have transformers installed.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tiktoken_model_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tiktoken_model_name",
                  "value": "",
                  "display_name": "TikToken Model Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generate embeddings using OpenAI models.",
              "icon": "OpenAI",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "OpenAI Embeddings",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "default_headers",
                "default_query",
                "chunk_size",
                "client",
                "deployment",
                "embedding_ctx_length",
                "max_retries",
                "model",
                "model_kwargs",
                "openai_api_base",
                "openai_api_key",
                "openai_api_type",
                "openai_api_version",
                "openai_organization",
                "openai_proxy",
                "request_timeout",
                "show_progress_bar",
                "skip_empty",
                "tiktoken_model_name",
                "tiktoken_enable",
                "dimensions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "OpenAIEmbeddings"
          },
          "selected": true,
          "width": 384,
          "height": 388,
          "dragging": false
        },
        {
          "id": "TextDataLoader-HTBZ0",
          "type": "genericNode",
          "position": {
            "x": 1487.39950897771,
            "y": 220.82134008321896
          },
          "data": {
            "type": "TextDataLoader",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import requests\nimport base64\nimport os\nimport tempfile\nfrom axiestudio.custom import Component\nfrom axiestudio.schema import Data\nfrom axiestudio.io import MessageTextInput, Output, DictInput\nimport logging\n\nclass TextDataLoader(Component):\n    display_name = \"Text to Data Loader\"\n    description = \"Converts Text into a Data object with metadata.\"\n    icon = \"file-text\"\n    name = \"TextDataLoader\"\n\n    inputs = [\n        MessageTextInput(name=\"text\", display_name=\"Text\", required=True),\n        DictInput(\n            name=\"metadata\",\n            display_name=\"Metadata\",\n            info='Metadata to add to the Data object. When calling as a tweak, this should be as a list of dictionaries, i.e. [{\"key1\":123},{\"key2\":\"abc\"}]',\n            is_list=True,\n        ),\n    ]\n    \n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"process_text\"),\n    ]\n    \n    def process_text(self) -> Data:\n        # Ensure metadata is a dictionary and handle cases where it's empty\n        metadata = self.metadata or {}\n\n        # Filter out entries with empty keys\n        metadata = {k: v for k, v in metadata.items() if k} or {}\n        \n        return_data = Data(\n            text=self.text, \n            **metadata\n        )   \n\n        self.status = return_data\n        return return_data",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "metadata": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "metadata",
                  "value": [
                    {
                      "user_id": 8555
                    },
                    {
                      "project_id": 6445
                    }
                  ],
                  "display_name": "Metadata",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Metadata to add to the Data object. When calling as a tweak, this should be as a list of dictionaries, i.e. [{\"key1\":123},{\"key2\":\"abc\"}]",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "text",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Converts Text into a Data object with metadata.",
              "icon": "file-text",
              "base_classes": [
                "Data"
              ],
              "display_name": "Text to Data Loader",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "process_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text",
                "metadata"
              ],
              "beta": false,
              "edited": true,
              "metadata": {},
              "lf_version": "1.0.18"
            },
            "id": "TextDataLoader-HTBZ0"
          },
          "selected": false,
          "width": 384,
          "height": 466
        },
        {
          "id": "ParseData-3dmVt",
          "type": "genericNode",
          "position": {
            "x": 999.5877166878765,
            "y": 202.31126039913283
          },
          "data": {
            "type": "ParseData",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sep": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sep",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{text}",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Convert Data into plain text following a specified template.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Parse Data",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "ParseData-3dmVt",
            "description": "Convert Data into plain text following a specified template.",
            "display_name": "Parse Data"
          },
          "selected": false,
          "width": 384,
          "height": 378
        }
      ],
      "edges": [
        {
          "source": "SplitText-lPyKW",
          "target": "AstraVectorStoreComponent-HBw7g",
          "sourceHandle": "{Å“dataTypeÅ“:Å“SplitTextÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“nameÅ“:Å“chunksÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
          "targetHandle": "{Å“fieldNameÅ“:Å“ingest_dataÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
          "id": "reactflow__edge-SplitText-lPyKW{Å“dataTypeÅ“:Å“SplitTextÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“nameÅ“:Å“chunksÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-AstraVectorStoreComponent-HBw7g{Å“fieldNameÅ“:Å“ingest_dataÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "sourceHandle": {
              "dataType": "SplitText",
              "id": "SplitText-lPyKW",
              "name": "chunks",
              "output_types": [
                "Data"
              ]
            },
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "AstraVectorStoreComponent-HBw7g",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            }
          },
          "selected": false
        },
        {
          "source": "OpenAIEmbeddings-zyyHB",
          "target": "AstraVectorStoreComponent-HBw7g",
          "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIEmbeddingsÅ“,Å“idÅ“:Å“OpenAIEmbeddings-zyyHBÅ“,Å“nameÅ“:Å“embeddingsÅ“,Å“output_typesÅ“:[Å“EmbeddingsÅ“]}",
          "targetHandle": "{Å“fieldNameÅ“:Å“embeddingÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“EmbeddingsÅ“],Å“typeÅ“:Å“otherÅ“}",
          "id": "reactflow__edge-OpenAIEmbeddings-zyyHB{Å“dataTypeÅ“:Å“OpenAIEmbeddingsÅ“,Å“idÅ“:Å“OpenAIEmbeddings-zyyHBÅ“,Å“nameÅ“:Å“embeddingsÅ“,Å“output_typesÅ“:[Å“EmbeddingsÅ“]}-AstraVectorStoreComponent-HBw7g{Å“fieldNameÅ“:Å“embeddingÅ“,Å“idÅ“:Å“AstraVectorStoreComponent-HBw7gÅ“,Å“inputTypesÅ“:[Å“EmbeddingsÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIEmbeddings",
              "id": "OpenAIEmbeddings-zyyHB",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            },
            "targetHandle": {
              "fieldName": "embedding",
              "id": "AstraVectorStoreComponent-HBw7g",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            }
          },
          "selected": false
        },
        {
          "source": "File-m1Sk9",
          "target": "ParseData-3dmVt",
          "sourceHandle": "{Å“dataTypeÅ“:Å“FileÅ“,Å“idÅ“:Å“File-m1Sk9Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
          "targetHandle": "{Å“fieldNameÅ“:Å“dataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
          "id": "reactflow__edge-File-m1Sk9{Å“dataTypeÅ“:Å“FileÅ“,Å“idÅ“:Å“File-m1Sk9Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-ParseData-3dmVt{Å“fieldNameÅ“:Å“dataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ParseData-3dmVt",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "File",
              "id": "File-m1Sk9",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "selected": false
        },
        {
          "source": "ParseData-3dmVt",
          "target": "TextDataLoader-HTBZ0",
          "sourceHandle": "{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "targetHandle": "{Å“fieldNameÅ“:Å“textÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "id": "reactflow__edge-ParseData-3dmVt{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-3dmVtÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-TextDataLoader-HTBZ0{Å“fieldNameÅ“:Å“textÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "text",
              "id": "TextDataLoader-HTBZ0",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ParseData",
              "id": "ParseData-3dmVt",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "selected": false
        },
        {
          "source": "TextDataLoader-HTBZ0",
          "target": "SplitText-lPyKW",
          "sourceHandle": "{Å“dataTypeÅ“:Å“TextDataLoaderÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
          "targetHandle": "{Å“fieldNameÅ“:Å“data_inputsÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
          "id": "reactflow__edge-TextDataLoader-HTBZ0{Å“dataTypeÅ“:Å“TextDataLoaderÅ“,Å“idÅ“:Å“TextDataLoader-HTBZ0Å“,Å“nameÅ“:Å“dataÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-SplitText-lPyKW{Å“fieldNameÅ“:Å“data_inputsÅ“,Å“idÅ“:Å“SplitText-lPyKWÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "data_inputs",
              "id": "SplitText-lPyKW",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "TextDataLoader",
              "id": "TextDataLoader-HTBZ0",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "selected": false
        }
      ],
      "viewport": {
        "x": -58.7379135091918,
        "y": 267.6626969228291,
        "zoom": 0.49181878012062724
      }
    },
    "date_created": "2024-11-04T13:37:46.476Z",
    "date_updated": "2024-11-04T13:37:46.576Z",
    "status": "Public",
    "sort": null,
    "user_updated": "76f05705-dfce-454b-8d27-4f5f02d94090",
    "user_created": {
      "username": "boreilly",
      "first_name": "Betul",
      "last_name": "O'Reilly",
      "id": "76f05705-dfce-454b-8d27-4f5f02d94090"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:01.943Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 52,
    "converter_version": "1.0.0"
  }
}