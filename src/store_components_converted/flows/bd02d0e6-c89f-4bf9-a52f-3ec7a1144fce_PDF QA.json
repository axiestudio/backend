{
  "id": "bd02d0e6-c89f-4bf9-a52f-3ec7a1144fce",
  "name": "PDF QA",
  "description": "Unleashing Business Potential through Language Engineering. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "keith-matthews",
    "first_name": "keith",
    "last_name": "matthews",
    "id": "b0c9c84d-b48a-4dee-bf0a-f872f4a11a2d",
    "full_name": "keith matthews"
  },
  "store_url": "https://www.langflow.store/store/component/bd02d0e6-c89f-4bf9-a52f-3ec7a1144fce",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-13T13:53:07.068Z",
    "updated": "2024-09-13T13:53:07.315Z",
    "downloaded": "2025-08-19T17:50:06.285Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.18",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "Chroma-RqiRC",
        "type": "genericNode",
        "position": {
          "x": 1318.943401164838,
          "y": -50.62955471741179
        },
        "data": {
          "type": "Chroma",
          "node": {
            "template": {
              "documents": {
                "type": "Document",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "documents",
                "display_name": "Documents",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "embedding": {
                "type": "Embeddings",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "chroma_server_cors_allow_origins": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chroma_server_cors_allow_origins",
                "display_name": "Server CORS Allow Origins",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "chroma_server_grpc_port": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chroma_server_grpc_port",
                "display_name": "Server gRPC Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "chroma_server_host": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chroma_server_host",
                "display_name": "Server Host",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": ""
              },
              "chroma_server_port": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chroma_server_port",
                "display_name": "Server Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": ""
              },
              "chroma_server_ssl_enabled": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chroma_server_ssl_enabled",
                "display_name": "Server SSL Enabled",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Optional, Union\n\nimport chromadb  # type: ignore\nfrom langchain.embeddings.base import Embeddings\nfrom langchain.schema import BaseRetriever, Document\nfrom langchain_community.vectorstores import VectorStore\nfrom langchain_community.vectorstores.chroma import Chroma\nfrom axiestudio import CustomComponent\n\n\nclass ChromaComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Chroma.\n    \"\"\"\n\n    display_name: str = \"Chroma\"\n    description: str = \"Implementation of Vector Store using Chroma\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    beta: bool = True\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"collection_name\": {\"display_name\": \"Collection Name\", \"value\": \"axiestudio\"},\n            \"persist\": {\"display_name\": \"Persist\"},\n            \"persist_directory\": {\"display_name\": \"Persist Directory\"},\n            \"code\": {\"advanced\": True, \"display_name\": \"Code\"},\n            \"documents\": {\"display_name\": \"Documents\", \"is_list\": True},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_port\": {\"display_name\": \"Server Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        collection_name: str,\n        persist: bool,\n        embedding: Embeddings,\n        chroma_server_ssl_enabled: bool,\n        persist_directory: Optional[str] = None,\n        documents: Optional[List[Document]] = None,\n        chroma_server_cors_allow_origins: Optional[str] = None,\n        chroma_server_host: Optional[str] = None,\n        chroma_server_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - collection_name (str): The name of the collection.\n        - persist_directory (Optional[str]): The directory to persist the Vector Store to.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - persist (bool): Whether to persist the Vector Store or not.\n        - embedding (Optional[Embeddings]): The embeddings to use for the Vector Store.\n        - documents (Optional[Document]): The documents to use for the Vector Store.\n        - chroma_server_cors_allow_origins (Optional[str]): The CORS allow origins for the Chroma server.\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\n        - chroma_server_port (Optional[int]): The port for the Chroma server.\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\n\n        Returns:\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n\n        if chroma_server_host is not None:\n            chroma_settings = chromadb.config.Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or None,\n                chroma_server_host=chroma_server_host,\n                chroma_server_port=chroma_server_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n\n        # If documents, then we need to create a Chroma instance using .from_documents\n        if documents is not None and embedding is not None:\n            if len(documents) == 0:\n                raise ValueError(\"If documents are provided, there must be at least one document.\")\n            return Chroma.from_documents(\n                documents=documents,  # type: ignore\n                persist_directory=persist_directory if persist else None,\n                collection_name=collection_name,\n                embedding=embedding,\n                client_settings=chroma_settings,\n            )\n\n        return Chroma(persist_directory=persist_directory, client_settings=chroma_settings)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "collection_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "axiestudio",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "collection_name",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "persist": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "persist",
                "display_name": "Persist",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "persist_directory": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "persist_directory",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Implementation of Vector Store using Chroma",
            "base_classes": [
              "VectorStore",
              "BaseRetriever"
            ],
            "display_name": "Chroma",
            "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
            "custom_fields": {
              "collection_name": null,
              "persist": null,
              "embedding": null,
              "chroma_server_ssl_enabled": null,
              "persist_directory": null,
              "documents": null,
              "chroma_server_cors_allow_origins": null,
              "chroma_server_host": null,
              "chroma_server_port": null,
              "chroma_server_grpc_port": null
            },
            "output_types": [
              "VectorStore",
              "BaseRetriever"
            ],
            "field_formatters": {},
            "beta": true,
            "outputs": [
              {
                "types": [
                  "VectorStore",
                  "BaseRetriever"
                ],
                "selected": "BaseRetriever",
                "name": "VectorStore | BaseRetriever",
                "display_name": "VectorStore | BaseRetriever"
              }
            ]
          },
          "id": "Chroma-RqiRC"
        },
        "selected": false,
        "width": 384,
        "height": 557,
        "positionAbsolute": {
          "x": 1318.943401164838,
          "y": -50.62955471741179
        },
        "dragging": false
      },
      {
        "id": "Google Generative AI Embeddings-BECyO",
        "type": "genericNode",
        "position": {
          "x": 254.63694376057265,
          "y": 819.5186150772323
        },
        "data": {
          "type": "Google Generative AI Embeddings",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output, SecretStrInput\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nfrom typing import List, Optional\n\n# TODO: remove ignore once the google package is published with types\nfrom google.ai.generativelanguage_v1beta.types import (\n    BatchEmbedContentsRequest,\n)\nfrom langchain_core.embeddings import Embeddings\n\nfrom langchain_google_genai._common import (\n    GoogleGenerativeAIError,\n)\n\nimport numpy as np\n\n\nclass GoogleGenerativeAIEmbeddingsComponent(Component):\n    display_name = \"Google Generative AI Embeddings\"\n    description = \"Connect to Google's generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, found in the langchain-google-genai package.\"\n    documentation: str = \"https://python.langchain.com/v0.2/docs/integrations/text_embedding/google_generative_ai/\"\n    icon = \"Google\"\n    name = \"Google Generative AI Embeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"models/text-embedding-004\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.api_key:\n            raise ValueError(\"API Key is required\")\n\n        class HotaGoogleGenerativeAIEmbeddings(GoogleGenerativeAIEmbeddings):\n            def __init__(self, *args, **kwargs):\n                super(GoogleGenerativeAIEmbeddings, self).__init__(*args, **kwargs)\n\n            def embed_documents(\n                self,\n                texts: List[str],\n                *,\n                batch_size: int = 100,\n                task_type: Optional[str] = None,\n                titles: Optional[List[str]] = None,\n                output_dimensionality: Optional[int] = 1536,\n            ) -> List[List[float]]:\n                \"\"\"Embed a list of strings. Google Generative AI currently\n                sets a max batch size of 100 strings.\n\n                Args:\n                    texts: List[str] The list of strings to embed.\n                    batch_size: [int] The batch size of embeddings to send to the model\n                    task_type: task_type (https://ai.google.dev/api/rest/v1/TaskType)\n                    titles: An optional list of titles for texts provided.\n                    Only applicable when TaskType is RETRIEVAL_DOCUMENT.\n                    output_dimensionality: Optional reduced dimension for the output embedding.\n                    https://ai.google.dev/api/rest/v1/models/batchEmbedContents#EmbedContentRequest\n                Returns:\n                    List of embeddings, one for each text.\n                \"\"\"\n                embeddings: List[List[float]] = []\n                batch_start_index = 0\n                for batch in GoogleGenerativeAIEmbeddings._prepare_batches(texts, batch_size):\n                    if titles:\n                        titles_batch = titles[batch_start_index : batch_start_index + len(batch)]\n                        batch_start_index += len(batch)\n                    else:\n                        titles_batch = [None] * len(batch)  # type: ignore[list-item]\n\n                    requests = [\n                        self._prepare_request(\n                            text=text,\n                            task_type=task_type,\n                            title=title,\n                            output_dimensionality=1536,\n                        )\n                        for text, title in zip(batch, titles_batch)\n                    ]\n\n                    try:\n                        result = self.client.batch_embed_contents(\n                            BatchEmbedContentsRequest(requests=requests, model=self.model)\n                        )\n                    except Exception as e:\n                        raise GoogleGenerativeAIError(f\"Error embedding content: {e}\") from e\n                    embeddings.extend([list(np.pad(e.values, (0, 768), \"constant\")) for e in result.embeddings])\n                return embeddings\n\n            def embed_query(\n                self,\n                text: str,\n                task_type: Optional[str] = None,\n                title: Optional[str] = None,\n                output_dimensionality: Optional[int] = 1536,\n            ) -> List[float]:\n                \"\"\"Embed a text.\n\n                Args:\n                    text: The text to embed.\n                    task_type: task_type (https://ai.google.dev/api/rest/v1/TaskType)\n                    title: An optional title for the text.\n                    Only applicable when TaskType is RETRIEVAL_DOCUMENT.\n                    output_dimensionality: Optional reduced dimension for the output embedding.\n                    https://ai.google.dev/api/rest/v1/models/batchEmbedContents#EmbedContentRequest\n\n                Returns:\n                    Embedding for the text.\n                \"\"\"\n                task_type = self.task_type or \"RETRIEVAL_QUERY\"\n                return self.embed_documents(\n                    [text],\n                    task_type=task_type,\n                    titles=[title] if title else None,\n                    output_dimensionality=1536,\n                )[0]\n\n        return HotaGoogleGenerativeAIEmbeddings(model=self.model_name, google_api_key=self.api_key)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "models/text-embedding-004",
                "display_name": "Model Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Connect to Google's generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, found in the langchain-google-genai package.",
            "icon": "Google",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Google Generative AI Embeddings",
            "documentation": "https://python.langchain.com/v0.2/docs/integrations/text_embedding/google_generative_ai/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "api_key",
              "model_name"
            ],
            "beta": false,
            "edited": false
          },
          "id": "Google Generative AI Embeddings-BECyO"
        },
        "selected": false,
        "width": 384,
        "height": 473,
        "positionAbsolute": {
          "x": 254.63694376057265,
          "y": 819.5186150772323
        },
        "dragging": false
      },
      {
        "id": "FAISS-vtnhr",
        "type": "genericNode",
        "position": {
          "x": 773.471260058336,
          "y": 365.02956603725295
        },
        "data": {
          "type": "FAISS",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "allow_dangerous_deserialization": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_dangerous_deserialization",
                "value": true,
                "display_name": "Allow Dangerous Deserialization",
                "advanced": true,
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "index_name",
                "value": "axiestudio_index",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "persist_directory",
                "value": "",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "FAISS Vector Store with search capabilities",
            "icon": "FAISS",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "FAISS",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "index_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "beta": false,
            "edited": false
          },
          "id": "FAISS-vtnhr"
        },
        "selected": false,
        "width": 384,
        "height": 662,
        "positionAbsolute": {
          "x": 773.471260058336,
          "y": 365.02956603725295
        },
        "dragging": false
      },
      {
        "id": "Chroma-XTusY",
        "type": "genericNode",
        "position": {
          "x": 1346.9334628059323,
          "y": 552.3951193322613
        },
        "data": {
          "type": "Chroma",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "allow_duplicates": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_duplicates",
                "value": false,
                "display_name": "Allow Duplicates",
                "advanced": true,
                "dynamic": false,
                "info": "If false, will not add documents that are already in the Vector Store.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "chroma_server_cors_allow_origins": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_cors_allow_origins",
                "value": "",
                "display_name": "Server CORS Allow Origins",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "chroma_server_grpc_port": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_grpc_port",
                "value": "",
                "display_name": "Server gRPC Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chroma_server_host": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_host",
                "value": "",
                "display_name": "Server Host",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "chroma_server_http_port": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_http_port",
                "value": "",
                "display_name": "Server HTTP Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chroma_server_ssl_enabled": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_ssl_enabled",
                "value": false,
                "display_name": "Server SSL Enabled",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.base.vectorstores.utils import chroma_collection_to_data\nfrom axiestudio.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom axiestudio.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"axiestudio\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "axiestudio",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "limit": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "limit",
                "value": "",
                "display_name": "Limit",
                "advanced": true,
                "dynamic": false,
                "info": "Limit the number of records to compare when Allow Duplicates is False.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 10,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "persist_directory",
                "value": "",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "search_type": {
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "MMR"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_type",
                "value": "Similarity",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Chroma Vector Store with search capabilities",
            "icon": "Chroma",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "Chroma DB",
            "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "collection_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "embedding",
              "chroma_server_cors_allow_origins",
              "chroma_server_host",
              "chroma_server_http_port",
              "chroma_server_grpc_port",
              "chroma_server_ssl_enabled",
              "allow_duplicates",
              "search_type",
              "number_of_results",
              "limit"
            ],
            "beta": false,
            "edited": false
          },
          "id": "Chroma-XTusY"
        },
        "selected": false,
        "width": 384,
        "height": 662,
        "positionAbsolute": {
          "x": 1346.9334628059323,
          "y": 552.3951193322613
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Google Generative AI Embeddings-BECyO",
        "sourceHandle": "{dataType:Google Generative AI Embeddings,id:Google Generative AI Embeddings-BECyO,name:embeddings,output_types:[Embeddings]}",
        "target": "FAISS-vtnhr",
        "targetHandle": "{fieldName:embedding,id:FAISS-vtnhr,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-vtnhr",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Google Generative AI Embeddings",
            "id": "Google Generative AI Embeddings-BECyO",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-Google Generative AI Embeddings-BECyO{dataType:Google Generative AI Embeddings,id:Google Generative AI Embeddings-BECyO,name:embeddings,output_types:[Embeddings]}-FAISS-vtnhr{fieldName:embedding,id:FAISS-vtnhr,inputTypes:[Embeddings],type:other}"
      }
    ],
    "viewport": {
      "x": 492.7766257692873,
      "y": 351.68447511574476,
      "zoom": 0.5224976539923726
    }
  },
  "metadata": {
    "Chroma": {
      "count": 2
    },
    "Google Generative AI Embeddings": {
      "count": 1
    },
    "FAISS": {
      "count": 1
    },
    "total": 4
  },
  "original": {
    "id": "bd02d0e6-c89f-4bf9-a52f-3ec7a1144fce",
    "name": "PDF QA",
    "description": "Unleashing Business Potential through Language Engineering.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "13",
    "metadata": {
      "Chroma": {
        "count": 2
      },
      "Google Generative AI Embeddings": {
        "count": 1
      },
      "FAISS": {
        "count": 1
      },
      "total": 4
    },
    "last_tested_version": "1.0.18",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "Chroma-RqiRC",
          "type": "genericNode",
          "position": {
            "x": 1318.943401164838,
            "y": -50.62955471741179
          },
          "data": {
            "type": "Chroma",
            "node": {
              "template": {
                "documents": {
                  "type": "Document",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "documents",
                  "display_name": "Documents",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "embedding": {
                  "type": "Embeddings",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "embedding",
                  "display_name": "Embedding",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "chroma_server_cors_allow_origins": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chroma_server_cors_allow_origins",
                  "display_name": "Server CORS Allow Origins",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "chroma_server_grpc_port": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chroma_server_grpc_port",
                  "display_name": "Server gRPC Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "chroma_server_host": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chroma_server_host",
                  "display_name": "Server Host",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": ""
                },
                "chroma_server_port": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chroma_server_port",
                  "display_name": "Server Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": ""
                },
                "chroma_server_ssl_enabled": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chroma_server_ssl_enabled",
                  "display_name": "Server SSL Enabled",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, Optional, Union\n\nimport chromadb  # type: ignore\nfrom langchain.embeddings.base import Embeddings\nfrom langchain.schema import BaseRetriever, Document\nfrom langchain_community.vectorstores import VectorStore\nfrom langchain_community.vectorstores.chroma import Chroma\nfrom axiestudio import CustomComponent\n\n\nclass ChromaComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Chroma.\n    \"\"\"\n\n    display_name: str = \"Chroma\"\n    description: str = \"Implementation of Vector Store using Chroma\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    beta: bool = True\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"collection_name\": {\"display_name\": \"Collection Name\", \"value\": \"axiestudio\"},\n            \"persist\": {\"display_name\": \"Persist\"},\n            \"persist_directory\": {\"display_name\": \"Persist Directory\"},\n            \"code\": {\"advanced\": True, \"display_name\": \"Code\"},\n            \"documents\": {\"display_name\": \"Documents\", \"is_list\": True},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_port\": {\"display_name\": \"Server Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        collection_name: str,\n        persist: bool,\n        embedding: Embeddings,\n        chroma_server_ssl_enabled: bool,\n        persist_directory: Optional[str] = None,\n        documents: Optional[List[Document]] = None,\n        chroma_server_cors_allow_origins: Optional[str] = None,\n        chroma_server_host: Optional[str] = None,\n        chroma_server_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - collection_name (str): The name of the collection.\n        - persist_directory (Optional[str]): The directory to persist the Vector Store to.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - persist (bool): Whether to persist the Vector Store or not.\n        - embedding (Optional[Embeddings]): The embeddings to use for the Vector Store.\n        - documents (Optional[Document]): The documents to use for the Vector Store.\n        - chroma_server_cors_allow_origins (Optional[str]): The CORS allow origins for the Chroma server.\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\n        - chroma_server_port (Optional[int]): The port for the Chroma server.\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\n\n        Returns:\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n\n        if chroma_server_host is not None:\n            chroma_settings = chromadb.config.Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or None,\n                chroma_server_host=chroma_server_host,\n                chroma_server_port=chroma_server_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n\n        # If documents, then we need to create a Chroma instance using .from_documents\n        if documents is not None and embedding is not None:\n            if len(documents) == 0:\n                raise ValueError(\"If documents are provided, there must be at least one document.\")\n            return Chroma.from_documents(\n                documents=documents,  # type: ignore\n                persist_directory=persist_directory if persist else None,\n                collection_name=collection_name,\n                embedding=embedding,\n                client_settings=chroma_settings,\n            )\n\n        return Chroma(persist_directory=persist_directory, client_settings=chroma_settings)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "collection_name": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "axiestudio",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "collection_name",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "persist": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "persist",
                  "display_name": "Persist",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "persist_directory": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "persist_directory",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Implementation of Vector Store using Chroma",
              "base_classes": [
                "VectorStore",
                "BaseRetriever"
              ],
              "display_name": "Chroma",
              "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
              "custom_fields": {
                "collection_name": null,
                "persist": null,
                "embedding": null,
                "chroma_server_ssl_enabled": null,
                "persist_directory": null,
                "documents": null,
                "chroma_server_cors_allow_origins": null,
                "chroma_server_host": null,
                "chroma_server_port": null,
                "chroma_server_grpc_port": null
              },
              "output_types": [
                "VectorStore",
                "BaseRetriever"
              ],
              "field_formatters": {},
              "beta": true,
              "outputs": [
                {
                  "types": [
                    "VectorStore",
                    "BaseRetriever"
                  ],
                  "selected": "BaseRetriever",
                  "name": "VectorStore | BaseRetriever",
                  "display_name": "VectorStore | BaseRetriever"
                }
              ]
            },
            "id": "Chroma-RqiRC"
          },
          "selected": false,
          "width": 384,
          "height": 557,
          "positionAbsolute": {
            "x": 1318.943401164838,
            "y": -50.62955471741179
          },
          "dragging": false
        },
        {
          "id": "Google Generative AI Embeddings-BECyO",
          "type": "genericNode",
          "position": {
            "x": 254.63694376057265,
            "y": 819.5186150772323
          },
          "data": {
            "type": "Google Generative AI Embeddings",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output, SecretStrInput\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\nfrom typing import List, Optional\n\n# TODO: remove ignore once the google package is published with types\nfrom google.ai.generativelanguage_v1beta.types import (\n    BatchEmbedContentsRequest,\n)\nfrom langchain_core.embeddings import Embeddings\n\nfrom langchain_google_genai._common import (\n    GoogleGenerativeAIError,\n)\n\nimport numpy as np\n\n\nclass GoogleGenerativeAIEmbeddingsComponent(Component):\n    display_name = \"Google Generative AI Embeddings\"\n    description = \"Connect to Google's generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, found in the langchain-google-genai package.\"\n    documentation: str = \"https://python.langchain.com/v0.2/docs/integrations/text_embedding/google_generative_ai/\"\n    icon = \"Google\"\n    name = \"Google Generative AI Embeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"models/text-embedding-004\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.api_key:\n            raise ValueError(\"API Key is required\")\n\n        class HotaGoogleGenerativeAIEmbeddings(GoogleGenerativeAIEmbeddings):\n            def __init__(self, *args, **kwargs):\n                super(GoogleGenerativeAIEmbeddings, self).__init__(*args, **kwargs)\n\n            def embed_documents(\n                self,\n                texts: List[str],\n                *,\n                batch_size: int = 100,\n                task_type: Optional[str] = None,\n                titles: Optional[List[str]] = None,\n                output_dimensionality: Optional[int] = 1536,\n            ) -> List[List[float]]:\n                \"\"\"Embed a list of strings. Google Generative AI currently\n                sets a max batch size of 100 strings.\n\n                Args:\n                    texts: List[str] The list of strings to embed.\n                    batch_size: [int] The batch size of embeddings to send to the model\n                    task_type: task_type (https://ai.google.dev/api/rest/v1/TaskType)\n                    titles: An optional list of titles for texts provided.\n                    Only applicable when TaskType is RETRIEVAL_DOCUMENT.\n                    output_dimensionality: Optional reduced dimension for the output embedding.\n                    https://ai.google.dev/api/rest/v1/models/batchEmbedContents#EmbedContentRequest\n                Returns:\n                    List of embeddings, one for each text.\n                \"\"\"\n                embeddings: List[List[float]] = []\n                batch_start_index = 0\n                for batch in GoogleGenerativeAIEmbeddings._prepare_batches(texts, batch_size):\n                    if titles:\n                        titles_batch = titles[batch_start_index : batch_start_index + len(batch)]\n                        batch_start_index += len(batch)\n                    else:\n                        titles_batch = [None] * len(batch)  # type: ignore[list-item]\n\n                    requests = [\n                        self._prepare_request(\n                            text=text,\n                            task_type=task_type,\n                            title=title,\n                            output_dimensionality=1536,\n                        )\n                        for text, title in zip(batch, titles_batch)\n                    ]\n\n                    try:\n                        result = self.client.batch_embed_contents(\n                            BatchEmbedContentsRequest(requests=requests, model=self.model)\n                        )\n                    except Exception as e:\n                        raise GoogleGenerativeAIError(f\"Error embedding content: {e}\") from e\n                    embeddings.extend([list(np.pad(e.values, (0, 768), \"constant\")) for e in result.embeddings])\n                return embeddings\n\n            def embed_query(\n                self,\n                text: str,\n                task_type: Optional[str] = None,\n                title: Optional[str] = None,\n                output_dimensionality: Optional[int] = 1536,\n            ) -> List[float]:\n                \"\"\"Embed a text.\n\n                Args:\n                    text: The text to embed.\n                    task_type: task_type (https://ai.google.dev/api/rest/v1/TaskType)\n                    title: An optional title for the text.\n                    Only applicable when TaskType is RETRIEVAL_DOCUMENT.\n                    output_dimensionality: Optional reduced dimension for the output embedding.\n                    https://ai.google.dev/api/rest/v1/models/batchEmbedContents#EmbedContentRequest\n\n                Returns:\n                    Embedding for the text.\n                \"\"\"\n                task_type = self.task_type or \"RETRIEVAL_QUERY\"\n                return self.embed_documents(\n                    [text],\n                    task_type=task_type,\n                    titles=[title] if title else None,\n                    output_dimensionality=1536,\n                )[0]\n\n        return HotaGoogleGenerativeAIEmbeddings(model=self.model_name, google_api_key=self.api_key)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "model_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "models/text-embedding-004",
                  "display_name": "Model Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Connect to Google's generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, found in the langchain-google-genai package.",
              "icon": "Google",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Google Generative AI Embeddings",
              "documentation": "https://python.langchain.com/v0.2/docs/integrations/text_embedding/google_generative_ai/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "api_key",
                "model_name"
              ],
              "beta": false,
              "edited": false
            },
            "id": "Google Generative AI Embeddings-BECyO"
          },
          "selected": false,
          "width": 384,
          "height": 473,
          "positionAbsolute": {
            "x": 254.63694376057265,
            "y": 819.5186150772323
          },
          "dragging": false
        },
        {
          "id": "FAISS-vtnhr",
          "type": "genericNode",
          "position": {
            "x": 773.471260058336,
            "y": 365.02956603725295
          },
          "data": {
            "type": "FAISS",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ingest_data",
                  "value": "",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "allow_dangerous_deserialization": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_dangerous_deserialization",
                  "value": true,
                  "display_name": "Allow Dangerous Deserialization",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "index_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "index_name",
                  "value": "axiestudio_index",
                  "display_name": "Index Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 4,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "persist_directory",
                  "value": "",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "FAISS Vector Store with search capabilities",
              "icon": "FAISS",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "FAISS",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "index_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "allow_dangerous_deserialization",
                "embedding",
                "number_of_results"
              ],
              "beta": false,
              "edited": false
            },
            "id": "FAISS-vtnhr"
          },
          "selected": false,
          "width": 384,
          "height": 662,
          "positionAbsolute": {
            "x": 773.471260058336,
            "y": 365.02956603725295
          },
          "dragging": false
        },
        {
          "id": "Chroma-XTusY",
          "type": "genericNode",
          "position": {
            "x": 1346.9334628059323,
            "y": 552.3951193322613
          },
          "data": {
            "type": "Chroma",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ingest_data",
                  "value": "",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "allow_duplicates": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_duplicates",
                  "value": false,
                  "display_name": "Allow Duplicates",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If false, will not add documents that are already in the Vector Store.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "chroma_server_cors_allow_origins": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_cors_allow_origins",
                  "value": "",
                  "display_name": "Server CORS Allow Origins",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "chroma_server_grpc_port": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_grpc_port",
                  "value": "",
                  "display_name": "Server gRPC Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chroma_server_host": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_host",
                  "value": "",
                  "display_name": "Server Host",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "chroma_server_http_port": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_http_port",
                  "value": "",
                  "display_name": "Server HTTP Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chroma_server_ssl_enabled": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_ssl_enabled",
                  "value": false,
                  "display_name": "Server SSL Enabled",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.base.vectorstores.utils import chroma_collection_to_data\nfrom axiestudio.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom axiestudio.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"axiestudio\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "collection_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "collection_name",
                  "value": "axiestudio",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "limit": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "limit",
                  "value": "",
                  "display_name": "Limit",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limit the number of records to compare when Allow Duplicates is False.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 10,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "persist_directory",
                  "value": "",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "search_type": {
                  "trace_as_metadata": true,
                  "options": [
                    "Similarity",
                    "MMR"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_type",
                  "value": "Similarity",
                  "display_name": "Search Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                }
              },
              "description": "Chroma Vector Store with search capabilities",
              "icon": "Chroma",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "Chroma DB",
              "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "collection_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "embedding",
                "chroma_server_cors_allow_origins",
                "chroma_server_host",
                "chroma_server_http_port",
                "chroma_server_grpc_port",
                "chroma_server_ssl_enabled",
                "allow_duplicates",
                "search_type",
                "number_of_results",
                "limit"
              ],
              "beta": false,
              "edited": false
            },
            "id": "Chroma-XTusY"
          },
          "selected": false,
          "width": 384,
          "height": 662,
          "positionAbsolute": {
            "x": 1346.9334628059323,
            "y": 552.3951193322613
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Google Generative AI Embeddings-BECyO",
          "sourceHandle": "{dataType:Google Generative AI Embeddings,id:Google Generative AI Embeddings-BECyO,name:embeddings,output_types:[Embeddings]}",
          "target": "FAISS-vtnhr",
          "targetHandle": "{fieldName:embedding,id:FAISS-vtnhr,inputTypes:[Embeddings],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "FAISS-vtnhr",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "Google Generative AI Embeddings",
              "id": "Google Generative AI Embeddings-BECyO",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-Google Generative AI Embeddings-BECyO{dataType:Google Generative AI Embeddings,id:Google Generative AI Embeddings-BECyO,name:embeddings,output_types:[Embeddings]}-FAISS-vtnhr{fieldName:embedding,id:FAISS-vtnhr,inputTypes:[Embeddings],type:other}"
        }
      ],
      "viewport": {
        "x": 492.7766257692873,
        "y": 351.68447511574476,
        "zoom": 0.5224976539923726
      }
    },
    "date_created": "2024-09-13T13:53:07.068Z",
    "date_updated": "2024-09-13T13:53:07.315Z",
    "status": "Public",
    "sort": null,
    "user_updated": "b0c9c84d-b48a-4dee-bf0a-f872f4a11a2d",
    "user_created": {
      "username": "keith-matthews",
      "first_name": "keith",
      "last_name": "matthews",
      "id": "b0c9c84d-b48a-4dee-bf0a-f872f4a11a2d"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:04.781Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 36,
    "converter_version": "1.0.0"
  }
}