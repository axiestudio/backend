{
  "id": "f94bee55-a13f-4a72-8777-eed20ec0e2f4",
  "name": "[Dev] Agent Deve and Testing",
  "description": "This Agent runs tasks in a predefined sequence. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "jingconsult",
    "first_name": "Jing",
    "last_name": "Consulting",
    "id": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "full_name": "Jing Consulting"
  },
  "store_url": "https://www.langflow.store/store/component/f94bee55-a13f-4a72-8777-eed20ec0e2f4",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-11T14:09:55.777Z",
    "updated": "2024-10-17T03:35:45.761Z",
    "downloaded": "2025-08-19T17:50:07.458Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "HierarchicalCrewComponent-POopw",
        "type": "genericNode",
        "position": {
          "x": -964.7290554289862,
          "y": -790.743116515845
        },
        "data": {
          "type": "HierarchicalCrewComponent",
          "node": {
            "template": {
              "_type": "Component",
              "agents": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agents",
                "value": "",
                "display_name": "Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "function_calling_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "function_calling_llm",
                "value": "",
                "display_name": "Function Calling LLM",
                "advanced": true,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "manager_agent": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "manager_agent",
                "value": "",
                "display_name": "Manager Agent",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "manager_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "manager_llm",
                "value": "",
                "display_name": "Manager LLM",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tasks": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tasks",
                "value": "",
                "display_name": "Tasks",
                "advanced": false,
                "input_types": [
                  "HierarchicalTask"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_rpm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_rpm",
                "value": 100,
                "display_name": "Max RPM",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": false,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "share_crew": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "share_crew",
                "value": false,
                "display_name": "Share Crew",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "use_cache": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_cache",
                "value": true,
                "display_name": "Cache",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": 0,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "icon": "CrewAI",
            "base_classes": [
              "Message"
            ],
            "display_name": "Hierarchical Crew",
            "documentation": "https://docs.crewai.com/how-to/Hierarchical/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "verbose",
              "memory",
              "use_cache",
              "max_rpm",
              "share_crew",
              "function_calling_llm",
              "agents",
              "tasks",
              "manager_llm",
              "manager_agent"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "HierarchicalCrewComponent-POopw"
        },
        "selected": false,
        "width": 384,
        "height": 454,
        "positionAbsolute": {
          "x": -964.7290554289862,
          "y": -790.743116515845
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-pF8ma",
        "type": "genericNode",
        "position": {
          "x": -3644.7966003082533,
          "y": -2689.3158975577467
        },
        "data": {
          "id": "OpenAIModel-pF8ma",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "lf_version": "1.0.17",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            }
          },
          "type": "OpenAIModel"
        },
        "selected": false,
        "width": 384,
        "height": 597,
        "positionAbsolute": {
          "x": -3644.7966003082533,
          "y": -2689.3158975577467
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-RJKKD",
        "type": "genericNode",
        "position": {
          "x": -2805.583462867302,
          "y": -1316.614108992988
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": true,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "User Interest Acquire Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CrewAIAgentComponent-RJKKD"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "positionAbsolute": {
          "x": -2805.583462867302,
          "y": -1316.614108992988
        },
        "dragging": false
      },
      {
        "id": "RetrieverTool-ijoHS",
        "type": "genericNode",
        "position": {
          "x": -5157.337458282449,
          "y": -846.4474784579469
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "GetSubdomains",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "RetrieverTool-ijoHS"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "positionAbsolute": {
          "x": -5157.337458282449,
          "y": -846.4474784579469
        },
        "dragging": false
      },
      {
        "id": "CollectiveCrewAIAgentComponent-JhWL3",
        "type": "genericNode",
        "position": {
          "x": -2704.034298468254,
          "y": -420.778431614837
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": true,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "You are a knowledgeable, socratic, kind, empathetic, psychology-degree attained K-12 educational counsellor. You will proactively facilitate and scaffold with the student {user} in conversations to foreground their learning interests and be very attentive to the conversational {sentiment} and extract knowledge domain keywords, making reflective notes to {user_profile} about any tentative learning project plan, critical path or learning path that may be applied to the generation of a committed learning {project} with personalized {learning_module}.   ",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "To elicit genuine learning interest and logging the potential relevance to the domain knowledge and subject matter. Update to {user_profile}, {learning interest}, record {chat}, {conversation}, forward {learning interest}, domain knowledge, subject matter to Agent 2",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "Counsellor",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Learning Module Generation Domain",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveCrewAIAgentComponent-JhWL3"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "positionAbsolute": {
          "x": -2704.034298468254,
          "y": -420.778431614837
        },
        "dragging": false
      },
      {
        "id": "CollectiveCrewAIAgentComponent-gsrJN",
        "type": "genericNode",
        "position": {
          "x": -1833.1416795636735,
          "y": -433.4566697111805
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": true,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "You are a scrupulous project planner who is very conscious about the timeline, scope, and the resource constraints by which a project is scheduled. You acknowledge the users {learning interest} and research on the related domain knowledge and subject matter by synthesizing the cross domain GraphDB search results (cypher query and llm combined to infer) with the project plan. With this synthesis, you will then present a draft of the project-based {learning module} for the {user} to consent. The draft is usually formatted with the following signposts (by their semantic meanings): \n1. **Project Management (pm) Set:**\n- I. Project Fundamentals\n    \n    A. Project Scope\n    B. Project Plan\n    C. Timeline\n    D. Budget\n    \n- II. Project Structure\n    \n    A. Work Breakdown Structure\n    B. Task\n    C. Milestone\n    D. Deliverable\n    E. Dependency\n    F. Critical Path\n    \n- III. Project Execution\n    \n    A. Prototyping\n    B. Schedule\n    C. Resource\n    D. Gantt\n    \n- IV. Project Management\n    \n    A. Change Management\n    B. Change Request\n    C. Risk\n    D. Issue\n    \n- V. People\n    \n    A. Stakeholder\n    B. Team Member\n    C. Project Manager\n    D. Team Lead\n    E. Subject Matter Expert\n    F. Technical Champion\n    G. Domain Knowledge\n    \n1. **Learning Module (lm) Set:**\n- I. Learning Structure\n    \n    A. Learning Path\n    B. Learning Module\n    C. Course\n    D. Training\n    E. Study Plan\n    F. Study Outline\n    G. Learning Activity\n    H. Learning Task\n    I. Self-directed Learning\n    J. Dojo\n    \n- II. Learning Roles\n    \n    A. Instructor\n    B. Facilitator\n    C. Mentor\n    D. Learning Companion\n    \n- III. Learning Characteristics\n    \n    A. Cross Domain\n    B. Inter-Domain\n    C. Knowledge Area\n    \n- IV. Learning Logistics\n    \n    A. Duration\n    \n- V. Learning Assessment\n    \n    A. Assessment\n    B. Marking\n    C. Score\n    D. Learning Feedback\n    E. Achievement\n    F. Certificate\n    G. Learning Outcome\n    \n- VI. Learning Management\n    \n    A. Learning Content Adjustment\n    \n1. **Integrated Project Plan with Learning Module:**\n- I. Project Fundamentals\n    - A. Project Scope\n        \n        1. Learning Path definition\n        2. Cross Domain / Inter-Domain integration\n        \n    - B. Project Plan\n        \n        1. Learning Module structure\n        2. Course and Training outline\n        3. Study Plan and Outline development\n        \n    - C. Timeline\n        \n        1. Overall project duration\n        2. Individual module durations\n        \n    - D. Budget\n        \n        1. Learning resources allocation\n        2. Instructor/Facilitator costs\n        \n- II. Project Structure\n    - A. Work Breakdown Structure\n        \n        1. Learning Path breakdown\n        2. Module-specific tasks\n        3. Learning Activities and Tasks design\n        \n    - B. Tasks\n        \n        1. Content development\n        2. Cross-domain integration activities\n        3. Self-directed Learning components\n        \n    - C. Milestones\n        \n        1. Module completion points\n        2. Cross-domain integration checkpoints\n        3. Dojo establishment and implementation\n        \n    - D. Deliverables\n        \n        1. Learning materials\n        2. Cross-domain knowledge artifacts\n        3. Assessment tools and rubrics\n        \n    - E. Dependencies\n        \n        1. Inter-module dependencies\n        2. Cross-domain knowledge prerequisites\n        \n    - F. Critical Path\n        \n        1. Essential learning sequence\n        2. Key cross-domain integration points\n        \n- III. Project Execution\n    - A. Prototyping\n        \n        1. Sample learning modules\n        2. Cross-domain integration examples\n        \n    - B. Schedule\n        \n        1. Module development timeline\n        2. Training session scheduling\n        3. Assessment and feedback cycles\n        \n    - C. Resource Allocation\n        \n        1. Instructors and Facilitators\n        2. Learning materials and platforms\n        3. Learning Companions assignment\n        \n    - D. Gantt Chart\n        \n        1. Visual representation of learning path\n        2. Cross-domain integration points\n        3. Assessment and feedback milestones\n        \n- IV. Project Management\n    - A. Change Management\n        \n        1. Adapting learning content\n        2. Updating cross-domain connections\n        3. Learning Content Adjustment process\n        \n    - B. Change Requests\n        \n        1. Module content adjustments\n        2. Cross-domain integration refinements\n        3. Assessment method revisions\n        \n    - C. Risk Management\n        \n        1. Learning effectiveness risks\n        2. Cross-domain integration challenges\n        3. Self-directed learning support risks\n        \n    - D. Issue Tracking\n        \n        1. Learning obstacles\n        2. Cross-domain misalignments\n        \n        3. Feedback implementation issues\n        \n- V. People and Roles\n    - A. Stakeholders\n        \n        1. Learners\n        2. Organizational leadership\n        \n    - B. Team Members\n        \n        1. Content developers\n        2. Cross-domain experts\n        3. Assessment designers\n        \n    - C. Project Manager\n        \n        1. Overall learning path management\n        2. Cross-domain integration oversight\n        3. Learning outcome monitoring\n        \n    - D. Team Lead\n        \n        1. Module development lead\n        2. Cross-domain integration lead\n        3. Learning Activity coordination\n        \n    - E. Subject Matter Experts\n        \n        1. Domain-specific knowledge providers\n        2. Cross-domain connection advisors\n        \n    - F. Technical Champion\n        \n        1. Learning platform specialist\n        2. Cross-domain tools expert\n        3. Dojo technical support\n        \n    - G. Instructors/Facilitators\n        \n        1. Module-specific instructors\n        2. Cross-domain integration facilitators\n        3. Learning feedback providers\n        \n    - H. Mentors\n        \n        1. Learner support\n        2. Cross-domain navigation guidance\n        3. Self-directed learning assistance\n        \n- VI. Knowledge Management\n    - A. Domain Knowledge\n        \n        1. Core subject areas\n        2. Cross-domain intersections\n        \n    - B. Knowledge Area Mapping\n        \n        1. Identifying key knowledge areas\n        2. Mapping cross-domain connections\n        \n    - C. Learning Outcome Tracking\n        \n        1. Achievement monitoring\n        2. Certificate issuance\n        3. Score analysis and reporting\n        \n- VII. Learning Assessment and Feedback\n    - A. Assessment Strategy\n        \n        1. Assessment design and implementation\n        2. Marking criteria development\n        \n    - B. Feedback Mechanism\n        \n        1. Learning feedback loops\n        2. Continuous improvement process\n        \n    - C. Performance Evaluation\n        \n        1. Score tracking and analysis\n        2. Learning outcome measurement\n        \n    - D. Recognition System\n        \n        1. Achievement acknowledgment\n        2. Certificate design and distribution\n        \n\nThis hierarchical structure clearly delineates the different levels and relationships within each set and in the integrated project plan.",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "Listening to the {user} and the input from Agent 1, draft a project plan with the templated learning module for project commitment.",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "Project Planner",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Project Planner",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveCrewAIAgentComponent-gsrJN"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "positionAbsolute": {
          "x": -1833.1416795636735,
          "y": -433.4566697111805
        },
        "dragging": false
      },
      {
        "id": "HierarchicalTaskComponent-fh9Vr",
        "type": "genericNode",
        "position": {
          "x": -4352.296232112481,
          "y": -226.51196401892486
        },
        "data": {
          "type": "HierarchicalTaskComponent",
          "node": {
            "template": {
              "_type": "Component",
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": true,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "expected_output": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "expected_output",
                "value": "",
                "display_name": "Expected Output",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Clear definition of expected task outcome.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "task_description": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "task_description",
                "value": "",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Descriptive text detailing task's purpose and execution.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "icon": "CrewAI",
            "base_classes": [
              "HierarchicalTask"
            ],
            "display_name": "Hierarchical Task",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "HierarchicalTask"
                ],
                "selected": "HierarchicalTask",
                "name": "task_output",
                "display_name": "Task",
                "method": "build_task",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "task_description",
              "expected_output",
              "tools"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "HierarchicalTaskComponent-fh9Vr"
        },
        "selected": false,
        "width": 384,
        "height": 406,
        "positionAbsolute": {
          "x": -4352.296232112481,
          "y": -226.51196401892486
        },
        "dragging": false
      },
      {
        "id": "CollectiveTool-iGp6D",
        "type": "genericNode",
        "position": {
          "x": -3774.2421303749106,
          "y": -1804.7580492303775
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Vector Search Tool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveTool-iGp6D"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "dragging": false,
        "positionAbsolute": {
          "x": -3774.2421303749106,
          "y": -1804.7580492303775
        }
      },
      {
        "id": "CollectiveTool-GGaIt",
        "type": "genericNode",
        "position": {
          "x": -4429.396359772079,
          "y": -1825.6300716360774
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Graph Search Tool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveTool-GGaIt"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "positionAbsolute": {
          "x": -4429.396359772079,
          "y": -1825.6300716360774
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-wBeSt",
        "type": "genericNode",
        "position": {
          "x": -181.4317707745172,
          "y": 70.33134873875764
        },
        "data": {
          "type": "CrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": true,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Manage how model responds",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Manager Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agent",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "CrewAIAgentComponent-wBeSt"
        },
        "selected": false,
        "width": 384,
        "height": 631,
        "positionAbsolute": {
          "x": -181.4317707745172,
          "y": 70.33134873875764
        },
        "dragging": false
      },
      {
        "id": "CollectiveCrewAIAgentComponent-g95En",
        "type": "genericNode",
        "position": {
          "x": -1775.1348717591247,
          "y": -1326.339236884657
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": true,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "You are the project gate-keeper, you are to monitor, assess, manage, and report the project development and the learning progress to {user}, {human tutor}, and {parent}. \n\nYou will attentively spot any **STAGNATION** in the project and learning progress, and proactively advise {user} of any adjustment or amendment to the **project plan** or **learning module** accordingly.",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "Abide to the committed project plan and learning module provided by Agent 2. Spot any STAGNATION or lag in the project timeline, tasks, learning activities and assessment. Adjust or amend to the project plan and learning module as per advised and required scenario arises with the {user}. Generate learning progress/performance report to {user}, {human tutor}, and {parent}",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "Project Warden",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Project Warden",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "official": false,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveCrewAIAgentComponent-g95En"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "dragging": false,
        "positionAbsolute": {
          "x": -1775.1348717591247,
          "y": -1326.339236884657
        }
      },
      {
        "id": "CollectiveTool-8jGBc",
        "type": "genericNode",
        "position": {
          "x": -2912.1575914537902,
          "y": -1843.1326669753314
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "User Profile Tool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveTool-8jGBc"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "positionAbsolute": {
          "x": -2912.1575914537902,
          "y": -1843.1326669753314
        },
        "dragging": false
      },
      {
        "id": "CollectiveTool-wx20I",
        "type": "genericNode",
        "position": {
          "x": -2297.7077035243124,
          "y": -1821.5309131028107
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Cypher Generation Tool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveTool-wx20I"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "positionAbsolute": {
          "x": -2297.7077035243124,
          "y": -1821.5309131028107
        },
        "dragging": false
      },
      {
        "id": "CollectiveTool-vMdr2",
        "type": "genericNode",
        "position": {
          "x": -1614.45754968375,
          "y": -1842.0785765508965
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "AI-tutor Report",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveTool-vMdr2"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "positionAbsolute": {
          "x": -1614.45754968375,
          "y": -1842.0785765508965
        },
        "dragging": false
      },
      {
        "id": "ChatInput-Cg9n0",
        "type": "genericNode",
        "position": {
          "x": -3461.985148738744,
          "y": 3751.0755651282143
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Based on your knowledge stored in the postgres database, tell me how to build a knowledge graph?",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatInput-Cg9n0"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": -3461.985148738744,
          "y": 3751.0755651282143
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-jr4bG",
        "type": "genericNode",
        "position": {
          "x": -2222.7968878390807,
          "y": 3722.2657082079704
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatOutput-jr4bG"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": -2222.7968878390807,
          "y": 3722.2657082079704
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-svPsH",
        "type": "genericNode",
        "position": {
          "x": -3402.1507837367276,
          "y": 1938.6699868253643
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-svPsH"
        },
        "selected": false,
        "width": 384,
        "height": 597,
        "positionAbsolute": {
          "x": -3402.1507837367276,
          "y": 1938.6699868253643
        },
        "dragging": false
      },
      {
        "id": "HierarchicalCrewComponent-8R2Ak",
        "type": "genericNode",
        "position": {
          "x": -1212.85292424607,
          "y": 2547.644519729222
        },
        "data": {
          "type": "HierarchicalCrewComponent",
          "node": {
            "template": {
              "_type": "Component",
              "agents": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agents",
                "value": "",
                "display_name": "Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "function_calling_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "function_calling_llm",
                "value": "",
                "display_name": "Function Calling LLM",
                "advanced": true,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "manager_agent": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "manager_agent",
                "value": "",
                "display_name": "Manager Agent",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "manager_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "manager_llm",
                "value": "",
                "display_name": "Manager LLM",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tasks": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tasks",
                "value": "",
                "display_name": "Tasks",
                "advanced": false,
                "input_types": [
                  "HierarchicalTask"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            planning=True\n        )\n        return crew\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_rpm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_rpm",
                "value": 100,
                "display_name": "Max RPM",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": false,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "share_crew": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "share_crew",
                "value": false,
                "display_name": "Share Crew",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "use_cache": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_cache",
                "value": false,
                "display_name": "Cache",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "load_from_db": false
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": 0,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "icon": "CrewAI",
            "base_classes": [
              "Message"
            ],
            "display_name": "Hierarchical Crew",
            "documentation": "https://docs.crewai.com/how-to/Hierarchical/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "verbose",
              "memory",
              "use_cache",
              "max_rpm",
              "share_crew",
              "function_calling_llm",
              "agents",
              "tasks",
              "manager_llm",
              "manager_agent"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "HierarchicalCrewComponent-8R2Ak"
        },
        "selected": false,
        "width": 384,
        "height": 454,
        "positionAbsolute": {
          "x": -1212.85292424607,
          "y": 2547.644519729222
        },
        "dragging": false
      },
      {
        "id": "CollectiveCrewAIAgentComponent-1z0Y8",
        "type": "genericNode",
        "position": {
          "x": -3263.3235794380553,
          "y": 924.8049991559969
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": false,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "You are an ontology warden who holds the ontology structure of knowledge domains.\n\n## 1. Mathematics and Statistics\n\n- Mathematics_PureMath\n- Mathematics_AppliedMath\n- Mathematics_Statistics\n\n## 2. Natural Sciences\n\n- NaturalSciences_Physics\n- NaturalSciences_Chemistry\n- NaturalSciences_Biology\n- NaturalSciences_EarthSciences\n\n## 3. Social Sciences\n\n- SocialSciences_Psychology\n- SocialSciences_SociologyAnthropology\n- SocialSciences_Economics\n- SocialSciences_PoliticalScience\n- SocialSciences_CommunicationMedia\n\n## 4. Humanities\n\n- Humanities_Philosophy\n- Humanities_Linguistics\n\n## 5. Business and Management\n\n- Business_Strategy\n- Business_Marketing\n\n## 6. Education\n\n- Education_GeneralEducation\n- Education_LiteracyWriting\n\n## 7. Applied Sciences and Engineering\n\n- AppliedSciences_ComputerScience\n- AppliedSciences_FoodScience\n- AppliedSciences_EnvironmentalScience\n- AppliedSciences_MarineScience\n\n## 8. Interdisciplinary Studies\n\n- Interdisciplinary_CulturalStudies\n- Interdisciplinary_EthicsSocialJustice",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "Answer user questions based on the ontology of knowledge domain in the backstor",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "Knowledge domain ontology warden",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Collective CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "official": false,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveCrewAIAgentComponent-1z0Y8"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "positionAbsolute": {
          "x": -3263.3235794380553,
          "y": 924.8049991559969
        },
        "dragging": false
      },
      {
        "id": "HierarchicalTaskComponent-Vezqe",
        "type": "genericNode",
        "position": {
          "x": -2713.1877278343118,
          "y": 2714.9893151137626
        },
        "data": {
          "type": "HierarchicalTaskComponent",
          "node": {
            "template": {
              "_type": "Component",
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": true,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output\n        )\n        self.status = task\n        return task\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "expected_output": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "expected_output",
                "value": "Succinct response that answers the User's query.",
                "display_name": "Expected Output",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Clear definition of expected task outcome.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "task_description": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "task_description",
                "value": "",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Descriptive text detailing task's purpose and execution.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "icon": "CrewAI",
            "base_classes": [
              "HierarchicalTask"
            ],
            "display_name": "Hierarchical Task",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "HierarchicalTask"
                ],
                "selected": "HierarchicalTask",
                "name": "task_output",
                "display_name": "Task",
                "method": "build_task",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "task_description",
              "expected_output",
              "tools"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "HierarchicalTaskComponent-Vezqe"
        },
        "selected": false,
        "width": 384,
        "height": 406,
        "dragging": false,
        "positionAbsolute": {
          "x": -2713.1877278343118,
          "y": 2714.9893151137626
        }
      },
      {
        "id": "Prompt-phlF8",
        "type": "genericNode",
        "position": {
          "x": -3195.459330872718,
          "y": 2938.3578928960665
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed. If it is just a general query (e.g a greeting) you can respond them directly.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Prompt-phlF8"
        },
        "selected": false,
        "width": 384,
        "height": 410,
        "positionAbsolute": {
          "x": -3195.459330872718,
          "y": 2938.3578928960665
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-Uq7Oe",
        "type": "genericNode",
        "position": {
          "x": -2300.0912752858617,
          "y": 2001.1752264824117
        },
        "data": {
          "type": "CrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": false,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "load_from_db": false
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "You are a RAG helper that can retrieve the most semantically relevant content from a database using embedding vector similarity search. When you give answers, only generate answer based on the retrieved content and always present the source of them from the data.",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "Find the most similar text to support the generation of answer for user's question.",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "PGVector Postgres Database Retriever",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agent",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CrewAIAgentComponent-Uq7Oe"
        },
        "selected": false,
        "width": 384,
        "height": 631,
        "positionAbsolute": {
          "x": -2300.0912752858617,
          "y": 2001.1752264824117
        },
        "dragging": false
      },
      {
        "id": "CollectiveCrewAIAgentComponent-yRgCM",
        "type": "genericNode",
        "position": {
          "x": -1896.7265112117511,
          "y": 1076.7368610958451
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": false,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "You discover the most similar subdomains in the ontology structure of knowledge domains from user's input.\n\n## 1. Mathematics and Statistics\n\n- Mathematics_PureMath\n- Mathematics_AppliedMath\n- Mathematics_Statistics\n\n## 2. Natural Sciences\n\n- NaturalSciences_Physics\n- NaturalSciences_Chemistry\n- NaturalSciences_Biology\n- NaturalSciences_EarthSciences\n\n## 3. Social Sciences\n\n- SocialSciences_Psychology\n- SocialSciences_SociologyAnthropology\n- SocialSciences_Economics\n- SocialSciences_PoliticalScience\n- SocialSciences_CommunicationMedia\n\n## 4. Humanities\n\n- Humanities_Philosophy\n- Humanities_Linguistics\n\n## 5. Business and Management\n\n- Business_Strategy\n- Business_Marketing\n\n## 6. Education\n\n- Education_GeneralEducation\n- Education_LiteracyWriting\n\n## 7. Applied Sciences and Engineering\n\n- AppliedSciences_ComputerScience\n- AppliedSciences_FoodScience\n- AppliedSciences_EnvironmentalScience\n- AppliedSciences_MarineScience\n\n## 8. Interdisciplinary Studies\n\n- Interdisciplinary_CulturalStudies\n- Interdisciplinary_EthicsSocialJustice",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "Discover user's interests with regards to one to three subdomains in the ontology",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "Interest discoverer",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Collective CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "official": false,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveCrewAIAgentComponent-yRgCM"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "positionAbsolute": {
          "x": -1896.7265112117511,
          "y": 1076.7368610958451
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-XHQqk",
        "type": "genericNode",
        "position": {
          "x": -1888.4967147972052,
          "y": 3042.15260904593
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-XHQqk"
        },
        "selected": false,
        "width": 384,
        "height": 597,
        "positionAbsolute": {
          "x": -1888.4967147972052,
          "y": 3042.15260904593
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-jKE5w",
        "type": "genericNode",
        "position": {
          "x": -6021.297568725004,
          "y": 1741.2968238056094
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-jKE5w"
        },
        "selected": false,
        "width": 384,
        "height": 597,
        "positionAbsolute": {
          "x": -6021.297568725004,
          "y": 1741.2968238056094
        },
        "dragging": false
      },
      {
        "id": "CollectiveCrewAIAgentComponent-bvGpO",
        "type": "genericNode",
        "position": {
          "x": -5502.852428097926,
          "y": 1853.485381808071
        },
        "data": {
          "type": "CollectiveCrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "previous_agents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "previous_agents",
                "value": "",
                "display_name": "Previous Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "The previous agents (for chaining).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": true,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "Collective CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agents",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs",
              "previous_agents"
            ],
            "beta": false,
            "edited": true,
            "official": false
          },
          "id": "CollectiveCrewAIAgentComponent-bvGpO"
        },
        "selected": false,
        "width": 384,
        "height": 707,
        "positionAbsolute": {
          "x": -5502.852428097926,
          "y": 1853.485381808071
        },
        "dragging": false
      },
      {
        "id": "CollectiveTool-p4hG6",
        "type": "genericNode",
        "position": {
          "x": -4431.206647909941,
          "y": 1901.1837328607676
        },
        "data": {
          "type": "Neo4jCypherQueryExecutorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, cast\r\nimport json\r\nimport pandas as pd\r\nfrom neo4j import GraphDatabase, exceptions\r\n\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.io import Output, MessageTextInput, MultilineInput\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.field_typing import Tool\r\n\r\nclass Neo4jCypherQueryExecutorComponent(Component):\r\n    display_name = \"Cypher Query Executor\"\r\n    description = \"Execute Cypher queries on a Neo4j database.\"\r\n    icon = \"\"\r\n    name = \"Neo4jCypherQueryExecutorComponent\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"cypher_query\", \r\n            display_name=\"Cypher Query\",\r\n            info=\"The Cypher query to execute.\"\r\n        ),\r\n        MessageTextInput(\r\n            name=\"neo4j_credentials\", \r\n            display_name=\"Neo4j Credentials\", \r\n            info=\"JSON string with Neo4j connection details.\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Tool\", name=\"output_tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        \"\"\"Execute the Cypher query and return the results as a message.\"\"\"\r\n        # Load Neo4j credentials\r\n        try:\r\n            credentials = json.loads(self.neo4j_credentials)\r\n            driver = GraphDatabase.driver(\r\n                credentials[\"url\"], \r\n                auth=(credentials[\"username\"], credentials[\"password\"])\r\n            )\r\n\r\n            with driver.session() as session:\r\n                results = session.run(self.cypher_query)\r\n\r\n                # Process results into a list of dictionaries\r\n                result_list = [\r\n                    {key: record.get(key) for key in record.keys()} \r\n                    for record in results\r\n                ]\r\n\r\n                # Convert results to DataFrame for easier viewing/logging (optional)\r\n                df = pd.DataFrame(result_list)\r\n                self.status = df.to_json(orient=\"records\")  # Status stores results as JSON string\r\n\r\n        except exceptions.CypherSyntaxError as e:\r\n            # Handle syntax errors in Cypher queries\r\n            self.status = f\"Invalid Cypher query: {str(e)}\"\r\n            return Message(text=f\"Invalid Cypher query: {str(e)}\")\r\n\r\n        except Exception as e:\r\n            # Handle other exceptions (e.g., connection errors)\r\n            self.status = f\"Error executing query: {str(e)}\"\r\n            return Message(text=f\"Error executing query: {str(e)}\")\r\n\r\n        finally:\r\n            # Ensure the driver is closed even if an error occurs\r\n            if 'driver' in locals():\r\n                driver.close()\r\n\r\n        # Return the results as a message\r\n        return Message(text=self.status)\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Builds the tool function for Langflow.\"\"\"\r\n        def query_executor(cypher_query: str, neo4j_credentials: str) -> str:\r\n            \"\"\"Execute the Cypher query and return results.\"\"\"\r\n            self.cypher_query = cypher_query\r\n            self.neo4j_credentials = neo4j_credentials\r\n            return self.build_output().text\r\n\r\n        # Return the tool, cast as required by Langflow\r\n        return cast(Tool, query_executor)\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "cypher_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cypher_query",
                "value": "",
                "display_name": "Cypher Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Cypher query to execute.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "JSON string with Neo4j connection details.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Execute Cypher queries on a Neo4j database.",
            "icon": "",
            "base_classes": [
              "Tool"
            ],
            "display_name": "GraphRAGRetrieverTool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cypher_query",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true
          },
          "id": "CollectiveTool-p4hG6"
        },
        "selected": false,
        "width": 384,
        "height": 378,
        "positionAbsolute": {
          "x": -4431.206647909941,
          "y": 1901.1837328607676
        },
        "dragging": false
      },
      {
        "id": "CollectiveTool-eeeQ3",
        "type": "genericNode",
        "position": {
          "x": -3843.2190181460915,
          "y": 1256.2555714042426
        },
        "data": {
          "type": "KnowledgeGraphIndexKRetrieverComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, cast, Union\r\nimport json\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nfrom neo4j import GraphDatabase\r\n\r\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.inputs import (\r\n    IntInput,\r\n    MessageTextInput,\r\n    DropdownInput,\r\n    SecretStrInput,\r\n)\r\n\r\nclass GraphVectorRetrieverTool(LCToolComponent):\r\n    display_name = \"Knowledge Graph Retriever\"\r\n    description = \"Retrieve top K results from Neo4j using vector similarity search.\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n    icon=\"\"\r\n    # Define inputs required by the component\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", display_name=\"Query\", info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4, required=True),\r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\"),\r\n    ]\r\n\r\n    def run_model(self) -> Union[List[Data], str]:\r\n        \"\"\"Executes the component logic and returns the results.\"\"\"\r\n        try:\r\n            # Load and parse Neo4j credentials\r\n            credentials = json.loads(self.neo4j_credentials)\r\n            driver = GraphDatabase.driver(\r\n                credentials[\"url\"], \r\n                auth=(credentials[\"username\"], credentials[\"password\"])\r\n            )\r\n\r\n            # Initialize OpenAI embeddings\r\n            embeddings = OpenAIEmbeddings(\r\n                api_key=self.openai_api_key,\r\n                model=self.openai_embedding_model,\r\n            )\r\n\r\n            # Initialize Neo4j Vector Search\r\n            vector_index = Neo4jVector.from_existing_graph(\r\n                embeddings,\r\n                search_type=\"hybrid\",\r\n                node_label=\"Document\",\r\n                text_node_properties=[\"text\"],\r\n                embedding_node_property=\"embedding\",\r\n                url=credentials[\"url\"],\r\n                username=credentials[\"username\"],\r\n                password=credentials[\"password\"],\r\n            )\r\n\r\n            # Execute the similarity search\r\n            results = vector_index.similarity_search(self.user_query, k=self.k)\r\n\r\n            # Convert results into Data objects for Langflow\r\n            data = [Data(data=result, text=result[\"text\"]) for result in results]\r\n            self.status = data\r\n            return data\r\n\r\n        except Exception as e:\r\n            self.status = f\"Error: {str(e)}\"\r\n            return f\"Error: {str(e)}\"\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Builds the tool for Langflow.\"\"\"\r\n        # Parse credentials\r\n        credentials = json.loads(self.neo4j_credentials)\r\n\r\n        # Initialize the embeddings and Neo4j vector search tool\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key, model=self.openai_embedding_model\r\n        )\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=\"Document\",\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n\r\n        # Return the tool, cast for Langflow compatibility\r\n        return cast(\r\n            Tool,\r\n            lambda query: vector_index.similarity_search(query, k=self.k),\r\n        )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "k": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "k",
                "value": 4,
                "display_name": "Number of results to return",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_embedding_model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_embedding_model",
                "value": "text-embedding-3-small",
                "display_name": "Embedding Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "user_query": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "User query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Retrieve top K results from Neo4j using vector similarity search.",
            "icon": "",
            "base_classes": [
              "Data",
              "Text",
              "Tool"
            ],
            "display_name": "GraphVectorRetrieverTool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data",
                  "Text"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "user_query",
              "k",
              "openai_embedding_model",
              "openai_api_key",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true
          },
          "id": "CollectiveTool-eeeQ3"
        },
        "selected": false,
        "width": 384,
        "height": 706,
        "dragging": false,
        "positionAbsolute": {
          "x": -3843.2190181460915,
          "y": 1256.2555714042426
        }
      },
      {
        "id": "Neo4jCredentialLoader-D6kdB",
        "type": "genericNode",
        "position": {
          "x": -4332.14846230714,
          "y": 1002.0638317776454
        },
        "data": {
          "type": "Neo4jCredentialLoader",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "neo4j_password": {
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_password",
                "value": "Neo4j Password",
                "display_name": "Neo4j Password",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_url",
                "value": "neo4j://jingconsult.tech:7687",
                "display_name": "Neo4j URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_username": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_username",
                "value": "neo4j",
                "display_name": "Neo4j Username",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "A handy component to load neo4j credentials",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Neo4j Credential Loader",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "credentials",
                "display_name": "Credentials",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "neo4j_url",
              "neo4j_username",
              "neo4j_password"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17",
            "official": false
          },
          "id": "Neo4jCredentialLoader-D6kdB"
        },
        "selected": false,
        "width": 384,
        "height": 467,
        "dragging": false,
        "positionAbsolute": {
          "x": -4332.14846230714,
          "y": 1002.0638317776454
        }
      },
      {
        "id": "CollectiveTool-N5nbH",
        "type": "genericNode",
        "position": {
          "x": -4317.720595152416,
          "y": 2353.8108751675377
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\nfrom crewai_tools import PGSearchTool\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(self) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "PGVectorTool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools"
            ],
            "beta": false,
            "edited": true
          },
          "id": "CollectiveTool-N5nbH"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "dragging": false,
        "positionAbsolute": {
          "x": -4317.720595152416,
          "y": 2353.8108751675377
        }
      },
      {
        "id": "CollectiveTool-NOeqq",
        "type": "genericNode",
        "position": {
          "x": -2849.1284097025464,
          "y": 1700.360664118603
        },
        "data": {
          "type": "CollectiveTool",
          "node": {
            "template": {
              "_type": "Component",
              "other_tools": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "other_tools",
                "value": "",
                "display_name": "Other tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Other tools (for grouping).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom crewai_tools import tool, BaseTool\r\nimport os\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\nfrom typing import List\r\nfrom langchain_community.vectorstores import PGVector\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom axiestudio.helpers.data import docs_to_data\r\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.utils.connection_string_parser import transform_connection_string\r\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\r\nimport psycopg2\r\nimport numpy as np\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\r\n            advanced=False,\r\n            value=\"OPENAI_API_KEY\",\r\n        ),\r\n        \r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    # @tool \r\n    # def PGSearchTool(input_string: str) -> str:\r\n    #     \"\"\"A tool that searches for top 5 results semantically related to the input string \r\n    #     in a postgres database table to find text using vector embedding similiarity search \r\n    #     that supports retrieval augmented generation (RAG)\"\"\"\r\n    #     conn = psycopg2.connect(\r\n    #         host=os.getenv(\"DB_HOST\"),\r\n    #         database=os.getenv(\"DB_NAME\"),\r\n    #         user=os.getenv(\"DB_USER\"),\r\n    #         password=os.getenv(\"DB_PASSWORD\")\r\n    #     )\r\n    #     cursor = conn.cursor()\r\n    #     embedding = OpenAIEmbeddings(\r\n    #         model=\"text-embedding-3-small\",\r\n    #         chunk_size=1000,\r\n    #         embedding_ctx_length=1536\r\n    #     )\r\n    #     search_vector = embedding.embed_query(str(input_string))\r\n    #     query = f\"\"\"\r\n    #         SELECT file_content\r\n    #         FROM embedding\r\n    #         ORDER BY vector <-> %s::vector\r\n    #         LIMIT 5;\r\n    #     \"\"\"\r\n        \r\n    #     cursor.execute(query, (search_vector,))\r\n    #     results = cursor.fetchall()\r\n    #     cursor.close()\r\n    #     conn.close()\r\n    #     return str(results[0])\r\n    \r\n    def build_output(self) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n        os.environ['OPENAI_API_KEY'] = self.api_key\r\n        class PGSearchTool(BaseTool):\r\n            name: str = \"pgvector postgres database retriever\"\r\n            description: str = \"A tool that searches for top 5 results semantically related to the input string \\\r\n            in a postgres database table to find text using vector embedding similarity search \\\r\n            that supports retrieval augmented generation (RAG)\"\r\n        \r\n            def _run(self, input_string: str) -> str:\r\n                print(\"Received string: \", input_string)\r\n                conn = psycopg2.connect(\r\n                    host=os.getenv(\"DB_HOST\"),\r\n                    database=os.getenv(\"DB_NAME\"),\r\n                    user=os.getenv(\"DB_USER\"),\r\n                    password=os.getenv(\"DB_PASSWORD\")\r\n                )\r\n                cursor = conn.cursor()\r\n                embedding = OpenAIEmbeddings(\r\n                    model=\"text-embedding-3-small\",\r\n                    chunk_size=1000,\r\n                    embedding_ctx_length=1536\r\n                )\r\n                search_vector = embedding.embed_query(str(input_string))\r\n                query = f\"\"\"\r\n                    SELECT file_content\r\n                    FROM embedding\r\n                    ORDER BY vector <-> %s::vector\r\n                    LIMIT 5;\r\n                \"\"\"\r\n                \r\n                cursor.execute(query, (search_vector,))\r\n                results = cursor.fetchall()\r\n                cursor.close()\r\n                conn.close()\r\n                return str(results[0])\r\n        tool = PGSearchTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\n# class PGSearchTool(BaseTool):\r\n#     name = \"PGSearchTool\"\r\n#     description = \"A tool that searches for top 5 results semantically related to the input string in a postgres database table to find text using vector embedding similiarity search that supports retrieval augmented generation (RAG)\"\r\n#     return_direct: bool = True\r\n#     def _run(self, intput_string: str) -> str:\r\n#         conn = psycopg2.connect(\r\n#                 host=\"localhost\", \r\n#                 database=\"ai_tutor\", \r\n#                 user=\"postgres\", \r\n#                 password=\"Jing_consult\"\r\n#             )\r\n#         cursor = conn.cursor()\r\n#         embedding = OpenAIEmbeddings(\r\n#             model = \"text-embedding-3-small\",\r\n#             chunk_size = 1000,\r\n#             embedding_ctx_length = 1536,\r\n#             api_key = \"sk-proj-NjiT0cmXcUaY8N2Ktd5CT3BlbkFJvpJm8LAqmLAIk79Pfq0X\"\r\n#             )\r\n#         search_vector = embedding.embed_query(str(input_string))\r\n#         query = \"\"\"\r\n#             SELECT file_content\r\n#             FROM embedding\r\n#             ORDER BY vector <-> %s::vector\r\n#             LIMIT 5;\r\n#         \"\"\"\r\n        \r\n#         cursor.execute(query, (search_vector))\r\n#         # Fetch the top results\r\n#         results = cursor.fetchall()\r\n#         cursor.close()\r\n#         conn.close()\r\n#         return str(results)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Template for creating a collection of tools for the agents",
            "icon": "custom_components",
            "base_classes": [
              "Tool"
            ],
            "display_name": "PGVectorTool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "output",
                "display_name": "Tools",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "other_tools",
              "api_key"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CollectiveTool-NOeqq"
        },
        "selected": false,
        "width": 384,
        "height": 372,
        "positionAbsolute": {
          "x": -2849.1284097025464,
          "y": 1700.360664118603
        },
        "dragging": false
      },
      {
        "id": "PythonCodeStructuredTool-kQm1H",
        "type": "genericNode",
        "position": {
          "x": -4661.265398733965,
          "y": 3104.1037216392783
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "Component",
              "_classes": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_classes",
                "value": "[]",
                "display_name": "Classes",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "_functions": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_functions",
                "value": "{}",
                "display_name": "Functions",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "global_variables": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "global_variables",
                "value": "",
                "display_name": "Global Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Enter the global variables or Create Data Component.",
                "title_case": false,
                "type": "dict",
                "_input_type": "HandleInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": false,
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tool_code": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "show": true,
                "name": "tool_code",
                "value": "",
                "display_name": "Tool Code",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "tool_description": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tool_function": {
                "trace_as_metadata": true,
                "options": [],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_function",
                "value": "",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "tool_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "",
                "display_name": "Tool Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "structuredtool dataclass code to tool",
            "icon": "",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Python Code Structured Tool",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "tool_code",
              "tool_name",
              "tool_description",
              "return_direct",
              "tool_function",
              "global_variables",
              "_classes",
              "_functions"
            ],
            "beta": false,
            "edited": false
          },
          "id": "PythonCodeStructuredTool-kQm1H"
        },
        "selected": false,
        "width": 384,
        "height": 706,
        "dragging": false
      },
      {
        "id": "HierarchicalCrewComponent-POt7U",
        "type": "genericNode",
        "position": {
          "x": -2762.6526676276767,
          "y": 3668.803306729951
        },
        "data": {
          "type": "HierarchicalCrewComponent",
          "node": {
            "template": {
              "_type": "Component",
              "agents": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agents",
                "value": "",
                "display_name": "Agents",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "function_calling_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "function_calling_llm",
                "value": "",
                "display_name": "Function Calling LLM",
                "advanced": true,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "manager_agent": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "manager_agent",
                "value": "",
                "display_name": "Manager Agent",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "manager_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "manager_llm",
                "value": "",
                "display_name": "Manager LLM",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tasks": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tasks",
                "value": "",
                "display_name": "Tasks",
                "advanced": false,
                "input_types": [
                  "HierarchicalTask"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent, Crew, Task, Process\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput, MessageTextInput\nfrom crewai_tools import BaseTool\nfrom langchain_openai import ChatOpenAI\nfrom langchain_openai.embeddings import OpenAIEmbeddings\nimport psycopg2\nfrom dotenv import load_dotenv\nimport os\nfrom langchain_community.vectorstores import Neo4jVector\nimport json\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\n    ]\n\n    def build_crew(self) -> Crew:\n        class PGSearchTool(BaseTool):\n            name: str = \"pgvector postgres database retriever\"\n            description: str = \"A tool that searches for top 5 results semantically related to the input string \\\n            in a postgres database table to find text using vector embedding similarity search \\\n            to support later retrieval augmented generation (RAG)\"\n            \n            def _run(self, input_string: str) -> str:\n                conn = psycopg2.connect(\n                    host=os.getenv(\"DB_HOST\"),\n                    database=os.getenv(\"DB_NAME\"),\n                    user=os.getenv(\"DB_USER\"),\n                    password=os.getenv(\"DB_PASSWORD\")\n                )\n                cursor = conn.cursor()\n                embedding = OpenAIEmbeddings(\n                    model=\"text-embedding-3-small\",\n                    chunk_size=1000,\n                    embedding_ctx_length=1536\n                )\n                search_vector = embedding.embed_query(str(input_string))\n                query = f\"\"\"\n                    SELECT file_content\n                    FROM embedding\n                    ORDER BY vector <-> %s::vector\n                    LIMIT 5;\n                \"\"\"\n                \n                cursor.execute(query, (search_vector,))\n                results = cursor.fetchall()\n                cursor.close()\n                conn.close()\n                return \",\".join([str(result) for result in results])\n        \n        \n        \n        class Neo4jSearchTool(BaseTool):\n            name: str = \"neo4j database vector retriever\"\n            description: str = \"A tool that searches for top 5 results semantically related to the input string \\\n            in a neo4j graph database to find text using vector embedding similarity search \\\n            to support later retrieval augmented generation (RAG)\"\n            k: int = 5\n            def _run(self, input_string: str) -> str:\n                embedding = OpenAIEmbeddings(\n                    model=\"text-embedding-3-small\",\n                    chunk_size=1000,\n                    embedding_ctx_length=1536\n                )\n                vector_index = Neo4jVector.from_existing_graph(\n                    embedding,\n                    search_type=\"hybrid\",\n                    node_label=\"Document\",\n                    text_node_properties=[\"text\"],\n                    embedding_node_property=\"embedding\",\n                    url=os.getenv(\"NEO4J_URL\"),\n                    username=os.getenv(\"NEO4J_NAME\"),\n                    password=os.getenv(\"NEO4J_PASSWORD\")\n                )\n                results = vector_index.similarity_search(input_string, k=self.k)\n                # parse: to keep source document name, page number, and content\n                documents = []\n                for document in results:\n                    documents.append(\n                        {\n                            \"source_document\": os.path.splitext(os.path.basename(document.metadata.get(\"source\")))[0],\n                            \"source_page\": document.metadata.get(\"page\"),\n                            \"page_content\": document.page_content\n                        }\n                    )\n                \n                return json.dumps(documents)\n        \n        # Initialise tools\n        pg_search_tool = PGSearchTool()\n        neo4j_search_tool = Neo4jSearchTool()\n        agent = Agent(\n            role=\"database RAG helper\",\n            goal=\"Find semantically related text to support the generation of answer for user's question.\",\n            backstory=\"You are a RAG helper that can retrieve the most semantically relevant content from \\\n            a database using embedding vector similarity search. When you give answers, only generate answer \\\n            based on the retrieved content and always present the source of them from the data. You have tools \\\n            which can accept a string as the input to perform similarity serach from the \\\n            existing databases. You should try all available tools and evaluate results from them then return answer.\",\n            verbose=True,\n            llm=ChatOpenAI(\n                model=os.getenv(\"OPENAI_MODEL\"),\n                temperature=float(os.getenv(\"OPENAI_TEMPERATURE\", \"0.1\")),\n            ),\n            tools=[neo4j_search_tool, pg_search_tool]\n        )\n        \n        \n        # Define the task\n        task = Task(\n            description=\"User: Tell me how to build a knowledge graph?\\\n            Respond to the user with as much as information as you can about the topic. \\\n            Always delegate the tasks to agents and compose answers based on the results\",\n            expected_output = \"Succinct response that answers the User's query.\"\n        )\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_rpm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_rpm",
                "value": 100,
                "display_name": "Max RPM",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": false,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "share_crew": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "share_crew",
                "value": false,
                "display_name": "Share Crew",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "use_cache": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_cache",
                "value": true,
                "display_name": "Cache",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": 0,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "icon": "CrewAI",
            "base_classes": [
              "Message"
            ],
            "display_name": "Hierarchical Crew",
            "documentation": "https://docs.crewai.com/how-to/Hierarchical/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "verbose",
              "memory",
              "use_cache",
              "max_rpm",
              "share_crew",
              "function_calling_llm",
              "agents",
              "tasks",
              "manager_llm",
              "manager_agent",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true
          },
          "id": "HierarchicalCrewComponent-POt7U"
        },
        "selected": true,
        "width": 384,
        "height": 542,
        "positionAbsolute": {
          "x": -2762.6526676276767,
          "y": 3668.803306729951
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "OpenAIModel-pF8ma",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:manager_llm,id:HierarchicalCrewComponent-POopw,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "manager_llm",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pF8ma",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-HierarchicalCrewComponent-POopw{fieldName:manager_llm,id:HierarchicalCrewComponent-POopw,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "RetrieverTool-ijoHS",
        "sourceHandle": "{dataType:CollectiveTool,id:RetrieverTool-ijoHS,name:output,output_types:[Tool]}",
        "target": "CrewAIAgentComponent-RJKKD",
        "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-RJKKD,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-RJKKD",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "RetrieverTool-ijoHS",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-RetrieverTool-ijoHS{dataType:CollectiveTool,id:RetrieverTool-ijoHS,name:output,output_types:[Tool]}-CrewAIAgentComponent-RJKKD{fieldName:tools,id:CrewAIAgentComponent-RJKKD,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "HierarchicalTaskComponent-fh9Vr",
        "sourceHandle": "{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-fh9Vr,name:task_output,output_types:[HierarchicalTask]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:tasks,id:HierarchicalCrewComponent-POopw,inputTypes:[HierarchicalTask],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tasks",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "HierarchicalTask"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "HierarchicalTaskComponent",
            "id": "HierarchicalTaskComponent-fh9Vr",
            "name": "task_output",
            "output_types": [
              "HierarchicalTask"
            ]
          }
        },
        "id": "reactflow__edge-HierarchicalTaskComponent-fh9Vr{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-fh9Vr,name:task_output,output_types:[HierarchicalTask]}-HierarchicalCrewComponent-POopw{fieldName:tasks,id:HierarchicalCrewComponent-POopw,inputTypes:[HierarchicalTask],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-GGaIt",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-GGaIt,name:output,output_types:[Tool]}",
        "target": "CollectiveTool-iGp6D",
        "targetHandle": "{fieldName:other_tools,id:CollectiveTool-iGp6D,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "other_tools",
            "id": "CollectiveTool-iGp6D",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-GGaIt",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-GGaIt{dataType:CollectiveTool,id:CollectiveTool-GGaIt,name:output,output_types:[Tool]}-CollectiveTool-iGp6D{fieldName:other_tools,id:CollectiveTool-iGp6D,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-wBeSt",
        "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-wBeSt,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:manager_agent,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "manager_agent",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-wBeSt",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-wBeSt{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-wBeSt,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:manager_agent,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveCrewAIAgentComponent-g95En",
        "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-g95En,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveCrewAIAgentComponent",
            "id": "CollectiveCrewAIAgentComponent-g95En",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveCrewAIAgentComponent-g95En{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-g95En,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-iGp6D",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-iGp6D,name:output,output_types:[Tool]}",
        "target": "CollectiveTool-8jGBc",
        "targetHandle": "{fieldName:other_tools,id:CollectiveTool-8jGBc,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "other_tools",
            "id": "CollectiveTool-8jGBc",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-iGp6D",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-iGp6D{dataType:CollectiveTool,id:CollectiveTool-iGp6D,name:output,output_types:[Tool]}-CollectiveTool-8jGBc{fieldName:other_tools,id:CollectiveTool-8jGBc,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-8jGBc",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-8jGBc,name:output,output_types:[Tool]}",
        "target": "CollectiveTool-wx20I",
        "targetHandle": "{fieldName:other_tools,id:CollectiveTool-wx20I,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "other_tools",
            "id": "CollectiveTool-wx20I",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-8jGBc",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-8jGBc{dataType:CollectiveTool,id:CollectiveTool-8jGBc,name:output,output_types:[Tool]}-CollectiveTool-wx20I{fieldName:other_tools,id:CollectiveTool-wx20I,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-wx20I",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}",
        "target": "CollectiveCrewAIAgentComponent-JhWL3",
        "targetHandle": "{fieldName:tools,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CollectiveCrewAIAgentComponent-JhWL3",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-wx20I",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-wx20I{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}-CollectiveCrewAIAgentComponent-JhWL3{fieldName:tools,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-wx20I",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}",
        "target": "CollectiveCrewAIAgentComponent-gsrJN",
        "targetHandle": "{fieldName:tools,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CollectiveCrewAIAgentComponent-gsrJN",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-wx20I",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-wx20I{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}-CollectiveCrewAIAgentComponent-gsrJN{fieldName:tools,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-wx20I",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}",
        "target": "CollectiveTool-vMdr2",
        "targetHandle": "{fieldName:other_tools,id:CollectiveTool-vMdr2,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "other_tools",
            "id": "CollectiveTool-vMdr2",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-wx20I",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-wx20I{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}-CollectiveTool-vMdr2{fieldName:other_tools,id:CollectiveTool-vMdr2,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveTool-vMdr2",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-vMdr2,name:output,output_types:[Tool]}",
        "target": "CollectiveCrewAIAgentComponent-g95En",
        "targetHandle": "{fieldName:tools,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CollectiveCrewAIAgentComponent-g95En",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-vMdr2",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-vMdr2{dataType:CollectiveTool,id:CollectiveTool-vMdr2,name:output,output_types:[Tool]}-CollectiveCrewAIAgentComponent-g95En{fieldName:tools,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[Tool],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-pF8ma",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
        "target": "CrewAIAgentComponent-RJKKD",
        "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-RJKKD,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-RJKKD",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pF8ma",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-RJKKD{fieldName:llm,id:CrewAIAgentComponent-RJKKD,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-pF8ma",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
        "target": "CollectiveCrewAIAgentComponent-JhWL3",
        "targetHandle": "{fieldName:llm,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CollectiveCrewAIAgentComponent-JhWL3",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pF8ma",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CollectiveCrewAIAgentComponent-JhWL3{fieldName:llm,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-pF8ma",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
        "target": "CollectiveCrewAIAgentComponent-gsrJN",
        "targetHandle": "{fieldName:llm,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CollectiveCrewAIAgentComponent-gsrJN",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pF8ma",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CollectiveCrewAIAgentComponent-gsrJN{fieldName:llm,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-pF8ma",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
        "target": "CollectiveCrewAIAgentComponent-g95En",
        "targetHandle": "{fieldName:llm,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CollectiveCrewAIAgentComponent-g95En",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pF8ma",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CollectiveCrewAIAgentComponent-g95En{fieldName:llm,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-pF8ma",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
        "target": "CrewAIAgentComponent-wBeSt",
        "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-wBeSt,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-wBeSt",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pF8ma",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-wBeSt{fieldName:llm,id:CrewAIAgentComponent-wBeSt,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveCrewAIAgentComponent-gsrJN",
        "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-gsrJN,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveCrewAIAgentComponent",
            "id": "CollectiveCrewAIAgentComponent-gsrJN",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveCrewAIAgentComponent-gsrJN{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-gsrJN,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "className": ""
      },
      {
        "source": "CollectiveCrewAIAgentComponent-JhWL3",
        "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-JhWL3,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveCrewAIAgentComponent",
            "id": "CollectiveCrewAIAgentComponent-JhWL3",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveCrewAIAgentComponent-JhWL3{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-JhWL3,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-RJKKD",
        "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CrewAIAgentComponent-RJKKD,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-POopw",
        "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-POopw",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveCrewAIAgentComponent",
            "id": "CrewAIAgentComponent-RJKKD",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-RJKKD{dataType:CollectiveCrewAIAgentComponent,id:CrewAIAgentComponent-RJKKD,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
        "className": ""
      },
      {
        "source": "HierarchicalTaskComponent-Vezqe",
        "sourceHandle": "{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-Vezqe,name:task_output,output_types:[HierarchicalTask]}",
        "target": "HierarchicalCrewComponent-8R2Ak",
        "targetHandle": "{fieldName:tasks,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[HierarchicalTask],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tasks",
            "id": "HierarchicalCrewComponent-8R2Ak",
            "inputTypes": [
              "HierarchicalTask"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "HierarchicalTaskComponent",
            "id": "HierarchicalTaskComponent-Vezqe",
            "name": "task_output",
            "output_types": [
              "HierarchicalTask"
            ]
          }
        },
        "id": "reactflow__edge-HierarchicalTaskComponent-Vezqe{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-Vezqe,name:task_output,output_types:[HierarchicalTask]}-HierarchicalCrewComponent-8R2Ak{fieldName:tasks,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[HierarchicalTask],type:other}",
        "className": ""
      },
      {
        "source": "Prompt-phlF8",
        "sourceHandle": "{dataType:Prompt,id:Prompt-phlF8,name:prompt,output_types:[Message]}",
        "target": "HierarchicalTaskComponent-Vezqe",
        "targetHandle": "{fieldName:task_description,id:HierarchicalTaskComponent-Vezqe,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "task_description",
            "id": "HierarchicalTaskComponent-Vezqe",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-phlF8",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-phlF8{dataType:Prompt,id:Prompt-phlF8,name:prompt,output_types:[Message]}-HierarchicalTaskComponent-Vezqe{fieldName:task_description,id:HierarchicalTaskComponent-Vezqe,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "OpenAIModel-svPsH",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-svPsH,name:model_output,output_types:[LanguageModel]}",
        "target": "CrewAIAgentComponent-Uq7Oe",
        "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-Uq7Oe",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-svPsH",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-svPsH{dataType:OpenAIModel,id:OpenAIModel-svPsH,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-Uq7Oe{fieldName:llm,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-Uq7Oe",
        "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Uq7Oe,name:output,output_types:[Agent]}",
        "target": "HierarchicalCrewComponent-8R2Ak",
        "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[Agent],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-8R2Ak",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-Uq7Oe",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-Uq7Oe{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Uq7Oe,name:output,output_types:[Agent]}-HierarchicalCrewComponent-8R2Ak{fieldName:agents,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[Agent],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-XHQqk",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-XHQqk,name:model_output,output_types:[LanguageModel]}",
        "target": "HierarchicalCrewComponent-8R2Ak",
        "targetHandle": "{fieldName:manager_llm,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "manager_llm",
            "id": "HierarchicalCrewComponent-8R2Ak",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-XHQqk",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-XHQqk{dataType:OpenAIModel,id:OpenAIModel-XHQqk,name:model_output,output_types:[LanguageModel]}-HierarchicalCrewComponent-8R2Ak{fieldName:manager_llm,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-D6kdB",
        "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-D6kdB,name:credentials,output_types:[Message]}",
        "target": "CollectiveTool-eeeQ3",
        "targetHandle": "{fieldName:neo4j_credentials,id:CollectiveTool-eeeQ3,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "CollectiveTool-eeeQ3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-D6kdB",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-D6kdB{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-D6kdB,name:credentials,output_types:[Message]}-CollectiveTool-eeeQ3{fieldName:neo4j_credentials,id:CollectiveTool-eeeQ3,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "CollectiveTool-NOeqq",
        "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-NOeqq,name:output,output_types:[Tool]}",
        "target": "CrewAIAgentComponent-Uq7Oe",
        "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-Uq7Oe",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CollectiveTool",
            "id": "CollectiveTool-NOeqq",
            "name": "output",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CollectiveTool-NOeqq{dataType:CollectiveTool,id:CollectiveTool-NOeqq,name:output,output_types:[Tool]}-CrewAIAgentComponent-Uq7Oe{fieldName:tools,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[Tool],type:other}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 2637.1470701313647,
      "y": -2190.907707398952,
      "zoom": 0.7073444639023024
    }
  },
  "metadata": {
    "HierarchicalCrewComponent": {
      "count": 3
    },
    "OpenAIModel": {
      "count": 4
    },
    "CrewAIAgentComponent": {
      "count": 3
    },
    "RetrieverTool": {
      "count": 1
    },
    "CollectiveCrewAIAgentComponent": {
      "count": 6
    },
    "HierarchicalTaskComponent": {
      "count": 2
    },
    "CollectiveTool": {
      "count": 9
    },
    "ChatInput": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "Neo4jCredentialLoader": {
      "count": 1
    },
    "PythonCodeStructuredTool": {
      "count": 1
    },
    "total": 33
  },
  "original": {
    "id": "f94bee55-a13f-4a72-8777-eed20ec0e2f4",
    "name": "[Dev] Agent Deve and Testing",
    "description": "This Agent runs tasks in a predefined sequence.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "HierarchicalCrewComponent": {
        "count": 3
      },
      "OpenAIModel": {
        "count": 4
      },
      "CrewAIAgentComponent": {
        "count": 3
      },
      "RetrieverTool": {
        "count": 1
      },
      "CollectiveCrewAIAgentComponent": {
        "count": 6
      },
      "HierarchicalTaskComponent": {
        "count": 2
      },
      "CollectiveTool": {
        "count": 9
      },
      "ChatInput": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "Neo4jCredentialLoader": {
        "count": 1
      },
      "PythonCodeStructuredTool": {
        "count": 1
      },
      "total": 33
    },
    "last_tested_version": "1.0.17",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "HierarchicalCrewComponent-POopw",
          "type": "genericNode",
          "position": {
            "x": -964.7290554289862,
            "y": -790.743116515845
          },
          "data": {
            "type": "HierarchicalCrewComponent",
            "node": {
              "template": {
                "_type": "Component",
                "agents": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "agents",
                  "value": "",
                  "display_name": "Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "function_calling_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "function_calling_llm",
                  "value": "",
                  "display_name": "Function Calling LLM",
                  "advanced": true,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "manager_agent": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "manager_agent",
                  "value": "",
                  "display_name": "Manager Agent",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "manager_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "manager_llm",
                  "value": "",
                  "display_name": "Manager LLM",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tasks": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tasks",
                  "value": "",
                  "display_name": "Tasks",
                  "advanced": false,
                  "input_types": [
                    "HierarchicalTask"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "max_rpm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_rpm",
                  "value": 100,
                  "display_name": "Max RPM",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": false,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "share_crew": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "share_crew",
                  "value": false,
                  "display_name": "Share Crew",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "use_cache": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "use_cache",
                  "value": true,
                  "display_name": "Cache",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": 0,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                }
              },
              "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
              "icon": "CrewAI",
              "base_classes": [
                "Message"
              ],
              "display_name": "Hierarchical Crew",
              "documentation": "https://docs.crewai.com/how-to/Hierarchical/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "verbose",
                "memory",
                "use_cache",
                "max_rpm",
                "share_crew",
                "function_calling_llm",
                "agents",
                "tasks",
                "manager_llm",
                "manager_agent"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "HierarchicalCrewComponent-POopw"
          },
          "selected": false,
          "width": 384,
          "height": 454,
          "positionAbsolute": {
            "x": -964.7290554289862,
            "y": -790.743116515845
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-pF8ma",
          "type": "genericNode",
          "position": {
            "x": -3644.7966003082533,
            "y": -2689.3158975577467
          },
          "data": {
            "id": "OpenAIModel-pF8ma",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "lf_version": "1.0.17",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "_input_type": "SecretStrInput",
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-4o-mini"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              }
            },
            "type": "OpenAIModel"
          },
          "selected": false,
          "width": 384,
          "height": 597,
          "positionAbsolute": {
            "x": -3644.7966003082533,
            "y": -2689.3158975577467
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-RJKKD",
          "type": "genericNode",
          "position": {
            "x": -2805.583462867302,
            "y": -1316.614108992988
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": true,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "User Interest Acquire Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CrewAIAgentComponent-RJKKD"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "positionAbsolute": {
            "x": -2805.583462867302,
            "y": -1316.614108992988
          },
          "dragging": false
        },
        {
          "id": "RetrieverTool-ijoHS",
          "type": "genericNode",
          "position": {
            "x": -5157.337458282449,
            "y": -846.4474784579469
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "GetSubdomains",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "RetrieverTool-ijoHS"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "positionAbsolute": {
            "x": -5157.337458282449,
            "y": -846.4474784579469
          },
          "dragging": false
        },
        {
          "id": "CollectiveCrewAIAgentComponent-JhWL3",
          "type": "genericNode",
          "position": {
            "x": -2704.034298468254,
            "y": -420.778431614837
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": true,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "You are a knowledgeable, socratic, kind, empathetic, psychology-degree attained K-12 educational counsellor. You will proactively facilitate and scaffold with the student {user} in conversations to foreground their learning interests and be very attentive to the conversational {sentiment} and extract knowledge domain keywords, making reflective notes to {user_profile} about any tentative learning project plan, critical path or learning path that may be applied to the generation of a committed learning {project} with personalized {learning_module}.   ",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "To elicit genuine learning interest and logging the potential relevance to the domain knowledge and subject matter. Update to {user_profile}, {learning interest}, record {chat}, {conversation}, forward {learning interest}, domain knowledge, subject matter to Agent 2",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "Counsellor",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Learning Module Generation Domain",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveCrewAIAgentComponent-JhWL3"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "positionAbsolute": {
            "x": -2704.034298468254,
            "y": -420.778431614837
          },
          "dragging": false
        },
        {
          "id": "CollectiveCrewAIAgentComponent-gsrJN",
          "type": "genericNode",
          "position": {
            "x": -1833.1416795636735,
            "y": -433.4566697111805
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": true,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "You are a scrupulous project planner who is very conscious about the timeline, scope, and the resource constraints by which a project is scheduled. You acknowledge the users {learning interest} and research on the related domain knowledge and subject matter by synthesizing the cross domain GraphDB search results (cypher query and llm combined to infer) with the project plan. With this synthesis, you will then present a draft of the project-based {learning module} for the {user} to consent. The draft is usually formatted with the following signposts (by their semantic meanings): \n1. **Project Management (pm) Set:**\n- I. Project Fundamentals\n    \n    A. Project Scope\n    B. Project Plan\n    C. Timeline\n    D. Budget\n    \n- II. Project Structure\n    \n    A. Work Breakdown Structure\n    B. Task\n    C. Milestone\n    D. Deliverable\n    E. Dependency\n    F. Critical Path\n    \n- III. Project Execution\n    \n    A. Prototyping\n    B. Schedule\n    C. Resource\n    D. Gantt\n    \n- IV. Project Management\n    \n    A. Change Management\n    B. Change Request\n    C. Risk\n    D. Issue\n    \n- V. People\n    \n    A. Stakeholder\n    B. Team Member\n    C. Project Manager\n    D. Team Lead\n    E. Subject Matter Expert\n    F. Technical Champion\n    G. Domain Knowledge\n    \n1. **Learning Module (lm) Set:**\n- I. Learning Structure\n    \n    A. Learning Path\n    B. Learning Module\n    C. Course\n    D. Training\n    E. Study Plan\n    F. Study Outline\n    G. Learning Activity\n    H. Learning Task\n    I. Self-directed Learning\n    J. Dojo\n    \n- II. Learning Roles\n    \n    A. Instructor\n    B. Facilitator\n    C. Mentor\n    D. Learning Companion\n    \n- III. Learning Characteristics\n    \n    A. Cross Domain\n    B. Inter-Domain\n    C. Knowledge Area\n    \n- IV. Learning Logistics\n    \n    A. Duration\n    \n- V. Learning Assessment\n    \n    A. Assessment\n    B. Marking\n    C. Score\n    D. Learning Feedback\n    E. Achievement\n    F. Certificate\n    G. Learning Outcome\n    \n- VI. Learning Management\n    \n    A. Learning Content Adjustment\n    \n1. **Integrated Project Plan with Learning Module:**\n- I. Project Fundamentals\n    - A. Project Scope\n        \n        1. Learning Path definition\n        2. Cross Domain / Inter-Domain integration\n        \n    - B. Project Plan\n        \n        1. Learning Module structure\n        2. Course and Training outline\n        3. Study Plan and Outline development\n        \n    - C. Timeline\n        \n        1. Overall project duration\n        2. Individual module durations\n        \n    - D. Budget\n        \n        1. Learning resources allocation\n        2. Instructor/Facilitator costs\n        \n- II. Project Structure\n    - A. Work Breakdown Structure\n        \n        1. Learning Path breakdown\n        2. Module-specific tasks\n        3. Learning Activities and Tasks design\n        \n    - B. Tasks\n        \n        1. Content development\n        2. Cross-domain integration activities\n        3. Self-directed Learning components\n        \n    - C. Milestones\n        \n        1. Module completion points\n        2. Cross-domain integration checkpoints\n        3. Dojo establishment and implementation\n        \n    - D. Deliverables\n        \n        1. Learning materials\n        2. Cross-domain knowledge artifacts\n        3. Assessment tools and rubrics\n        \n    - E. Dependencies\n        \n        1. Inter-module dependencies\n        2. Cross-domain knowledge prerequisites\n        \n    - F. Critical Path\n        \n        1. Essential learning sequence\n        2. Key cross-domain integration points\n        \n- III. Project Execution\n    - A. Prototyping\n        \n        1. Sample learning modules\n        2. Cross-domain integration examples\n        \n    - B. Schedule\n        \n        1. Module development timeline\n        2. Training session scheduling\n        3. Assessment and feedback cycles\n        \n    - C. Resource Allocation\n        \n        1. Instructors and Facilitators\n        2. Learning materials and platforms\n        3. Learning Companions assignment\n        \n    - D. Gantt Chart\n        \n        1. Visual representation of learning path\n        2. Cross-domain integration points\n        3. Assessment and feedback milestones\n        \n- IV. Project Management\n    - A. Change Management\n        \n        1. Adapting learning content\n        2. Updating cross-domain connections\n        3. Learning Content Adjustment process\n        \n    - B. Change Requests\n        \n        1. Module content adjustments\n        2. Cross-domain integration refinements\n        3. Assessment method revisions\n        \n    - C. Risk Management\n        \n        1. Learning effectiveness risks\n        2. Cross-domain integration challenges\n        3. Self-directed learning support risks\n        \n    - D. Issue Tracking\n        \n        1. Learning obstacles\n        2. Cross-domain misalignments\n        \n        3. Feedback implementation issues\n        \n- V. People and Roles\n    - A. Stakeholders\n        \n        1. Learners\n        2. Organizational leadership\n        \n    - B. Team Members\n        \n        1. Content developers\n        2. Cross-domain experts\n        3. Assessment designers\n        \n    - C. Project Manager\n        \n        1. Overall learning path management\n        2. Cross-domain integration oversight\n        3. Learning outcome monitoring\n        \n    - D. Team Lead\n        \n        1. Module development lead\n        2. Cross-domain integration lead\n        3. Learning Activity coordination\n        \n    - E. Subject Matter Experts\n        \n        1. Domain-specific knowledge providers\n        2. Cross-domain connection advisors\n        \n    - F. Technical Champion\n        \n        1. Learning platform specialist\n        2. Cross-domain tools expert\n        3. Dojo technical support\n        \n    - G. Instructors/Facilitators\n        \n        1. Module-specific instructors\n        2. Cross-domain integration facilitators\n        3. Learning feedback providers\n        \n    - H. Mentors\n        \n        1. Learner support\n        2. Cross-domain navigation guidance\n        3. Self-directed learning assistance\n        \n- VI. Knowledge Management\n    - A. Domain Knowledge\n        \n        1. Core subject areas\n        2. Cross-domain intersections\n        \n    - B. Knowledge Area Mapping\n        \n        1. Identifying key knowledge areas\n        2. Mapping cross-domain connections\n        \n    - C. Learning Outcome Tracking\n        \n        1. Achievement monitoring\n        2. Certificate issuance\n        3. Score analysis and reporting\n        \n- VII. Learning Assessment and Feedback\n    - A. Assessment Strategy\n        \n        1. Assessment design and implementation\n        2. Marking criteria development\n        \n    - B. Feedback Mechanism\n        \n        1. Learning feedback loops\n        2. Continuous improvement process\n        \n    - C. Performance Evaluation\n        \n        1. Score tracking and analysis\n        2. Learning outcome measurement\n        \n    - D. Recognition System\n        \n        1. Achievement acknowledgment\n        2. Certificate design and distribution\n        \n\nThis hierarchical structure clearly delineates the different levels and relationships within each set and in the integrated project plan.",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "Listening to the {user} and the input from Agent 1, draft a project plan with the templated learning module for project commitment.",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "Project Planner",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Project Planner",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveCrewAIAgentComponent-gsrJN"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "positionAbsolute": {
            "x": -1833.1416795636735,
            "y": -433.4566697111805
          },
          "dragging": false
        },
        {
          "id": "HierarchicalTaskComponent-fh9Vr",
          "type": "genericNode",
          "position": {
            "x": -4352.296232112481,
            "y": -226.51196401892486
          },
          "data": {
            "type": "HierarchicalTaskComponent",
            "node": {
              "template": {
                "_type": "Component",
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": true,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "expected_output": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "expected_output",
                  "value": "",
                  "display_name": "Expected Output",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Clear definition of expected task outcome.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "task_description": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "task_description",
                  "value": "",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Descriptive text detailing task's purpose and execution.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Each task must have a description, an expected output and an agent responsible for execution.",
              "icon": "CrewAI",
              "base_classes": [
                "HierarchicalTask"
              ],
              "display_name": "Hierarchical Task",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "HierarchicalTask"
                  ],
                  "selected": "HierarchicalTask",
                  "name": "task_output",
                  "display_name": "Task",
                  "method": "build_task",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "task_description",
                "expected_output",
                "tools"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "HierarchicalTaskComponent-fh9Vr"
          },
          "selected": false,
          "width": 384,
          "height": 406,
          "positionAbsolute": {
            "x": -4352.296232112481,
            "y": -226.51196401892486
          },
          "dragging": false
        },
        {
          "id": "CollectiveTool-iGp6D",
          "type": "genericNode",
          "position": {
            "x": -3774.2421303749106,
            "y": -1804.7580492303775
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Vector Search Tool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveTool-iGp6D"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "dragging": false,
          "positionAbsolute": {
            "x": -3774.2421303749106,
            "y": -1804.7580492303775
          }
        },
        {
          "id": "CollectiveTool-GGaIt",
          "type": "genericNode",
          "position": {
            "x": -4429.396359772079,
            "y": -1825.6300716360774
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Graph Search Tool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveTool-GGaIt"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "positionAbsolute": {
            "x": -4429.396359772079,
            "y": -1825.6300716360774
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-wBeSt",
          "type": "genericNode",
          "position": {
            "x": -181.4317707745172,
            "y": 70.33134873875764
          },
          "data": {
            "type": "CrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": true,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Manage how model responds",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Manager Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agent",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "CrewAIAgentComponent-wBeSt"
          },
          "selected": false,
          "width": 384,
          "height": 631,
          "positionAbsolute": {
            "x": -181.4317707745172,
            "y": 70.33134873875764
          },
          "dragging": false
        },
        {
          "id": "CollectiveCrewAIAgentComponent-g95En",
          "type": "genericNode",
          "position": {
            "x": -1775.1348717591247,
            "y": -1326.339236884657
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": true,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "You are the project gate-keeper, you are to monitor, assess, manage, and report the project development and the learning progress to {user}, {human tutor}, and {parent}. \n\nYou will attentively spot any **STAGNATION** in the project and learning progress, and proactively advise {user} of any adjustment or amendment to the **project plan** or **learning module** accordingly.",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "Abide to the committed project plan and learning module provided by Agent 2. Spot any STAGNATION or lag in the project timeline, tasks, learning activities and assessment. Adjust or amend to the project plan and learning module as per advised and required scenario arises with the {user}. Generate learning progress/performance report to {user}, {human tutor}, and {parent}",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "Project Warden",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Project Warden",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "official": false,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveCrewAIAgentComponent-g95En"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "dragging": false,
          "positionAbsolute": {
            "x": -1775.1348717591247,
            "y": -1326.339236884657
          }
        },
        {
          "id": "CollectiveTool-8jGBc",
          "type": "genericNode",
          "position": {
            "x": -2912.1575914537902,
            "y": -1843.1326669753314
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "User Profile Tool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveTool-8jGBc"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "positionAbsolute": {
            "x": -2912.1575914537902,
            "y": -1843.1326669753314
          },
          "dragging": false
        },
        {
          "id": "CollectiveTool-wx20I",
          "type": "genericNode",
          "position": {
            "x": -2297.7077035243124,
            "y": -1821.5309131028107
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Cypher Generation Tool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveTool-wx20I"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "positionAbsolute": {
            "x": -2297.7077035243124,
            "y": -1821.5309131028107
          },
          "dragging": false
        },
        {
          "id": "CollectiveTool-vMdr2",
          "type": "genericNode",
          "position": {
            "x": -1614.45754968375,
            "y": -1842.0785765508965
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(\r\n        self\r\n    ) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "AI-tutor Report",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveTool-vMdr2"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "positionAbsolute": {
            "x": -1614.45754968375,
            "y": -1842.0785765508965
          },
          "dragging": false
        },
        {
          "id": "ChatInput-Cg9n0",
          "type": "genericNode",
          "position": {
            "x": -3461.985148738744,
            "y": 3751.0755651282143
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "Based on your knowledge stored in the postgres database, tell me how to build a knowledge graph?",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatInput-Cg9n0"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": -3461.985148738744,
            "y": 3751.0755651282143
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-jr4bG",
          "type": "genericNode",
          "position": {
            "x": -2222.7968878390807,
            "y": 3722.2657082079704
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatOutput-jr4bG"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": -2222.7968878390807,
            "y": 3722.2657082079704
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-svPsH",
          "type": "genericNode",
          "position": {
            "x": -3402.1507837367276,
            "y": 1938.6699868253643
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-svPsH"
          },
          "selected": false,
          "width": 384,
          "height": 597,
          "positionAbsolute": {
            "x": -3402.1507837367276,
            "y": 1938.6699868253643
          },
          "dragging": false
        },
        {
          "id": "HierarchicalCrewComponent-8R2Ak",
          "type": "genericNode",
          "position": {
            "x": -1212.85292424607,
            "y": 2547.644519729222
          },
          "data": {
            "type": "HierarchicalCrewComponent",
            "node": {
              "template": {
                "_type": "Component",
                "agents": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "agents",
                  "value": "",
                  "display_name": "Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "function_calling_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "function_calling_llm",
                  "value": "",
                  "display_name": "Function Calling LLM",
                  "advanced": true,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "manager_agent": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "manager_agent",
                  "value": "",
                  "display_name": "Manager Agent",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "manager_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "manager_llm",
                  "value": "",
                  "display_name": "Manager LLM",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tasks": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tasks",
                  "value": "",
                  "display_name": "Tasks",
                  "advanced": false,
                  "input_types": [
                    "HierarchicalTask"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            planning=True\n        )\n        return crew\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "max_rpm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_rpm",
                  "value": 100,
                  "display_name": "Max RPM",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": false,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "share_crew": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "share_crew",
                  "value": false,
                  "display_name": "Share Crew",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "use_cache": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "use_cache",
                  "value": false,
                  "display_name": "Cache",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput",
                  "load_from_db": false
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": 0,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                }
              },
              "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
              "icon": "CrewAI",
              "base_classes": [
                "Message"
              ],
              "display_name": "Hierarchical Crew",
              "documentation": "https://docs.crewai.com/how-to/Hierarchical/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "verbose",
                "memory",
                "use_cache",
                "max_rpm",
                "share_crew",
                "function_calling_llm",
                "agents",
                "tasks",
                "manager_llm",
                "manager_agent"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "HierarchicalCrewComponent-8R2Ak"
          },
          "selected": false,
          "width": 384,
          "height": 454,
          "positionAbsolute": {
            "x": -1212.85292424607,
            "y": 2547.644519729222
          },
          "dragging": false
        },
        {
          "id": "CollectiveCrewAIAgentComponent-1z0Y8",
          "type": "genericNode",
          "position": {
            "x": -3263.3235794380553,
            "y": 924.8049991559969
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": false,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "You are an ontology warden who holds the ontology structure of knowledge domains.\n\n## 1. Mathematics and Statistics\n\n- Mathematics_PureMath\n- Mathematics_AppliedMath\n- Mathematics_Statistics\n\n## 2. Natural Sciences\n\n- NaturalSciences_Physics\n- NaturalSciences_Chemistry\n- NaturalSciences_Biology\n- NaturalSciences_EarthSciences\n\n## 3. Social Sciences\n\n- SocialSciences_Psychology\n- SocialSciences_SociologyAnthropology\n- SocialSciences_Economics\n- SocialSciences_PoliticalScience\n- SocialSciences_CommunicationMedia\n\n## 4. Humanities\n\n- Humanities_Philosophy\n- Humanities_Linguistics\n\n## 5. Business and Management\n\n- Business_Strategy\n- Business_Marketing\n\n## 6. Education\n\n- Education_GeneralEducation\n- Education_LiteracyWriting\n\n## 7. Applied Sciences and Engineering\n\n- AppliedSciences_ComputerScience\n- AppliedSciences_FoodScience\n- AppliedSciences_EnvironmentalScience\n- AppliedSciences_MarineScience\n\n## 8. Interdisciplinary Studies\n\n- Interdisciplinary_CulturalStudies\n- Interdisciplinary_EthicsSocialJustice",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "Answer user questions based on the ontology of knowledge domain in the backstor",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "Knowledge domain ontology warden",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Collective CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "official": false,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveCrewAIAgentComponent-1z0Y8"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "positionAbsolute": {
            "x": -3263.3235794380553,
            "y": 924.8049991559969
          },
          "dragging": false
        },
        {
          "id": "HierarchicalTaskComponent-Vezqe",
          "type": "genericNode",
          "position": {
            "x": -2713.1877278343118,
            "y": 2714.9893151137626
          },
          "data": {
            "type": "HierarchicalTaskComponent",
            "node": {
              "template": {
                "_type": "Component",
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": true,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output\n        )\n        self.status = task\n        return task\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "expected_output": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "expected_output",
                  "value": "Succinct response that answers the User's query.",
                  "display_name": "Expected Output",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Clear definition of expected task outcome.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "task_description": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "task_description",
                  "value": "",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Descriptive text detailing task's purpose and execution.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Each task must have a description, an expected output and an agent responsible for execution.",
              "icon": "CrewAI",
              "base_classes": [
                "HierarchicalTask"
              ],
              "display_name": "Hierarchical Task",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "HierarchicalTask"
                  ],
                  "selected": "HierarchicalTask",
                  "name": "task_output",
                  "display_name": "Task",
                  "method": "build_task",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "task_description",
                "expected_output",
                "tools"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "HierarchicalTaskComponent-Vezqe"
          },
          "selected": false,
          "width": 384,
          "height": 406,
          "dragging": false,
          "positionAbsolute": {
            "x": -2713.1877278343118,
            "y": 2714.9893151137626
          }
        },
        {
          "id": "Prompt-phlF8",
          "type": "genericNode",
          "position": {
            "x": -3195.459330872718,
            "y": 2938.3578928960665
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed. If it is just a general query (e.g a greeting) you can respond them directly.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "query": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "query",
                  "display_name": "query",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "query"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Prompt-phlF8"
          },
          "selected": false,
          "width": 384,
          "height": 410,
          "positionAbsolute": {
            "x": -3195.459330872718,
            "y": 2938.3578928960665
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-Uq7Oe",
          "type": "genericNode",
          "position": {
            "x": -2300.0912752858617,
            "y": 2001.1752264824117
          },
          "data": {
            "type": "CrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": false,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput",
                  "load_from_db": false
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "You are a RAG helper that can retrieve the most semantically relevant content from a database using embedding vector similarity search. When you give answers, only generate answer based on the retrieved content and always present the source of them from the data.",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "Find the most similar text to support the generation of answer for user's question.",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "PGVector Postgres Database Retriever",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agent",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CrewAIAgentComponent-Uq7Oe"
          },
          "selected": false,
          "width": 384,
          "height": 631,
          "positionAbsolute": {
            "x": -2300.0912752858617,
            "y": 2001.1752264824117
          },
          "dragging": false
        },
        {
          "id": "CollectiveCrewAIAgentComponent-yRgCM",
          "type": "genericNode",
          "position": {
            "x": -1896.7265112117511,
            "y": 1076.7368610958451
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": false,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "You discover the most similar subdomains in the ontology structure of knowledge domains from user's input.\n\n## 1. Mathematics and Statistics\n\n- Mathematics_PureMath\n- Mathematics_AppliedMath\n- Mathematics_Statistics\n\n## 2. Natural Sciences\n\n- NaturalSciences_Physics\n- NaturalSciences_Chemistry\n- NaturalSciences_Biology\n- NaturalSciences_EarthSciences\n\n## 3. Social Sciences\n\n- SocialSciences_Psychology\n- SocialSciences_SociologyAnthropology\n- SocialSciences_Economics\n- SocialSciences_PoliticalScience\n- SocialSciences_CommunicationMedia\n\n## 4. Humanities\n\n- Humanities_Philosophy\n- Humanities_Linguistics\n\n## 5. Business and Management\n\n- Business_Strategy\n- Business_Marketing\n\n## 6. Education\n\n- Education_GeneralEducation\n- Education_LiteracyWriting\n\n## 7. Applied Sciences and Engineering\n\n- AppliedSciences_ComputerScience\n- AppliedSciences_FoodScience\n- AppliedSciences_EnvironmentalScience\n- AppliedSciences_MarineScience\n\n## 8. Interdisciplinary Studies\n\n- Interdisciplinary_CulturalStudies\n- Interdisciplinary_EthicsSocialJustice",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "Discover user's interests with regards to one to three subdomains in the ontology",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "Interest discoverer",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Collective CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "official": false,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveCrewAIAgentComponent-yRgCM"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "positionAbsolute": {
            "x": -1896.7265112117511,
            "y": 1076.7368610958451
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-XHQqk",
          "type": "genericNode",
          "position": {
            "x": -1888.4967147972052,
            "y": 3042.15260904593
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-XHQqk"
          },
          "selected": false,
          "width": 384,
          "height": 597,
          "positionAbsolute": {
            "x": -1888.4967147972052,
            "y": 3042.15260904593
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-jKE5w",
          "type": "genericNode",
          "position": {
            "x": -6021.297568725004,
            "y": 1741.2968238056094
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-jKE5w"
          },
          "selected": false,
          "width": 384,
          "height": 597,
          "positionAbsolute": {
            "x": -6021.297568725004,
            "y": 1741.2968238056094
          },
          "dragging": false
        },
        {
          "id": "CollectiveCrewAIAgentComponent-bvGpO",
          "type": "genericNode",
          "position": {
            "x": -5502.852428097926,
            "y": 1853.485381808071
          },
          "data": {
            "type": "CollectiveCrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "previous_agents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "previous_agents",
                  "value": "",
                  "display_name": "Previous Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "The previous agents (for chaining).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": true,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\n\r\n\r\nclass CollectiveCrewAIAgentComponent(Component):\r\n    display_name = \"Collective CrewAI Agent\"\r\n    description = \"Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.\"\r\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\r\n    icon = \"CrewAI\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\r\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\r\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\r\n        HandleInput(\r\n            name=\"tools\",\r\n            display_name=\"Tools\",\r\n            input_types=[\"Tool\"],\r\n            is_list=True,\r\n            info=\"Tools at agents disposal\",\r\n            value=[],\r\n        ),\r\n        HandleInput(\r\n            name=\"llm\",\r\n            display_name=\"Language Model\",\r\n            info=\"Language model that will run the agent.\",\r\n            input_types=[\"LanguageModel\"],\r\n        ),\r\n        BoolInput(\r\n            name=\"memory\",\r\n            display_name=\"Memory\",\r\n            info=\"Whether the agent should have memory or not\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"verbose\",\r\n            display_name=\"Verbose\",\r\n            advanced=True,\r\n            value=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_delegation\",\r\n            display_name=\"Allow Delegation\",\r\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\r\n            value=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"allow_code_execution\",\r\n            display_name=\"Allow Code Execution\",\r\n            info=\"Whether the agent is allowed to execute code.\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        DictInput(\r\n            name=\"kwargs\",\r\n            display_name=\"kwargs\",\r\n            info=\"kwargs of agent.\",\r\n            is_list=True,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"previous_agents\",\r\n            display_name=\"Previous Agents\",\r\n            input_types=[\"Agent\"],\r\n            info=\"The previous agents (for chaining).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Agents\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> list[Agent]:\r\n        \r\n        kwargs = self.kwargs if self.kwargs else {}\r\n        agent = Agent(\r\n            role=self.role,\r\n            goal=self.goal,\r\n            backstory=self.backstory,\r\n            llm=self.llm,\r\n            verbose=self.verbose,\r\n            memory=self.memory,\r\n            tools=self.tools if self.tools else [],\r\n            allow_delegation=self.allow_delegation,\r\n            allow_code_execution=self.allow_code_execution,\r\n            **kwargs,\r\n        )\r\n        self.status = repr(agent)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.previous_agents:\r\n            if isinstance(self.previous_agents, list):\r\n                agents = self.previous_agents + []\r\n            else:\r\n                agents = [self.previous_agents, agent]\r\n        else:\r\n            agents = [agent]\r\n        return agents\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI. Always return a list of agents, able to collect previous agents.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "Collective CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agents",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs",
                "previous_agents"
              ],
              "beta": false,
              "edited": true,
              "official": false
            },
            "id": "CollectiveCrewAIAgentComponent-bvGpO"
          },
          "selected": false,
          "width": 384,
          "height": 707,
          "positionAbsolute": {
            "x": -5502.852428097926,
            "y": 1853.485381808071
          },
          "dragging": false
        },
        {
          "id": "CollectiveTool-p4hG6",
          "type": "genericNode",
          "position": {
            "x": -4431.206647909941,
            "y": 1901.1837328607676
          },
          "data": {
            "type": "Neo4jCypherQueryExecutorComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, cast\r\nimport json\r\nimport pandas as pd\r\nfrom neo4j import GraphDatabase, exceptions\r\n\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.io import Output, MessageTextInput, MultilineInput\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.field_typing import Tool\r\n\r\nclass Neo4jCypherQueryExecutorComponent(Component):\r\n    display_name = \"Cypher Query Executor\"\r\n    description = \"Execute Cypher queries on a Neo4j database.\"\r\n    icon = \"\"\r\n    name = \"Neo4jCypherQueryExecutorComponent\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"cypher_query\", \r\n            display_name=\"Cypher Query\",\r\n            info=\"The Cypher query to execute.\"\r\n        ),\r\n        MessageTextInput(\r\n            name=\"neo4j_credentials\", \r\n            display_name=\"Neo4j Credentials\", \r\n            info=\"JSON string with Neo4j connection details.\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Tool\", name=\"output_tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        \"\"\"Execute the Cypher query and return the results as a message.\"\"\"\r\n        # Load Neo4j credentials\r\n        try:\r\n            credentials = json.loads(self.neo4j_credentials)\r\n            driver = GraphDatabase.driver(\r\n                credentials[\"url\"], \r\n                auth=(credentials[\"username\"], credentials[\"password\"])\r\n            )\r\n\r\n            with driver.session() as session:\r\n                results = session.run(self.cypher_query)\r\n\r\n                # Process results into a list of dictionaries\r\n                result_list = [\r\n                    {key: record.get(key) for key in record.keys()} \r\n                    for record in results\r\n                ]\r\n\r\n                # Convert results to DataFrame for easier viewing/logging (optional)\r\n                df = pd.DataFrame(result_list)\r\n                self.status = df.to_json(orient=\"records\")  # Status stores results as JSON string\r\n\r\n        except exceptions.CypherSyntaxError as e:\r\n            # Handle syntax errors in Cypher queries\r\n            self.status = f\"Invalid Cypher query: {str(e)}\"\r\n            return Message(text=f\"Invalid Cypher query: {str(e)}\")\r\n\r\n        except Exception as e:\r\n            # Handle other exceptions (e.g., connection errors)\r\n            self.status = f\"Error executing query: {str(e)}\"\r\n            return Message(text=f\"Error executing query: {str(e)}\")\r\n\r\n        finally:\r\n            # Ensure the driver is closed even if an error occurs\r\n            if 'driver' in locals():\r\n                driver.close()\r\n\r\n        # Return the results as a message\r\n        return Message(text=self.status)\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Builds the tool function for Langflow.\"\"\"\r\n        def query_executor(cypher_query: str, neo4j_credentials: str) -> str:\r\n            \"\"\"Execute the Cypher query and return results.\"\"\"\r\n            self.cypher_query = cypher_query\r\n            self.neo4j_credentials = neo4j_credentials\r\n            return self.build_output().text\r\n\r\n        # Return the tool, cast as required by Langflow\r\n        return cast(Tool, query_executor)\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "cypher_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cypher_query",
                  "value": "",
                  "display_name": "Cypher Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The Cypher query to execute.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "JSON string with Neo4j connection details.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Execute Cypher queries on a Neo4j database.",
              "icon": "",
              "base_classes": [
                "Tool"
              ],
              "display_name": "GraphRAGRetrieverTool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cypher_query",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true
            },
            "id": "CollectiveTool-p4hG6"
          },
          "selected": false,
          "width": 384,
          "height": 378,
          "positionAbsolute": {
            "x": -4431.206647909941,
            "y": 1901.1837328607676
          },
          "dragging": false
        },
        {
          "id": "CollectiveTool-eeeQ3",
          "type": "genericNode",
          "position": {
            "x": -3843.2190181460915,
            "y": 1256.2555714042426
          },
          "data": {
            "type": "KnowledgeGraphIndexKRetrieverComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, cast, Union\r\nimport json\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nfrom neo4j import GraphDatabase\r\n\r\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.inputs import (\r\n    IntInput,\r\n    MessageTextInput,\r\n    DropdownInput,\r\n    SecretStrInput,\r\n)\r\n\r\nclass GraphVectorRetrieverTool(LCToolComponent):\r\n    display_name = \"Knowledge Graph Retriever\"\r\n    description = \"Retrieve top K results from Neo4j using vector similarity search.\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n    icon=\"\"\r\n    # Define inputs required by the component\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", display_name=\"Query\", info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4, required=True),\r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\"),\r\n    ]\r\n\r\n    def run_model(self) -> Union[List[Data], str]:\r\n        \"\"\"Executes the component logic and returns the results.\"\"\"\r\n        try:\r\n            # Load and parse Neo4j credentials\r\n            credentials = json.loads(self.neo4j_credentials)\r\n            driver = GraphDatabase.driver(\r\n                credentials[\"url\"], \r\n                auth=(credentials[\"username\"], credentials[\"password\"])\r\n            )\r\n\r\n            # Initialize OpenAI embeddings\r\n            embeddings = OpenAIEmbeddings(\r\n                api_key=self.openai_api_key,\r\n                model=self.openai_embedding_model,\r\n            )\r\n\r\n            # Initialize Neo4j Vector Search\r\n            vector_index = Neo4jVector.from_existing_graph(\r\n                embeddings,\r\n                search_type=\"hybrid\",\r\n                node_label=\"Document\",\r\n                text_node_properties=[\"text\"],\r\n                embedding_node_property=\"embedding\",\r\n                url=credentials[\"url\"],\r\n                username=credentials[\"username\"],\r\n                password=credentials[\"password\"],\r\n            )\r\n\r\n            # Execute the similarity search\r\n            results = vector_index.similarity_search(self.user_query, k=self.k)\r\n\r\n            # Convert results into Data objects for Langflow\r\n            data = [Data(data=result, text=result[\"text\"]) for result in results]\r\n            self.status = data\r\n            return data\r\n\r\n        except Exception as e:\r\n            self.status = f\"Error: {str(e)}\"\r\n            return f\"Error: {str(e)}\"\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Builds the tool for Langflow.\"\"\"\r\n        # Parse credentials\r\n        credentials = json.loads(self.neo4j_credentials)\r\n\r\n        # Initialize the embeddings and Neo4j vector search tool\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key, model=self.openai_embedding_model\r\n        )\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=\"Document\",\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n\r\n        # Return the tool, cast for Langflow compatibility\r\n        return cast(\r\n            Tool,\r\n            lambda query: vector_index.similarity_search(query, k=self.k),\r\n        )\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "k",
                  "value": 4,
                  "display_name": "Number of results to return",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_embedding_model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_embedding_model",
                  "value": "text-embedding-3-small",
                  "display_name": "Embedding Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "user_query": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_query",
                  "value": "",
                  "display_name": "Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "User query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Retrieve top K results from Neo4j using vector similarity search.",
              "icon": "",
              "base_classes": [
                "Data",
                "Text",
                "Tool"
              ],
              "display_name": "GraphVectorRetrieverTool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data",
                    "Text"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "user_query",
                "k",
                "openai_embedding_model",
                "openai_api_key",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true
            },
            "id": "CollectiveTool-eeeQ3"
          },
          "selected": false,
          "width": 384,
          "height": 706,
          "dragging": false,
          "positionAbsolute": {
            "x": -3843.2190181460915,
            "y": 1256.2555714042426
          }
        },
        {
          "id": "Neo4jCredentialLoader-D6kdB",
          "type": "genericNode",
          "position": {
            "x": -4332.14846230714,
            "y": 1002.0638317776454
          },
          "data": {
            "type": "Neo4jCredentialLoader",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "neo4j_password": {
                  "trace_as_metadata": true,
                  "load_from_db": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_password",
                  "value": "Neo4j Password",
                  "display_name": "Neo4j Password",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_url": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_url",
                  "value": "neo4j://jingconsult.tech:7687",
                  "display_name": "Neo4j URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_username": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_username",
                  "value": "neo4j",
                  "display_name": "Neo4j Username",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "A handy component to load neo4j credentials",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Neo4j Credential Loader",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "credentials",
                  "display_name": "Credentials",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "neo4j_url",
                "neo4j_username",
                "neo4j_password"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17",
              "official": false
            },
            "id": "Neo4jCredentialLoader-D6kdB"
          },
          "selected": false,
          "width": 384,
          "height": 467,
          "dragging": false,
          "positionAbsolute": {
            "x": -4332.14846230714,
            "y": 1002.0638317776454
          }
        },
        {
          "id": "CollectiveTool-N5nbH",
          "type": "genericNode",
          "position": {
            "x": -4317.720595152416,
            "y": 2353.8108751675377
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom langchain_core.tools import BaseTool, tool\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\nfrom crewai_tools import PGSearchTool\r\n\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    @tool \r\n    def custom_tool() -> str:\r\n        \"\"\"Define custome tool\"\"\"\r\n        return \"\"\r\n    \r\n    def build_output(self) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n\r\n        tool = CustomTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\nclass CustomTool(BaseTool):\r\n    name = \"CustomTool\"\r\n    description = \"CustomTool\"\r\n    return_direct: bool = True\r\n    def _run() -> str:\r\n        return \"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "PGVectorTool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools"
              ],
              "beta": false,
              "edited": true
            },
            "id": "CollectiveTool-N5nbH"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "dragging": false,
          "positionAbsolute": {
            "x": -4317.720595152416,
            "y": 2353.8108751675377
          }
        },
        {
          "id": "CollectiveTool-NOeqq",
          "type": "genericNode",
          "position": {
            "x": -2849.1284097025464,
            "y": 1700.360664118603
          },
          "data": {
            "type": "CollectiveTool",
            "node": {
              "template": {
                "_type": "Component",
                "other_tools": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "other_tools",
                  "value": "",
                  "display_name": "Other tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Other tools (for grouping).",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.field_typing import BaseRetriever, Tool\r\nfrom crewai_tools import tool, BaseTool\r\nimport os\r\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\r\nfrom typing import List\r\nfrom langchain_community.vectorstores import PGVector\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom axiestudio.helpers.data import docs_to_data\r\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.utils.connection_string_parser import transform_connection_string\r\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\r\nimport psycopg2\r\nimport numpy as np\r\n\r\nclass CollectiveToolComponent(Component):\r\n    display_name = \"Collective Tool Template\"\r\n    description = \"Template for creating a collection of tools for the agents\"\r\n    name = \"CollectiveTool\"\r\n    icon = \"custom_components\"\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"other_tools\",\r\n            display_name=\"Other tools\",\r\n            input_types=[\"Tool\"],\r\n            info=\"Other tools (for grouping).\",\r\n            required=False,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\r\n            advanced=False,\r\n            value=\"OPENAI_API_KEY\",\r\n        ),\r\n        \r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Tools\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    # @tool \r\n    # def PGSearchTool(input_string: str) -> str:\r\n    #     \"\"\"A tool that searches for top 5 results semantically related to the input string \r\n    #     in a postgres database table to find text using vector embedding similiarity search \r\n    #     that supports retrieval augmented generation (RAG)\"\"\"\r\n    #     conn = psycopg2.connect(\r\n    #         host=os.getenv(\"DB_HOST\"),\r\n    #         database=os.getenv(\"DB_NAME\"),\r\n    #         user=os.getenv(\"DB_USER\"),\r\n    #         password=os.getenv(\"DB_PASSWORD\")\r\n    #     )\r\n    #     cursor = conn.cursor()\r\n    #     embedding = OpenAIEmbeddings(\r\n    #         model=\"text-embedding-3-small\",\r\n    #         chunk_size=1000,\r\n    #         embedding_ctx_length=1536\r\n    #     )\r\n    #     search_vector = embedding.embed_query(str(input_string))\r\n    #     query = f\"\"\"\r\n    #         SELECT file_content\r\n    #         FROM embedding\r\n    #         ORDER BY vector <-> %s::vector\r\n    #         LIMIT 5;\r\n    #     \"\"\"\r\n        \r\n    #     cursor.execute(query, (search_vector,))\r\n    #     results = cursor.fetchall()\r\n    #     cursor.close()\r\n    #     conn.close()\r\n    #     return str(results[0])\r\n    \r\n    def build_output(self) -> list[Tool]:\r\n        # Define Tool Class\r\n\r\n        os.environ['OPENAI_API_KEY'] = self.api_key\r\n        class PGSearchTool(BaseTool):\r\n            name: str = \"pgvector postgres database retriever\"\r\n            description: str = \"A tool that searches for top 5 results semantically related to the input string \\\r\n            in a postgres database table to find text using vector embedding similarity search \\\r\n            that supports retrieval augmented generation (RAG)\"\r\n        \r\n            def _run(self, input_string: str) -> str:\r\n                print(\"Received string: \", input_string)\r\n                conn = psycopg2.connect(\r\n                    host=os.getenv(\"DB_HOST\"),\r\n                    database=os.getenv(\"DB_NAME\"),\r\n                    user=os.getenv(\"DB_USER\"),\r\n                    password=os.getenv(\"DB_PASSWORD\")\r\n                )\r\n                cursor = conn.cursor()\r\n                embedding = OpenAIEmbeddings(\r\n                    model=\"text-embedding-3-small\",\r\n                    chunk_size=1000,\r\n                    embedding_ctx_length=1536\r\n                )\r\n                search_vector = embedding.embed_query(str(input_string))\r\n                query = f\"\"\"\r\n                    SELECT file_content\r\n                    FROM embedding\r\n                    ORDER BY vector <-> %s::vector\r\n                    LIMIT 5;\r\n                \"\"\"\r\n                \r\n                cursor.execute(query, (search_vector,))\r\n                results = cursor.fetchall()\r\n                cursor.close()\r\n                conn.close()\r\n                return str(results[0])\r\n        tool = PGSearchTool()\r\n        tools = []\r\n        self.status = repr(tool)\r\n        # If there's a previous task, create a list of tasks\r\n        if self.other_tools:\r\n            if isinstance(self.other_tools, list):\r\n                tools = self.other_tools + []\r\n            else:\r\n                tools = [self.other_tools, tool]\r\n        else:\r\n            tools = [tool]\r\n        return tools\r\n\r\n# class PGSearchTool(BaseTool):\r\n#     name = \"PGSearchTool\"\r\n#     description = \"A tool that searches for top 5 results semantically related to the input string in a postgres database table to find text using vector embedding similiarity search that supports retrieval augmented generation (RAG)\"\r\n#     return_direct: bool = True\r\n#     def _run(self, intput_string: str) -> str:\r\n#         conn = psycopg2.connect(\r\n#                 host=\"localhost\", \r\n#                 database=\"ai_tutor\", \r\n#                 user=\"postgres\", \r\n#                 password=\"Jing_consult\"\r\n#             )\r\n#         cursor = conn.cursor()\r\n#         embedding = OpenAIEmbeddings(\r\n#             model = \"text-embedding-3-small\",\r\n#             chunk_size = 1000,\r\n#             embedding_ctx_length = 1536,\r\n#             api_key = \"sk-proj-NjiT0cmXcUaY8N2Ktd5CT3BlbkFJvpJm8LAqmLAIk79Pfq0X\"\r\n#             )\r\n#         search_vector = embedding.embed_query(str(input_string))\r\n#         query = \"\"\"\r\n#             SELECT file_content\r\n#             FROM embedding\r\n#             ORDER BY vector <-> %s::vector\r\n#             LIMIT 5;\r\n#         \"\"\"\r\n        \r\n#         cursor.execute(query, (search_vector))\r\n#         # Fetch the top results\r\n#         results = cursor.fetchall()\r\n#         cursor.close()\r\n#         conn.close()\r\n#         return str(results)",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Template for creating a collection of tools for the agents",
              "icon": "custom_components",
              "base_classes": [
                "Tool"
              ],
              "display_name": "PGVectorTool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "output",
                  "display_name": "Tools",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "other_tools",
                "api_key"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CollectiveTool-NOeqq"
          },
          "selected": false,
          "width": 384,
          "height": 372,
          "positionAbsolute": {
            "x": -2849.1284097025464,
            "y": 1700.360664118603
          },
          "dragging": false
        },
        {
          "id": "PythonCodeStructuredTool-kQm1H",
          "type": "genericNode",
          "position": {
            "x": -4661.265398733965,
            "y": 3104.1037216392783
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "Component",
                "_classes": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_classes",
                  "value": "[]",
                  "display_name": "Classes",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "_functions": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_functions",
                  "value": "{}",
                  "display_name": "Functions",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "global_variables": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "global_variables",
                  "value": "",
                  "display_name": "Global Variables",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Enter the global variables or Create Data Component.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "HandleInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": false,
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tool_code": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "show": true,
                  "name": "tool_code",
                  "value": "",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "tool_description": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_description",
                  "value": "",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "tool_function": {
                  "trace_as_metadata": true,
                  "options": [],
                  "combobox": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_function",
                  "value": "",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "tool_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_name",
                  "value": "",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "structuredtool dataclass code to tool",
              "icon": "",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Python Code Structured Tool",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "tool_code",
                "tool_name",
                "tool_description",
                "return_direct",
                "tool_function",
                "global_variables",
                "_classes",
                "_functions"
              ],
              "beta": false,
              "edited": false
            },
            "id": "PythonCodeStructuredTool-kQm1H"
          },
          "selected": false,
          "width": 384,
          "height": 706,
          "dragging": false
        },
        {
          "id": "HierarchicalCrewComponent-POt7U",
          "type": "genericNode",
          "position": {
            "x": -2762.6526676276767,
            "y": 3668.803306729951
          },
          "data": {
            "type": "HierarchicalCrewComponent",
            "node": {
              "template": {
                "_type": "Component",
                "agents": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "agents",
                  "value": "",
                  "display_name": "Agents",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "function_calling_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "function_calling_llm",
                  "value": "",
                  "display_name": "Function Calling LLM",
                  "advanced": true,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "manager_agent": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "manager_agent",
                  "value": "",
                  "display_name": "Manager Agent",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "manager_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "manager_llm",
                  "value": "",
                  "display_name": "Manager LLM",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tasks": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tasks",
                  "value": "",
                  "display_name": "Tasks",
                  "advanced": false,
                  "input_types": [
                    "HierarchicalTask"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent, Crew, Task, Process\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput, MessageTextInput\nfrom crewai_tools import BaseTool\nfrom langchain_openai import ChatOpenAI\nfrom langchain_openai.embeddings import OpenAIEmbeddings\nimport psycopg2\nfrom dotenv import load_dotenv\nimport os\nfrom langchain_community.vectorstores import Neo4jVector\nimport json\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\n    ]\n\n    def build_crew(self) -> Crew:\n        class PGSearchTool(BaseTool):\n            name: str = \"pgvector postgres database retriever\"\n            description: str = \"A tool that searches for top 5 results semantically related to the input string \\\n            in a postgres database table to find text using vector embedding similarity search \\\n            to support later retrieval augmented generation (RAG)\"\n            \n            def _run(self, input_string: str) -> str:\n                conn = psycopg2.connect(\n                    host=os.getenv(\"DB_HOST\"),\n                    database=os.getenv(\"DB_NAME\"),\n                    user=os.getenv(\"DB_USER\"),\n                    password=os.getenv(\"DB_PASSWORD\")\n                )\n                cursor = conn.cursor()\n                embedding = OpenAIEmbeddings(\n                    model=\"text-embedding-3-small\",\n                    chunk_size=1000,\n                    embedding_ctx_length=1536\n                )\n                search_vector = embedding.embed_query(str(input_string))\n                query = f\"\"\"\n                    SELECT file_content\n                    FROM embedding\n                    ORDER BY vector <-> %s::vector\n                    LIMIT 5;\n                \"\"\"\n                \n                cursor.execute(query, (search_vector,))\n                results = cursor.fetchall()\n                cursor.close()\n                conn.close()\n                return \",\".join([str(result) for result in results])\n        \n        \n        \n        class Neo4jSearchTool(BaseTool):\n            name: str = \"neo4j database vector retriever\"\n            description: str = \"A tool that searches for top 5 results semantically related to the input string \\\n            in a neo4j graph database to find text using vector embedding similarity search \\\n            to support later retrieval augmented generation (RAG)\"\n            k: int = 5\n            def _run(self, input_string: str) -> str:\n                embedding = OpenAIEmbeddings(\n                    model=\"text-embedding-3-small\",\n                    chunk_size=1000,\n                    embedding_ctx_length=1536\n                )\n                vector_index = Neo4jVector.from_existing_graph(\n                    embedding,\n                    search_type=\"hybrid\",\n                    node_label=\"Document\",\n                    text_node_properties=[\"text\"],\n                    embedding_node_property=\"embedding\",\n                    url=os.getenv(\"NEO4J_URL\"),\n                    username=os.getenv(\"NEO4J_NAME\"),\n                    password=os.getenv(\"NEO4J_PASSWORD\")\n                )\n                results = vector_index.similarity_search(input_string, k=self.k)\n                # parse: to keep source document name, page number, and content\n                documents = []\n                for document in results:\n                    documents.append(\n                        {\n                            \"source_document\": os.path.splitext(os.path.basename(document.metadata.get(\"source\")))[0],\n                            \"source_page\": document.metadata.get(\"page\"),\n                            \"page_content\": document.page_content\n                        }\n                    )\n                \n                return json.dumps(documents)\n        \n        # Initialise tools\n        pg_search_tool = PGSearchTool()\n        neo4j_search_tool = Neo4jSearchTool()\n        agent = Agent(\n            role=\"database RAG helper\",\n            goal=\"Find semantically related text to support the generation of answer for user's question.\",\n            backstory=\"You are a RAG helper that can retrieve the most semantically relevant content from \\\n            a database using embedding vector similarity search. When you give answers, only generate answer \\\n            based on the retrieved content and always present the source of them from the data. You have tools \\\n            which can accept a string as the input to perform similarity serach from the \\\n            existing databases. You should try all available tools and evaluate results from them then return answer.\",\n            verbose=True,\n            llm=ChatOpenAI(\n                model=os.getenv(\"OPENAI_MODEL\"),\n                temperature=float(os.getenv(\"OPENAI_TEMPERATURE\", \"0.1\")),\n            ),\n            tools=[neo4j_search_tool, pg_search_tool]\n        )\n        \n        \n        # Define the task\n        task = Task(\n            description=\"User: Tell me how to build a knowledge graph?\\\n            Respond to the user with as much as information as you can about the topic. \\\n            Always delegate the tasks to agents and compose answers based on the results\",\n            expected_output = \"Succinct response that answers the User's query.\"\n        )\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "max_rpm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_rpm",
                  "value": 100,
                  "display_name": "Max RPM",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": false,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "share_crew": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "share_crew",
                  "value": false,
                  "display_name": "Share Crew",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "use_cache": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "use_cache",
                  "value": true,
                  "display_name": "Cache",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": 0,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                }
              },
              "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
              "icon": "CrewAI",
              "base_classes": [
                "Message"
              ],
              "display_name": "Hierarchical Crew",
              "documentation": "https://docs.crewai.com/how-to/Hierarchical/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "verbose",
                "memory",
                "use_cache",
                "max_rpm",
                "share_crew",
                "function_calling_llm",
                "agents",
                "tasks",
                "manager_llm",
                "manager_agent",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true
            },
            "id": "HierarchicalCrewComponent-POt7U"
          },
          "selected": true,
          "width": 384,
          "height": 542,
          "positionAbsolute": {
            "x": -2762.6526676276767,
            "y": 3668.803306729951
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "OpenAIModel-pF8ma",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:manager_llm,id:HierarchicalCrewComponent-POopw,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "manager_llm",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pF8ma",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-HierarchicalCrewComponent-POopw{fieldName:manager_llm,id:HierarchicalCrewComponent-POopw,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "RetrieverTool-ijoHS",
          "sourceHandle": "{dataType:CollectiveTool,id:RetrieverTool-ijoHS,name:output,output_types:[Tool]}",
          "target": "CrewAIAgentComponent-RJKKD",
          "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-RJKKD,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-RJKKD",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "RetrieverTool-ijoHS",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-RetrieverTool-ijoHS{dataType:CollectiveTool,id:RetrieverTool-ijoHS,name:output,output_types:[Tool]}-CrewAIAgentComponent-RJKKD{fieldName:tools,id:CrewAIAgentComponent-RJKKD,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "HierarchicalTaskComponent-fh9Vr",
          "sourceHandle": "{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-fh9Vr,name:task_output,output_types:[HierarchicalTask]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:tasks,id:HierarchicalCrewComponent-POopw,inputTypes:[HierarchicalTask],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tasks",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "HierarchicalTask"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "HierarchicalTaskComponent",
              "id": "HierarchicalTaskComponent-fh9Vr",
              "name": "task_output",
              "output_types": [
                "HierarchicalTask"
              ]
            }
          },
          "id": "reactflow__edge-HierarchicalTaskComponent-fh9Vr{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-fh9Vr,name:task_output,output_types:[HierarchicalTask]}-HierarchicalCrewComponent-POopw{fieldName:tasks,id:HierarchicalCrewComponent-POopw,inputTypes:[HierarchicalTask],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-GGaIt",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-GGaIt,name:output,output_types:[Tool]}",
          "target": "CollectiveTool-iGp6D",
          "targetHandle": "{fieldName:other_tools,id:CollectiveTool-iGp6D,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "other_tools",
              "id": "CollectiveTool-iGp6D",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-GGaIt",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-GGaIt{dataType:CollectiveTool,id:CollectiveTool-GGaIt,name:output,output_types:[Tool]}-CollectiveTool-iGp6D{fieldName:other_tools,id:CollectiveTool-iGp6D,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-wBeSt",
          "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-wBeSt,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:manager_agent,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "manager_agent",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-wBeSt",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-wBeSt{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-wBeSt,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:manager_agent,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveCrewAIAgentComponent-g95En",
          "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-g95En,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveCrewAIAgentComponent",
              "id": "CollectiveCrewAIAgentComponent-g95En",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveCrewAIAgentComponent-g95En{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-g95En,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-iGp6D",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-iGp6D,name:output,output_types:[Tool]}",
          "target": "CollectiveTool-8jGBc",
          "targetHandle": "{fieldName:other_tools,id:CollectiveTool-8jGBc,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "other_tools",
              "id": "CollectiveTool-8jGBc",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-iGp6D",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-iGp6D{dataType:CollectiveTool,id:CollectiveTool-iGp6D,name:output,output_types:[Tool]}-CollectiveTool-8jGBc{fieldName:other_tools,id:CollectiveTool-8jGBc,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-8jGBc",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-8jGBc,name:output,output_types:[Tool]}",
          "target": "CollectiveTool-wx20I",
          "targetHandle": "{fieldName:other_tools,id:CollectiveTool-wx20I,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "other_tools",
              "id": "CollectiveTool-wx20I",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-8jGBc",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-8jGBc{dataType:CollectiveTool,id:CollectiveTool-8jGBc,name:output,output_types:[Tool]}-CollectiveTool-wx20I{fieldName:other_tools,id:CollectiveTool-wx20I,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-wx20I",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}",
          "target": "CollectiveCrewAIAgentComponent-JhWL3",
          "targetHandle": "{fieldName:tools,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CollectiveCrewAIAgentComponent-JhWL3",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-wx20I",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-wx20I{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}-CollectiveCrewAIAgentComponent-JhWL3{fieldName:tools,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-wx20I",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}",
          "target": "CollectiveCrewAIAgentComponent-gsrJN",
          "targetHandle": "{fieldName:tools,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CollectiveCrewAIAgentComponent-gsrJN",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-wx20I",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-wx20I{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}-CollectiveCrewAIAgentComponent-gsrJN{fieldName:tools,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-wx20I",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}",
          "target": "CollectiveTool-vMdr2",
          "targetHandle": "{fieldName:other_tools,id:CollectiveTool-vMdr2,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "other_tools",
              "id": "CollectiveTool-vMdr2",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-wx20I",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-wx20I{dataType:CollectiveTool,id:CollectiveTool-wx20I,name:output,output_types:[Tool]}-CollectiveTool-vMdr2{fieldName:other_tools,id:CollectiveTool-vMdr2,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveTool-vMdr2",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-vMdr2,name:output,output_types:[Tool]}",
          "target": "CollectiveCrewAIAgentComponent-g95En",
          "targetHandle": "{fieldName:tools,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CollectiveCrewAIAgentComponent-g95En",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-vMdr2",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-vMdr2{dataType:CollectiveTool,id:CollectiveTool-vMdr2,name:output,output_types:[Tool]}-CollectiveCrewAIAgentComponent-g95En{fieldName:tools,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[Tool],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-pF8ma",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
          "target": "CrewAIAgentComponent-RJKKD",
          "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-RJKKD,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-RJKKD",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pF8ma",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-RJKKD{fieldName:llm,id:CrewAIAgentComponent-RJKKD,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-pF8ma",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
          "target": "CollectiveCrewAIAgentComponent-JhWL3",
          "targetHandle": "{fieldName:llm,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CollectiveCrewAIAgentComponent-JhWL3",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pF8ma",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CollectiveCrewAIAgentComponent-JhWL3{fieldName:llm,id:CollectiveCrewAIAgentComponent-JhWL3,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-pF8ma",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
          "target": "CollectiveCrewAIAgentComponent-gsrJN",
          "targetHandle": "{fieldName:llm,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CollectiveCrewAIAgentComponent-gsrJN",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pF8ma",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CollectiveCrewAIAgentComponent-gsrJN{fieldName:llm,id:CollectiveCrewAIAgentComponent-gsrJN,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-pF8ma",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
          "target": "CollectiveCrewAIAgentComponent-g95En",
          "targetHandle": "{fieldName:llm,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CollectiveCrewAIAgentComponent-g95En",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pF8ma",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CollectiveCrewAIAgentComponent-g95En{fieldName:llm,id:CollectiveCrewAIAgentComponent-g95En,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-pF8ma",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}",
          "target": "CrewAIAgentComponent-wBeSt",
          "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-wBeSt,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-wBeSt",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pF8ma",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pF8ma{dataType:OpenAIModel,id:OpenAIModel-pF8ma,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-wBeSt{fieldName:llm,id:CrewAIAgentComponent-wBeSt,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveCrewAIAgentComponent-gsrJN",
          "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-gsrJN,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveCrewAIAgentComponent",
              "id": "CollectiveCrewAIAgentComponent-gsrJN",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveCrewAIAgentComponent-gsrJN{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-gsrJN,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "className": ""
        },
        {
          "source": "CollectiveCrewAIAgentComponent-JhWL3",
          "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-JhWL3,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveCrewAIAgentComponent",
              "id": "CollectiveCrewAIAgentComponent-JhWL3",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveCrewAIAgentComponent-JhWL3{dataType:CollectiveCrewAIAgentComponent,id:CollectiveCrewAIAgentComponent-JhWL3,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-RJKKD",
          "sourceHandle": "{dataType:CollectiveCrewAIAgentComponent,id:CrewAIAgentComponent-RJKKD,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-POopw",
          "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-POopw",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveCrewAIAgentComponent",
              "id": "CrewAIAgentComponent-RJKKD",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-RJKKD{dataType:CollectiveCrewAIAgentComponent,id:CrewAIAgentComponent-RJKKD,name:output,output_types:[Agent]}-HierarchicalCrewComponent-POopw{fieldName:agents,id:HierarchicalCrewComponent-POopw,inputTypes:[Agent],type:other}",
          "className": ""
        },
        {
          "source": "HierarchicalTaskComponent-Vezqe",
          "sourceHandle": "{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-Vezqe,name:task_output,output_types:[HierarchicalTask]}",
          "target": "HierarchicalCrewComponent-8R2Ak",
          "targetHandle": "{fieldName:tasks,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[HierarchicalTask],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tasks",
              "id": "HierarchicalCrewComponent-8R2Ak",
              "inputTypes": [
                "HierarchicalTask"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "HierarchicalTaskComponent",
              "id": "HierarchicalTaskComponent-Vezqe",
              "name": "task_output",
              "output_types": [
                "HierarchicalTask"
              ]
            }
          },
          "id": "reactflow__edge-HierarchicalTaskComponent-Vezqe{dataType:HierarchicalTaskComponent,id:HierarchicalTaskComponent-Vezqe,name:task_output,output_types:[HierarchicalTask]}-HierarchicalCrewComponent-8R2Ak{fieldName:tasks,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[HierarchicalTask],type:other}",
          "className": ""
        },
        {
          "source": "Prompt-phlF8",
          "sourceHandle": "{dataType:Prompt,id:Prompt-phlF8,name:prompt,output_types:[Message]}",
          "target": "HierarchicalTaskComponent-Vezqe",
          "targetHandle": "{fieldName:task_description,id:HierarchicalTaskComponent-Vezqe,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "task_description",
              "id": "HierarchicalTaskComponent-Vezqe",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-phlF8",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-phlF8{dataType:Prompt,id:Prompt-phlF8,name:prompt,output_types:[Message]}-HierarchicalTaskComponent-Vezqe{fieldName:task_description,id:HierarchicalTaskComponent-Vezqe,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "OpenAIModel-svPsH",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-svPsH,name:model_output,output_types:[LanguageModel]}",
          "target": "CrewAIAgentComponent-Uq7Oe",
          "targetHandle": "{fieldName:llm,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-Uq7Oe",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-svPsH",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-svPsH{dataType:OpenAIModel,id:OpenAIModel-svPsH,name:model_output,output_types:[LanguageModel]}-CrewAIAgentComponent-Uq7Oe{fieldName:llm,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-Uq7Oe",
          "sourceHandle": "{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Uq7Oe,name:output,output_types:[Agent]}",
          "target": "HierarchicalCrewComponent-8R2Ak",
          "targetHandle": "{fieldName:agents,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[Agent],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-8R2Ak",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-Uq7Oe",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-Uq7Oe{dataType:CrewAIAgentComponent,id:CrewAIAgentComponent-Uq7Oe,name:output,output_types:[Agent]}-HierarchicalCrewComponent-8R2Ak{fieldName:agents,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[Agent],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-XHQqk",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-XHQqk,name:model_output,output_types:[LanguageModel]}",
          "target": "HierarchicalCrewComponent-8R2Ak",
          "targetHandle": "{fieldName:manager_llm,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "manager_llm",
              "id": "HierarchicalCrewComponent-8R2Ak",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-XHQqk",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-XHQqk{dataType:OpenAIModel,id:OpenAIModel-XHQqk,name:model_output,output_types:[LanguageModel]}-HierarchicalCrewComponent-8R2Ak{fieldName:manager_llm,id:HierarchicalCrewComponent-8R2Ak,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-D6kdB",
          "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-D6kdB,name:credentials,output_types:[Message]}",
          "target": "CollectiveTool-eeeQ3",
          "targetHandle": "{fieldName:neo4j_credentials,id:CollectiveTool-eeeQ3,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "CollectiveTool-eeeQ3",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-D6kdB",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-D6kdB{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-D6kdB,name:credentials,output_types:[Message]}-CollectiveTool-eeeQ3{fieldName:neo4j_credentials,id:CollectiveTool-eeeQ3,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "CollectiveTool-NOeqq",
          "sourceHandle": "{dataType:CollectiveTool,id:CollectiveTool-NOeqq,name:output,output_types:[Tool]}",
          "target": "CrewAIAgentComponent-Uq7Oe",
          "targetHandle": "{fieldName:tools,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[Tool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-Uq7Oe",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CollectiveTool",
              "id": "CollectiveTool-NOeqq",
              "name": "output",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CollectiveTool-NOeqq{dataType:CollectiveTool,id:CollectiveTool-NOeqq,name:output,output_types:[Tool]}-CrewAIAgentComponent-Uq7Oe{fieldName:tools,id:CrewAIAgentComponent-Uq7Oe,inputTypes:[Tool],type:other}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 2637.1470701313647,
        "y": -2190.907707398952,
        "zoom": 0.7073444639023024
      }
    },
    "date_created": "2024-10-11T14:09:55.777Z",
    "date_updated": "2024-10-17T03:35:45.761Z",
    "status": "Public",
    "sort": null,
    "user_updated": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "user_created": {
      "username": "jingconsult",
      "first_name": "Jing",
      "last_name": "Consulting",
      "id": "6decf44a-a4d8-438a-92d3-df07d49ad213"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:08.248Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 234,
    "converter_version": "1.0.0"
  }
}