{
  "id": "a0df8e47-f28a-46cc-9952-d723b19b7395",
  "name": "Sequential Tasks Agent",
  "description": "This Agent runs tasks in a predefined sequence. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "emtechme1",
    "first_name": "emtech",
    "last_name": "ME",
    "id": "5a08877f-43ac-479a-9650-6b9a6e3e02c8",
    "full_name": "emtech ME"
  },
  "store_url": "https://www.langflow.store/store/component/a0df8e47-f28a-46cc-9952-d723b19b7395",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-08-19T13:25:16.298Z",
    "updated": "2024-08-19T13:25:16.338Z",
    "downloaded": "2025-08-19T17:50:05.970Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.15",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "TextOutput-0SYKB",
        "type": "genericNode",
        "position": {
          "x": -3615.887482344415,
          "y": -564.1249339849606
        },
        "data": {
          "type": "TextOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.text import TextComponent\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "TextOutput-0SYKB"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "dragging": false,
        "positionAbsolute": {
          "x": -3615.887482344415,
          "y": -564.1249339849606
        }
      },
      {
        "id": "TextInput-acTjx",
        "type": "genericNode",
        "position": {
          "x": -4826.007109117352,
          "y": -934.8035707851349
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.text import TextComponent\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "TextInput-acTjx"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": -4826.007109117352,
          "y": -934.8035707851349
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-TPOGq",
        "type": "genericNode",
        "position": {
          "x": -4794.247772542848,
          "y": -463.99115774549944
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "json_mode",
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "gpt-4o-mini",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "output_schema",
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1,
                "name": "seed",
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "0.101",
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "OpenAIModel-TPOGq"
        },
        "selected": false,
        "width": 384,
        "height": 593,
        "positionAbsolute": {
          "x": -4794.247772542848,
          "y": -463.99115774549944
        },
        "dragging": false
      },
      {
        "id": "OpenAIToolsAgent-aSbna",
        "type": "genericNode",
        "position": {
          "x": -4238.071931427172,
          "y": -767.587346582954
        },
        "data": {
          "type": "OpenAIToolsAgent",
          "node": {
            "template": {
              "_type": "Component",
              "chat_history": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_history",
                "value": "",
                "display_name": "Chat History",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel",
                  "ToolEnabledLanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, List\n\nfrom langchain.agents import create_openai_tools_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.inputs import MultilineInput\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\nfrom axiestudio.schema import Data\n\n\nclass OpenAIToolsAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"OpenAI Tools Agent\"\n    description: str = \"Agent that uses tools via openai-tools.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"OpenAIToolsAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\", \"ToolEnabledLanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_openai_tools_agent(self.llm, self.tools, prompt)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "system_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant",
                "display_name": "System Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System prompt for the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "user_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_prompt",
                "value": "{input}",
                "display_name": "Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "This prompt must contain 'input' key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Agent that uses tools via openai-tools.",
            "icon": "LangChain",
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "display_name": "OpenAI Tools Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "AgentExecutor"
                ],
                "selected": "AgentExecutor",
                "name": "agent",
                "display_name": "Agent",
                "method": "build_agent",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "tools",
              "llm",
              "system_prompt",
              "user_prompt",
              "chat_history"
            ],
            "beta": true,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "OpenAIToolsAgent-aSbna"
        },
        "selected": false,
        "width": 384,
        "height": 603,
        "positionAbsolute": {
          "x": -4238.071931427172,
          "y": -767.587346582954
        },
        "dragging": false
      },
      {
        "id": "PythonCodeStructuredTool-JfnJq",
        "type": "genericNode",
        "position": {
          "x": -5356.770362853002,
          "y": -683.2492510055507
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "Component",
              "_classes": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_classes",
                "value": "[]",
                "display_name": "Classes",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "_functions": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_functions",
                "value": "{\"add_numbers\": {\"name\": \"add_numbers\", \"args\": [{\"name\": \"b\", \"annotation\": \"int\"}]}}",
                "display_name": "Functions",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import BoolInput, DropdownInput, FieldTypes, HandleInput, MessageTextInput, MultilineInput\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"ðŸ\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        (arg.lineno is not None and default.lineno is not None and arg.lineno > default.lineno)\n                        or (\n                            arg.col_offset is not None\n                            and default.col_offset is not None\n                            and arg.col_offset > default.col_offset\n                        )\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n            if isinstance(func[\"args\"], list):\n                func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "global_variables": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "global_variables",
                "value": "",
                "display_name": "Global Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Enter the global variables or Create Data Component.",
                "title_case": false,
                "type": "dict",
                "_input_type": "HandleInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": true,
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tool_code": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "show": true,
                "name": "tool_code",
                "value": "def add_numbers() -> string:\n\n    return \"Hello\"\n\n",
                "display_name": "Tool Code",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "tool_description": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "This function will be triggered when people ask about London",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tool_function": {
                "trace_as_metadata": true,
                "options": [
                  "Failed to parse",
                  "cannot access local variable 'func_arg' where it is not associated with a value"
                ],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_function",
                "value": "add_numbers",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "tool_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "Londonfucntion",
                "display_name": "Tool Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "add_numbers|b": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "add_numbers|b",
                "value": "dasdasdas",
                "display_name": "b: Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description for b",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "structuredtool dataclass code to tool",
            "icon": "ðŸ",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Python Code Structured Tool",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "tool_code",
              "tool_name",
              "tool_description",
              "return_direct",
              "tool_function",
              "global_variables",
              "_classes",
              "_functions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "PythonCodeStructuredTool-JfnJq"
        },
        "selected": false,
        "width": 384,
        "height": 832,
        "positionAbsolute": {
          "x": -5356.770362853002,
          "y": -683.2492510055507
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "TextInput-acTjx",
        "sourceHandle": "{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-acTjxÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "OpenAIToolsAgent-aSbna",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIToolsAgent-aSbna",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-acTjx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-acTjx{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-acTjxÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-OpenAIToolsAgent-aSbna{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "OpenAIModel-TPOGq",
        "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-TPOGqÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}",
        "target": "OpenAIToolsAgent-aSbna",
        "targetHandle": "{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“LanguageModelÅ“,Å“ToolEnabledLanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "OpenAIToolsAgent-aSbna",
            "inputTypes": [
              "LanguageModel",
              "ToolEnabledLanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-TPOGq",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-TPOGq{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-TPOGqÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}-OpenAIToolsAgent-aSbna{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“LanguageModelÅ“,Å“ToolEnabledLanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "source": "OpenAIToolsAgent-aSbna",
        "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIToolsAgentÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“nameÅ“:Å“responseÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "TextOutput-0SYKB",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“TextOutput-0SYKBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-0SYKB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIToolsAgent",
            "id": "OpenAIToolsAgent-aSbna",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIToolsAgent-aSbna{Å“dataTypeÅ“:Å“OpenAIToolsAgentÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“nameÅ“:Å“responseÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-TextOutput-0SYKB{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“TextOutput-0SYKBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "PythonCodeStructuredTool-JfnJq",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-JfnJqÅ“,Å“nameÅ“:Å“result_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}",
        "target": "OpenAIToolsAgent-aSbna",
        "targetHandle": "{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-aSbna",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "PythonCodeStructuredTool",
            "id": "PythonCodeStructuredTool-JfnJq",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-PythonCodeStructuredTool-JfnJq{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-JfnJqÅ“,Å“nameÅ“:Å“result_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-OpenAIToolsAgent-aSbna{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}"
      }
    ],
    "viewport": {
      "x": 4275.053529248975,
      "y": 395.88154332462204,
      "zoom": 0.7214073138871323
    }
  },
  "metadata": {
    "TextOutput": {
      "count": 1
    },
    "TextInput": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "OpenAIToolsAgent": {
      "count": 1
    },
    "PythonCodeStructuredTool": {
      "count": 1
    },
    "total": 5
  },
  "original": {
    "id": "a0df8e47-f28a-46cc-9952-d723b19b7395",
    "name": "Sequential Tasks Agent",
    "description": "This Agent runs tasks in a predefined sequence.",
    "is_component": false,
    "liked_by_count": "3",
    "downloads_count": "46",
    "metadata": {
      "TextOutput": {
        "count": 1
      },
      "TextInput": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "OpenAIToolsAgent": {
        "count": 1
      },
      "PythonCodeStructuredTool": {
        "count": 1
      },
      "total": 5
    },
    "last_tested_version": "1.0.15",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "TextOutput-0SYKB",
          "type": "genericNode",
          "position": {
            "x": -3615.887482344415,
            "y": -564.1249339849606
          },
          "data": {
            "type": "TextOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.text import TextComponent\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Text to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Display a text output in the Playground.",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "Text Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "TextOutput-0SYKB"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "dragging": false,
          "positionAbsolute": {
            "x": -3615.887482344415,
            "y": -564.1249339849606
          }
        },
        {
          "id": "TextInput-acTjx",
          "type": "genericNode",
          "position": {
            "x": -4826.007109117352,
            "y": -934.8035707851349
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.text import TextComponent\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Text to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "Text Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "TextInput-acTjx"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": -4826.007109117352,
            "y": -934.8035707851349
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-TPOGq",
          "type": "genericNode",
          "position": {
            "x": -4794.247772542848,
            "y": -463.99115774549944
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "json_mode",
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "gpt-4o-mini",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "output_schema",
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1,
                  "name": "seed",
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "0.101",
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "OpenAIModel-TPOGq"
          },
          "selected": false,
          "width": 384,
          "height": 593,
          "positionAbsolute": {
            "x": -4794.247772542848,
            "y": -463.99115774549944
          },
          "dragging": false
        },
        {
          "id": "OpenAIToolsAgent-aSbna",
          "type": "genericNode",
          "position": {
            "x": -4238.071931427172,
            "y": -767.587346582954
          },
          "data": {
            "type": "OpenAIToolsAgent",
            "node": {
              "template": {
                "_type": "Component",
                "chat_history": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_history",
                  "value": "",
                  "display_name": "Chat History",
                  "advanced": true,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel",
                    "ToolEnabledLanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool",
                    "BaseTool"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, List\n\nfrom langchain.agents import create_openai_tools_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.inputs import MultilineInput\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\nfrom axiestudio.schema import Data\n\n\nclass OpenAIToolsAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"OpenAI Tools Agent\"\n    description: str = \"Agent that uses tools via openai-tools.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"OpenAIToolsAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\", \"ToolEnabledLanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_openai_tools_agent(self.llm, self.tools, prompt)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "handle_parsing_errors",
                  "value": true,
                  "display_name": "Handle Parse Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "max_iterations": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_iterations",
                  "value": 15,
                  "display_name": "Max Iterations",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "system_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_prompt",
                  "value": "You are a helpful assistant",
                  "display_name": "System Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System prompt for the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "user_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_prompt",
                  "value": "{input}",
                  "display_name": "Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "This prompt must contain 'input' key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": true,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Agent that uses tools via openai-tools.",
              "icon": "LangChain",
              "base_classes": [
                "AgentExecutor",
                "Message"
              ],
              "display_name": "OpenAI Tools Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "AgentExecutor"
                  ],
                  "selected": "AgentExecutor",
                  "name": "agent",
                  "display_name": "Agent",
                  "method": "build_agent",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "response",
                  "display_name": "Response",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "handle_parsing_errors",
                "verbose",
                "max_iterations",
                "tools",
                "llm",
                "system_prompt",
                "user_prompt",
                "chat_history"
              ],
              "beta": true,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "OpenAIToolsAgent-aSbna"
          },
          "selected": false,
          "width": 384,
          "height": 603,
          "positionAbsolute": {
            "x": -4238.071931427172,
            "y": -767.587346582954
          },
          "dragging": false
        },
        {
          "id": "PythonCodeStructuredTool-JfnJq",
          "type": "genericNode",
          "position": {
            "x": -5356.770362853002,
            "y": -683.2492510055507
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "Component",
                "_classes": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_classes",
                  "value": "[]",
                  "display_name": "Classes",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "_functions": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_functions",
                  "value": "{\"add_numbers\": {\"name\": \"add_numbers\", \"args\": [{\"name\": \"b\", \"annotation\": \"int\"}]}}",
                  "display_name": "Functions",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import BoolInput, DropdownInput, FieldTypes, HandleInput, MessageTextInput, MultilineInput\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"ðŸ\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        (arg.lineno is not None and default.lineno is not None and arg.lineno > default.lineno)\n                        or (\n                            arg.col_offset is not None\n                            and default.col_offset is not None\n                            and arg.col_offset > default.col_offset\n                        )\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n            if isinstance(func[\"args\"], list):\n                func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "global_variables": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "global_variables",
                  "value": "",
                  "display_name": "Global Variables",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Enter the global variables or Create Data Component.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "HandleInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": true,
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tool_code": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "show": true,
                  "name": "tool_code",
                  "value": "def add_numbers() -> string:\n\n    return \"Hello\"\n\n",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "tool_description": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_description",
                  "value": "This function will be triggered when people ask about London",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "tool_function": {
                  "trace_as_metadata": true,
                  "options": [
                    "Failed to parse",
                    "cannot access local variable 'func_arg' where it is not associated with a value"
                  ],
                  "combobox": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_function",
                  "value": "add_numbers",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "tool_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_name",
                  "value": "Londonfucntion",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "add_numbers|b": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "add_numbers|b",
                  "value": "dasdasdas",
                  "display_name": "b: Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description for b",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "structuredtool dataclass code to tool",
              "icon": "ðŸ",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Python Code Structured Tool",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "tool_code",
                "tool_name",
                "tool_description",
                "return_direct",
                "tool_function",
                "global_variables",
                "_classes",
                "_functions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "PythonCodeStructuredTool-JfnJq"
          },
          "selected": false,
          "width": 384,
          "height": 832,
          "positionAbsolute": {
            "x": -5356.770362853002,
            "y": -683.2492510055507
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "TextInput-acTjx",
          "sourceHandle": "{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-acTjxÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "target": "OpenAIToolsAgent-aSbna",
          "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIToolsAgent-aSbna",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TextInput",
              "id": "TextInput-acTjx",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-TextInput-acTjx{Å“dataTypeÅ“:Å“TextInputÅ“,Å“idÅ“:Å“TextInput-acTjxÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-OpenAIToolsAgent-aSbna{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
        },
        {
          "source": "OpenAIModel-TPOGq",
          "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-TPOGqÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}",
          "target": "OpenAIToolsAgent-aSbna",
          "targetHandle": "{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“LanguageModelÅ“,Å“ToolEnabledLanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "OpenAIToolsAgent-aSbna",
              "inputTypes": [
                "LanguageModel",
                "ToolEnabledLanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-TPOGq",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-TPOGq{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-TPOGqÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}-OpenAIToolsAgent-aSbna{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“LanguageModelÅ“,Å“ToolEnabledLanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}"
        },
        {
          "source": "OpenAIToolsAgent-aSbna",
          "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIToolsAgentÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“nameÅ“:Å“responseÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "target": "TextOutput-0SYKB",
          "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“TextOutput-0SYKBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "TextOutput-0SYKB",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIToolsAgent",
              "id": "OpenAIToolsAgent-aSbna",
              "name": "response",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIToolsAgent-aSbna{Å“dataTypeÅ“:Å“OpenAIToolsAgentÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“nameÅ“:Å“responseÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-TextOutput-0SYKB{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“TextOutput-0SYKBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
        },
        {
          "source": "PythonCodeStructuredTool-JfnJq",
          "sourceHandle": "{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-JfnJqÅ“,Å“nameÅ“:Å“result_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}",
          "target": "OpenAIToolsAgent-aSbna",
          "targetHandle": "{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-aSbna",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "PythonCodeStructuredTool",
              "id": "PythonCodeStructuredTool-JfnJq",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-PythonCodeStructuredTool-JfnJq{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-JfnJqÅ“,Å“nameÅ“:Å“result_toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-OpenAIToolsAgent-aSbna{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“OpenAIToolsAgent-aSbnaÅ“,Å“inputTypesÅ“:[Å“ToolÅ“,Å“BaseToolÅ“],Å“typeÅ“:Å“otherÅ“}"
        }
      ],
      "viewport": {
        "x": 4275.053529248975,
        "y": 395.88154332462204,
        "zoom": 0.7214073138871323
      }
    },
    "date_created": "2024-08-19T13:25:16.298Z",
    "date_updated": "2024-08-19T13:25:16.338Z",
    "status": "Public",
    "sort": null,
    "user_updated": "5a08877f-43ac-479a-9650-6b9a6e3e02c8",
    "user_created": {
      "username": "emtechme1",
      "first_name": "emtech",
      "last_name": "ME",
      "id": "5a08877f-43ac-479a-9650-6b9a6e3e02c8"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:02.873Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 40,
    "converter_version": "1.0.0"
  }
}