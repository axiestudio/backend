{
  "id": "8b990fd4-cc8a-41a2-80eb-b9be2a8a9c91",
  "name": "[demo] GraphRAG conversation",
  "description": "Demonstration of graphRAG conversation. Click \"Playground\" at bottom right corner to start conversation. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "jingconsult",
    "first_name": "Jing",
    "last_name": "Consulting",
    "id": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "full_name": "Jing Consulting"
  },
  "store_url": "https://www.langflow.store/store/component/8b990fd4-cc8a-41a2-80eb-b9be2a8a9c91",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-26T03:46:01.191Z",
    "updated": "2024-10-01T09:05:10.290Z",
    "downloaded": "2025-08-19T17:50:07.320Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
        "type": "genericNode",
        "position": {
          "x": -1334.687732541277,
          "y": 66.58733553312331
        },
        "data": {
          "type": "KnowledgeGraphIndexKRetrieverComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nimport json\r\nclass KnowledgeGraphIndexKRetrieverComponent(Component):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        # Populate the node_type dropdown after credentials are set\r\n        if self.neo4j_credentials:\r\n            self.populate_node_type_options()\r\n    \r\n    display_name = \"KnowledgeGraphIndexKRetriever\"\r\n    description = \"Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.\"\r\n    icon = \"custom_components\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", \r\n                         display_name=\"Query\",\r\n                         info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4),\r\n        DropdownInput(\r\n            name=\"node_type\",\r\n            display_name=\"Nodes to be returned\",\r\n            options=[\r\n            ],\r\n            value=\"\"\r\n        ),\r\n        \r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n        \r\n    def populate_node_type_options(self):\r\n        # Fetch node types from Neo4j and populate the options\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        node_types = set()\r\n        with driver.session() as session:\r\n            result = session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\")\r\n            for record in result:\r\n                node_types.update(record[\"labels\"])\r\n\r\n        driver.close()\r\n        \r\n        # Update the dropdown options\r\n        node_type_input = self._get_input_by_name(\"node_type\")\r\n        if node_type_input:\r\n            node_type_input.options = list(node_types)\r\n            if node_types:\r\n                node_type_input.value = list(node_types)[0]  # Set a default value if needed\r\n                \r\n    def build_output(self) -> Data:\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key,\r\n            model=self.openai_embedding_model\r\n        )\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=self.node_type,\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n        results = vector_index.similarity_search(self.user_query, k=self.k)\r\n        # data = Data(data=results)\r\n        self.status = results\r\n        return results\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "k",
                "value": 4,
                "display_name": "Number of results to return",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "node_type": {
                "trace_as_metadata": true,
                "options": [],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "node_type",
                "value": "Document",
                "display_name": "Nodes to be returned",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_embedding_model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_embedding_model",
                "value": "text-embedding-3-small",
                "display_name": "Embedding Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "user_query": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "User query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "Neo4J K Retriever (Vector Search)",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "user_query",
              "k",
              "node_type",
              "openai_embedding_model",
              "openai_api_key",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "KnowledgeGraphIndexKRetrieverComponent-565D8"
        },
        "selected": false,
        "width": 384,
        "height": 768,
        "positionAbsolute": {
          "x": -1334.687732541277,
          "y": 66.58733553312331
        },
        "dragging": false
      },
      {
        "id": "Prompt-EuTRv",
        "type": "genericNode",
        "position": {
          "x": 889.5310184103306,
          "y": 277.6003144750475
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Conversation Memory: {memory}\nContext: {context}\nLabeled Documents: {labeled_documents}\nUser File: {user_file}\nQuestion: {question}\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "question",
                "display_name": "question",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "memory": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "memory",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "user_file": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_file",
                "display_name": "user_file",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "labeled_documents": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "labeled_documents",
                "display_name": "labeled_documents",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Generate a prompt for LLM to process query",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "memory",
                "context",
                "labeled_documents",
                "user_file",
                "question"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Prompt-EuTRv"
        },
        "selected": false,
        "width": 384,
        "height": 726,
        "positionAbsolute": {
          "x": 889.5310184103306,
          "y": 277.6003144750475
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-CbbWh",
        "type": "genericNode",
        "position": {
          "x": 1403.3436178353643,
          "y": 1275.1313254043337
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-CbbWh"
        },
        "selected": false,
        "width": 384,
        "height": 685,
        "positionAbsolute": {
          "x": 1403.3436178353643,
          "y": 1275.1313254043337
        },
        "dragging": false
      },
      {
        "id": "Neo4jCredentialLoader-3OzVQ",
        "type": "genericNode",
        "position": {
          "x": -2597.1327148085256,
          "y": -205.3840003152996
        },
        "data": {
          "type": "Neo4jCredentialLoader",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "neo4j_password": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_password",
                "value": "Jingconsult",
                "display_name": "Neo4j Password",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_url",
                "value": "neo4j://jingconsult.tech:7687",
                "display_name": "Neo4j URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_username": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_username",
                "value": "neo4j",
                "display_name": "Neo4j Username",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "A handy component to load neo4j credentials",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Neo4j Credential Loader",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "credentials",
                "display_name": "Credentials",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "neo4j_url",
              "neo4j_username",
              "neo4j_password"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "Neo4jCredentialLoader-3OzVQ"
        },
        "selected": false,
        "width": 384,
        "height": 469,
        "positionAbsolute": {
          "x": -2597.1327148085256,
          "y": -205.3840003152996
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-GLZBq",
        "type": "genericNode",
        "position": {
          "x": 1917.1052240661318,
          "y": 986.3484963560147
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatOutput-GLZBq"
        },
        "selected": false,
        "width": 384,
        "height": 297,
        "positionAbsolute": {
          "x": 1917.1052240661318,
          "y": 986.3484963560147
        },
        "dragging": false
      },
      {
        "id": "VectorRetrieverParserComponent-CHqZl",
        "type": "genericNode",
        "position": {
          "x": -690.318341057922,
          "y": 504.67586328169546
        },
        "data": {
          "type": "VectorRetrieverParserComponent",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nclass VectorRetrieverParserComponent(Component):\r\n    display_name = \"Vector Retriever Parser\"\r\n    description = \"Parse retrieved Documents\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetrieverParserComponent\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n\r\n    def parsed_data(self) -> Message:\r\n        documents = []\r\n        if self.data:\r\n            for document in self.data:\r\n                documents.append(\r\n                    {\r\n                        \"metadata\": document.metadata,\r\n                        \"page_content\": document.page_content\r\n                    }\r\n                )\r\n        \r\n            return json.dumps(documents)\r\n        else:\r\n            return None\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Parse retrieved Documents",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Vector Retriever Parser",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parsed_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "VectorRetrieverParserComponent-CHqZl"
        },
        "selected": false,
        "width": 384,
        "height": 259,
        "positionAbsolute": {
          "x": -690.318341057922,
          "y": 504.67586328169546
        },
        "dragging": false
      },
      {
        "id": "GraphTransformer-UoIbP",
        "type": "genericNode",
        "position": {
          "x": -2063.35031516878,
          "y": 1101.345286530143
        },
        "data": {
          "type": "GraphTransformer",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output, DropdownInput\r\nfrom axiestudio.schema import Data\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_experimental.graph_transformers import LLMGraphTransformer\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom langchain_core.documents import Document\r\nimport json\r\nclass GraphTransformer(Component):\r\n    display_name = \"Graph Transformer\"\r\n    description = \"Transform any text input into graph. Input: text, schema in JSON to control\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphTransformer\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_text\", display_name=\"Input Text\", value=\"Hello, World!\"),\r\n        MessageTextInput(name=\"schema_text\", display_name=\"Schema Text\", value=\"\"\"{\r\n    \"allowed_nodes\": [],\r\n    \"allowed_relationships\": [],\r\n    \"prompt\": null,\r\n    \"strict_mode\": true,\r\n    \"node_properties\": true,\r\n    \"relationship_properties\": true\r\n}\"\"\"),\r\n        DropdownInput(\r\n            name=\"openai_model\",\r\n            display_name=\"Graph Transformation Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"gpt-4o-mini\",\r\n                \"gpt-4o\",\r\n                \"gpt-4-turbo\",\r\n                \"gpt-3.5-turbo\",\r\n            ],\r\n            value=\"gpt-4o-mini\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    def process_text(self,text: str, transformer: LLMGraphTransformer) -> List[GraphDocument]:\r\n        doc = Document(page_content=text)\r\n        return transformer.convert_to_graph_documents([doc])\r\n    def build_output(self) -> Data:\r\n        schema = json.loads(self.schema_text)\r\n        llm = ChatOpenAI(\r\n            temperature=0,\r\n            model_name=self.openai_model,\r\n            api_key=self.openai_api_key\r\n        )\r\n        llm_transformer = LLMGraphTransformer(\r\n            llm = llm,\r\n            allowed_nodes=schema.get(\"allowed_nodes\", []),  \r\n            allowed_relationships=schema.get(\"allowed_relationships\", []),  \r\n            prompt=schema.get(\"prompt\", None),  \r\n            strict_mode=schema.get(\"strict_mode\", True),  \r\n            node_properties=schema.get(\"node_properties\", True),  \r\n            relationship_properties=schema.get(\"relationship_properties\", True) \r\n        )\r\n        result = self.process_text(self.input_text, llm_transformer)\r\n        self.status = result\r\n        return result\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Input Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_model": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-3.5-turbo"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_model",
                "value": "gpt-4o-mini",
                "display_name": "Graph Transformation Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "schema_text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "schema_text",
                "value": "{\n    \"allowed_nodes\": [],\n    \"allowed_relationships\": [],\n    \"prompt\": null,\n    \"strict_mode\": true,\n    \"node_properties\": true,\n    \"relationship_properties\": true\n}",
                "display_name": "Schema Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Transform any text input into graph. Input: text, schema in JSON to control",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "Graph Transfomrer",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_text",
              "schema_text",
              "openai_model",
              "openai_api_key"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17",
            "official": false
          },
          "id": "GraphTransformer-UoIbP"
        },
        "selected": false,
        "width": 384,
        "height": 582,
        "positionAbsolute": {
          "x": -2063.35031516878,
          "y": 1101.345286530143
        },
        "dragging": false
      },
      {
        "id": "GraphSearchCypher-U5N9V",
        "type": "genericNode",
        "position": {
          "x": -1487.1418763829224,
          "y": 1570.1649038372038
        },
        "data": {
          "type": "GraphSearchCypher",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "User's query graph data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nclass GraphSearchCypherComponent(Component):\r\n    display_name = \"Graph Search Cypher\"\r\n    description = \"Generate cypher to search nodes in the graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphSearchCypher\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"User's query graph data\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Cypher Query\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # only generate queries for nodes search\r\n        output_str = \"\"\r\n        documents = self.data\r\n        node_ids =[]\r\n        for document in documents:\r\n            for node in document.nodes:\r\n                node_ids.append(node.id)\r\n        query = f\"\"\"\r\n        UNWIND {node_ids} as node_id\r\n        MATCH (n {{id: node_id}})\r\n        OPTIONAL MATCH (n)-[]-(doc:Document)\r\n        WITH doc, [key IN keys(doc) WHERE NOT key IN ['elementId', 'id', 'embedding']] AS filteredKeys\r\n        RETURN collect(apoc.map.submap(doc, filteredKeys)) AS docAttributes\r\n        \"\"\"\r\n        self.status = query\r\n        return query\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Generate cypher to search nodes in the graph",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Graph Search Cypher",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Cypher Query",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "GraphSearchCypher-U5N9V"
        },
        "selected": false,
        "width": 384,
        "height": 259,
        "dragging": false,
        "positionAbsolute": {
          "x": -1487.1418763829224,
          "y": 1570.1649038372038
        }
      },
      {
        "id": "GraphRetriever-BX0SN",
        "type": "genericNode",
        "position": {
          "x": -826.3130606407302,
          "y": 1148.594519863012
        },
        "data": {
          "type": "GraphRetriever",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom neo4j import GraphDatabase\r\n\r\nimport json\r\nclass GraphRetriever(Component):\r\n\r\n    \r\n    display_name = \"Graph Retriever\"\r\n    description = \"Execute cypher query to retrieve from knowledge graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRetriever\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"cypher_query\", \r\n                         display_name=\"Cypher Query\",\r\n                         info=\"Cypher query\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n       \r\n                \r\n    def build_output(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        results = None\r\n        with driver.session() as session:\r\n            results = session.run(self.cypher_query)\r\n            data = json.dumps([doc[\"docAttributes\"] for doc in results.data()])\r\n\r\n        driver.close()\r\n        self.status = data  # Update status with extracted data\r\n        return Message(text=data)\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "cypher_query": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cypher_query",
                "value": "",
                "display_name": "Cypher Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Cypher query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Execute cypher query to retrieve from knowledge graph",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Graph Retriever",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cypher_query",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "GraphRetriever-BX0SN"
        },
        "selected": false,
        "width": 384,
        "height": 411,
        "positionAbsolute": {
          "x": -826.3130606407302,
          "y": 1148.594519863012
        },
        "dragging": false
      },
      {
        "id": "CombineText-D63qf",
        "type": "genericNode",
        "position": {
          "x": -33.43760090079604,
          "y": 485.7503649564312
        },
        "data": {
          "type": "CombineText",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "delimiter": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "delimiter",
                "value": "",
                "display_name": "Delimiter",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text1": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text1",
                "value": "",
                "display_name": "First Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text2": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text2",
                "value": "",
                "display_name": "Second Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "icon": "merge",
            "base_classes": [
              "Message"
            ],
            "display_name": "Combine Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "combined_text",
                "display_name": "Combined Text",
                "method": "combine_texts",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "CombineText-D63qf"
        },
        "selected": false,
        "width": 384,
        "height": 497,
        "positionAbsolute": {
          "x": -33.43760090079604,
          "y": 485.7503649564312
        },
        "dragging": false
      },
      {
        "id": "ChatInput-vYDBl",
        "type": "genericNode",
        "position": {
          "x": -2587.3926718110406,
          "y": 663.7444501525915
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "show me the documents that are labeled as 'Education_GeneralEducation' in the graph database",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatInput-vYDBl"
        },
        "selected": true,
        "width": 384,
        "height": 299,
        "positionAbsolute": {
          "x": -2587.3926718110406,
          "y": 663.7444501525915
        },
        "dragging": false
      },
      {
        "id": "Memory-CEDv8",
        "type": "genericNode",
        "position": {
          "x": -443.3263533525806,
          "y": 1681.6828277169948
        },
        "data": {
          "type": "Memory",
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "order": {
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "icon": "message-square-more",
            "base_classes": [
              "BaseChatMemory",
              "Data",
              "Message"
            ],
            "display_name": "Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Messages (Data)",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "BaseChatMemory"
                ],
                "selected": "BaseChatMemory",
                "name": "lc_memory",
                "display_name": "Memory",
                "method": "build_lc_memory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Memory-CEDv8"
        },
        "selected": false,
        "width": 384,
        "height": 377,
        "positionAbsolute": {
          "x": -443.3263533525806,
          "y": 1681.6828277169948
        },
        "dragging": false
      },
      {
        "id": "OpenAIEmbeddings-krlUW",
        "type": "genericNode",
        "position": {
          "x": -1063.7148191296403,
          "y": 2297.4415901852467
        },
        "data": {
          "type": "OpenAIEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom axiestudio.base.embeddings.model import LCEmbeddingsModel\nfrom axiestudio.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-small",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_version": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_base",
              "openai_api_key",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIEmbeddings-krlUW"
        },
        "selected": false,
        "width": 384,
        "height": 383,
        "positionAbsolute": {
          "x": -1063.7148191296403,
          "y": 2297.4415901852467
        },
        "dragging": false
      },
      {
        "id": "VectorRetriever-dfR8T",
        "type": "genericNode",
        "position": {
          "x": 40.713063203535285,
          "y": 2076.1273088332687
        },
        "data": {
          "type": "VectorRetriever",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chat_session_id": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_session_id",
                "value": "",
                "display_name": "Chat Session ID",
                "advanced": false,
                "dynamic": false,
                "info": "Chat Session ID",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom typing import List\r\nfrom langchain_community.vectorstores import PGVector\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom axiestudio.helpers.data import docs_to_data\r\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.utils.connection_string_parser import transform_connection_string\r\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\r\nimport psycopg2\r\nimport numpy as np\r\n\r\nclass VectorRetriever(Component):\r\n    display_name = \"Vector Retriever\"\r\n    description = \"Retrieve vector from postgres database.\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetriever\"\r\n    inputs = [\r\n        StrInput(\r\n            name=\"chat_session_id\",\r\n            display_name=\"Chat Session ID\",\r\n            value=\"\",\r\n            info=\"Chat Session ID\",\r\n        ),\r\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of results to return.\",\r\n            value=4,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        if self.chat_session_id and self.search_query:\r\n            conn = psycopg2.connect(\r\n                host=\"localhost\", \r\n                database=\"ai_tutor\", \r\n                user=\"postgres\", \r\n                password=\"Jing_consult\"\r\n            )\r\n            cursor = conn.cursor()\r\n            chat_session_id = self.chat_session_id\r\n            search_vector = self.embedding.embed_query(str(self.search_query))\r\n            query = \"\"\"\r\n                SELECT file_content\r\n                FROM embedding\r\n                WHERE session_id = %s\r\n                ORDER BY vector <-> %s::vector\r\n                LIMIT 5;\r\n            \"\"\"\r\n            \r\n            cursor.execute(query, (chat_session_id, search_vector))\r\n            # Fetch the top results\r\n            results = cursor.fetchall()\r\n            cursor.close()\r\n            conn.close()\r\n            self.status = results\r\n            return Message(text=str(results))\r\n        else:\r\n            return None",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieve vector from postgres database.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Vector store retriever",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "chat_session_id",
              "search_query",
              "embedding",
              "number_of_results",
              "embedding"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "VectorRetriever-dfR8T"
        },
        "selected": false,
        "width": 384,
        "height": 431,
        "positionAbsolute": {
          "x": 40.713063203535285,
          "y": 2076.1273088332687
        },
        "dragging": false
      },
      {
        "id": "TextInput-S2UdH",
        "type": "genericNode",
        "position": {
          "x": 509.4787434629718,
          "y": 1899.0768948644693
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.text import TextComponent\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema.message import Message\r\n\r\n\r\nclass SystemPromptComponent(TextComponent):\r\n    display_name = \"System prompt\"\r\n    description = \"Inject systemprompt\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    inputs = [\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"System Prompt\", name=\"text\", method=\"text_response\"),\r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        sys_prompt = \"\"\"\r\n\r\nYou are an answer generation component to answer the user's question based on the context information of some documents stored in the graph database and content from user uploaded files that is associated with user's question.\r\n\r\n**Guidelines for Answering Questions:**\r\n1. **Question Analysis:**\r\n   - First, analyze the user's question based on the Conversation Memory if given.\r\n   - The context does not contain the label explicitly. **Never** respond something like 'The document related to that label is not explicitly mentioned in the provided context.'.\r\n   \r\n2. **Label Related Questions:**\r\n   - Both Labeled Documents and Context contain the data retrieved from the graph database, they are always the documents stored in the graph database.\r\n   - If the question is related to the name of documents related to a particular label, check that in Labeled Documents, and answer the user's question based on that.\r\n   - Ignore page numbers, if the documents have same name, they are same documents.\r\n   - If the label is not found, respond with the documents and their labels found in the Labeled Documents the user.\r\n   \r\n3. **Use Conversation Memory:**\r\n   - If the question does not clearly reference a label or document, review the conversation memory. Use it to guide your response, interpreting the user's intent based on prior interactions. \r\n   \r\n4. **Context and User File Priority:**\r\n   - The context is combined text retrieved from the Neo4j graph database from the documents related to the user's question.\r\n   - Always prioritize the context and the user file for answers. If the answer is found in the user file, respond using it as the highest priority source. If the context contains the necessary data, generate a response based on the documents retrieved from the context.\r\n   \r\n5. **Response Generation:**\r\n   - If the answer cannot be derived from conversation memory, context, or the user file, generate an appropriate answer based on your general knowledge. However, if no valid answer can be generated, provide a clear, reasonable explanation or politely decline if it involves sharing raw data or if the information is unavailable.\r\n\r\n6. **Data Handling:**\r\n   - Never provide raw data directly to the user, even if the question asks for it. Instead, summarize or analyze the data from the context and user file to deliver a comprehensive answer.\r\n\r\n7. **Format:**\r\n   - Responses should be concise, accurate, and relevant to the user's question. Do not mention conversation memory, context, or the user file unless the question directly involves them.\r\n\r\n**Contextual Breakdown for Answering Questions:**\r\n- **Conversation Memory:** Previous exchanges during the ongoing chat session.\r\n- **Context:** This includes database documents, their names, and contents.\r\n- **Labeled Documents:** Documents retrieved from the graph database and their labels formatted in JSON format.\r\n- **User File:** Any uploaded or associated files provided by the user, not part of graph database.\r\n- **Question:** user's question.\r\n\r\n\r\n\"\"\"\r\n        message = Message(\r\n            text=sys_prompt,\r\n        )\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Inject systemprompt",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "System Prompt",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "System Prompt",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "TextInput-S2UdH"
        },
        "selected": false,
        "width": 384,
        "height": 215,
        "positionAbsolute": {
          "x": 509.4787434629718,
          "y": 1899.0768948644693
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-3humn",
        "type": "genericNode",
        "position": {
          "x": -631.1558347701043,
          "y": -54.806402603556236
        },
        "data": {
          "type": "DocumentNameParser",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to parse.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nfrom neo4j import GraphDatabase\r\nclass DocumentNameParser(Component):\r\n    display_name = \"Document Name parser\"\r\n    description = \"Parse the retrieved document, extract document names and find their related labels.\"\r\n    icon = \"custom_components\"\r\n    name = \"DocumentNameParser\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to parse.\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Parsed document names with labels\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n    def get_node_labels(self, driver ,source, page):\r\n        \"\"\"Query Neo4j to retrieve the labels of nodes matching the source and page.\"\"\"\r\n        query = \"\"\"\r\n        MATCH (n:Document) WHERE n.source =$source\r\n        RETURN n.source AS source, labels(n) AS labels\r\n        \"\"\"\r\n        with driver.session() as session:\r\n            result = session.run(query, source=source, page=page)\r\n            return [{\"source\": source, \"labels\": record[\"labels\"]} for record in result]\r\n\r\n    def parsed_data(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        url=credentials[\"url\"]\r\n        username=credentials[\"username\"]\r\n        password=credentials[\"password\"]\r\n        driver = GraphDatabase.driver(url, auth=(username, password))\r\n        \r\n        result = []\r\n        seen = set()\r\n        for document in self.data:\r\n            source = document.metadata.get(\"source\")\r\n            page = document.metadata.get(\"page\")\r\n            labels = self.get_node_labels(driver, source, page)\r\n            if labels:\r\n                labels_list = self.get_node_labels(driver, source, page)\r\n\r\n                # Check for uniqueness using a tuple (source, tuple(labels))\r\n                for labels_dict in labels_list:\r\n                    source = labels_dict[\"source\"]\r\n                    labels = tuple(labels_dict[\"labels\"])  # Convert labels to tuple to use in a set\r\n\r\n                    identifier = (source, labels)\r\n                    if identifier not in seen:\r\n                        seen.add(identifier)\r\n                        result.append({\r\n                            \"source\": source,\r\n                            \"labels\": list(labels)  # Convert back to list for JSON output\r\n                        })\r\n        driver.close()\r\n        if result:\r\n            return Message(text=json.dumps(result))\r\n        else:\r\n            return Message(text=\"No nodes found for the given documents.\")\r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Parse the retrieved document, extract document names and find their related labels.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Document Name parser",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Parsed document names with labels",
                "method": "parsed_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CustomComponent-3humn"
        },
        "selected": false,
        "width": 384,
        "height": 373,
        "dragging": false,
        "positionAbsolute": {
          "x": -631.1558347701043,
          "y": -54.806402603556236
        }
      }
    ],
    "edges": [
      {
        "source": "Neo4jCredentialLoader-3OzVQ",
        "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}",
        "target": "KnowledgeGraphIndexKRetrieverComponent-565D8",
        "targetHandle": "{fieldName:neo4j_credentials,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-3OzVQ",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-3OzVQ{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}-KnowledgeGraphIndexKRetrieverComponent-565D8{fieldName:neo4j_credentials,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "KnowledgeGraphIndexKRetrieverComponent-565D8",
        "sourceHandle": "{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}",
        "target": "VectorRetrieverParserComponent-CHqZl",
        "targetHandle": "{fieldName:data,id:VectorRetrieverParserComponent-CHqZl,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "VectorRetrieverParserComponent-CHqZl",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "KnowledgeGraphIndexKRetrieverComponent",
            "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-565D8{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}-VectorRetrieverParserComponent-CHqZl{fieldName:data,id:VectorRetrieverParserComponent-CHqZl,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "GraphTransformer-UoIbP",
        "sourceHandle": "{dataType:GraphTransformer,id:GraphTransformer-UoIbP,name:output,output_types:[Data]}",
        "target": "GraphSearchCypher-U5N9V",
        "targetHandle": "{fieldName:data,id:GraphSearchCypher-U5N9V,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "GraphSearchCypher-U5N9V",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "GraphTransformer",
            "id": "GraphTransformer-UoIbP",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-GraphTransformer-UoIbP{dataType:GraphTransformer,id:GraphTransformer-UoIbP,name:output,output_types:[Data]}-GraphSearchCypher-U5N9V{fieldName:data,id:GraphSearchCypher-U5N9V,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "GraphSearchCypher-U5N9V",
        "sourceHandle": "{dataType:GraphSearchCypher,id:GraphSearchCypher-U5N9V,name:output,output_types:[Message]}",
        "target": "GraphRetriever-BX0SN",
        "targetHandle": "{fieldName:cypher_query,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "cypher_query",
            "id": "GraphRetriever-BX0SN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphSearchCypher",
            "id": "GraphSearchCypher-U5N9V",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphSearchCypher-U5N9V{dataType:GraphSearchCypher,id:GraphSearchCypher-U5N9V,name:output,output_types:[Message]}-GraphRetriever-BX0SN{fieldName:cypher_query,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-3OzVQ",
        "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}",
        "target": "GraphRetriever-BX0SN",
        "targetHandle": "{fieldName:neo4j_credentials,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "GraphRetriever-BX0SN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-3OzVQ",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-3OzVQ{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}-GraphRetriever-BX0SN{fieldName:neo4j_credentials,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "VectorRetrieverParserComponent-CHqZl",
        "sourceHandle": "{dataType:VectorRetrieverParserComponent,id:VectorRetrieverParserComponent-CHqZl,name:text,output_types:[Message]}",
        "target": "CombineText-D63qf",
        "targetHandle": "{fieldName:text1,id:CombineText-D63qf,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-D63qf",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "VectorRetrieverParserComponent",
            "id": "VectorRetrieverParserComponent-CHqZl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-VectorRetrieverParserComponent-CHqZl{dataType:VectorRetrieverParserComponent,id:VectorRetrieverParserComponent-CHqZl,name:text,output_types:[Message]}-CombineText-D63qf{fieldName:text1,id:CombineText-D63qf,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "GraphRetriever-BX0SN",
        "sourceHandle": "{dataType:GraphRetriever,id:GraphRetriever-BX0SN,name:output,output_types:[Message]}",
        "target": "CombineText-D63qf",
        "targetHandle": "{fieldName:text2,id:CombineText-D63qf,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-D63qf",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRetriever",
            "id": "GraphRetriever-BX0SN",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRetriever-BX0SN{dataType:GraphRetriever,id:GraphRetriever-BX0SN,name:output,output_types:[Message]}-CombineText-D63qf{fieldName:text2,id:CombineText-D63qf,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "ChatInput-vYDBl",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
        "target": "KnowledgeGraphIndexKRetrieverComponent-565D8",
        "targetHandle": "{fieldName:user_query,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-vYDBl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-KnowledgeGraphIndexKRetrieverComponent-565D8{fieldName:user_query,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "ChatInput-vYDBl",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
        "target": "Prompt-EuTRv",
        "targetHandle": "{fieldName:question,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-EuTRv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-vYDBl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-Prompt-EuTRv{fieldName:question,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "ChatInput-vYDBl",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
        "target": "GraphTransformer-UoIbP",
        "targetHandle": "{fieldName:input_text,id:GraphTransformer-UoIbP,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_text",
            "id": "GraphTransformer-UoIbP",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-vYDBl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-GraphTransformer-UoIbP{fieldName:input_text,id:GraphTransformer-UoIbP,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "Memory-CEDv8",
        "sourceHandle": "{dataType:Memory,id:Memory-CEDv8,name:messages_text,output_types:[Message]}",
        "target": "Prompt-EuTRv",
        "targetHandle": "{fieldName:memory,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "Prompt-EuTRv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-CEDv8",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Memory-CEDv8{dataType:Memory,id:Memory-CEDv8,name:messages_text,output_types:[Message]}-Prompt-EuTRv{fieldName:memory,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "OpenAIEmbeddings-krlUW",
        "sourceHandle": "{dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-krlUW,name:embeddings,output_types:[Embeddings]}",
        "target": "VectorRetriever-dfR8T",
        "targetHandle": "{fieldName:embedding,id:VectorRetriever-dfR8T,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "VectorRetriever-dfR8T",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-krlUW",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-krlUW{dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-krlUW,name:embeddings,output_types:[Embeddings]}-VectorRetriever-dfR8T{fieldName:embedding,id:VectorRetriever-dfR8T,inputTypes:[Embeddings],type:other}",
        "className": ""
      },
      {
        "source": "ChatInput-vYDBl",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
        "target": "VectorRetriever-dfR8T",
        "targetHandle": "{fieldName:search_query,id:VectorRetriever-dfR8T,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "search_query",
            "id": "VectorRetriever-dfR8T",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-vYDBl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-VectorRetriever-dfR8T{fieldName:search_query,id:VectorRetriever-dfR8T,inputTypes:[Message],type:str}",
        "className": "",
        "selected": false
      },
      {
        "source": "VectorRetriever-dfR8T",
        "sourceHandle": "{dataType:VectorRetriever,id:VectorRetriever-dfR8T,name:output,output_types:[Message]}",
        "target": "Prompt-EuTRv",
        "targetHandle": "{fieldName:user_file,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "user_file",
            "id": "Prompt-EuTRv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "VectorRetriever",
            "id": "VectorRetriever-dfR8T",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-VectorRetriever-dfR8T{dataType:VectorRetriever,id:VectorRetriever-dfR8T,name:output,output_types:[Message]}-Prompt-EuTRv{fieldName:user_file,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "TextInput-S2UdH",
        "sourceHandle": "{dataType:TextInput,id:TextInput-S2UdH,name:text,output_types:[Message]}",
        "target": "OpenAIModel-CbbWh",
        "targetHandle": "{fieldName:system_message,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-CbbWh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-S2UdH",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-S2UdH{dataType:TextInput,id:TextInput-S2UdH,name:text,output_types:[Message]}-OpenAIModel-CbbWh{fieldName:system_message,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "CombineText-D63qf",
        "sourceHandle": "{dataType:CombineText,id:CombineText-D63qf,name:combined_text,output_types:[Message]}",
        "target": "Prompt-EuTRv",
        "targetHandle": "{fieldName:context,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-EuTRv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-D63qf",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CombineText-D63qf{dataType:CombineText,id:CombineText-D63qf,name:combined_text,output_types:[Message]}-Prompt-EuTRv{fieldName:context,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "Prompt-EuTRv",
        "sourceHandle": "{dataType:Prompt,id:Prompt-EuTRv,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-CbbWh",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-CbbWh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-EuTRv",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-EuTRv{dataType:Prompt,id:Prompt-EuTRv,name:prompt,output_types:[Message]}-OpenAIModel-CbbWh{fieldName:input_value,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "OpenAIModel-CbbWh",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-CbbWh,name:text_output,output_types:[Message]}",
        "target": "ChatOutput-GLZBq",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-GLZBq,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-GLZBq",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-CbbWh",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-CbbWh{dataType:OpenAIModel,id:OpenAIModel-CbbWh,name:text_output,output_types:[Message]}-ChatOutput-GLZBq{fieldName:input_value,id:ChatOutput-GLZBq,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-3OzVQ",
        "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}",
        "target": "CustomComponent-3humn",
        "targetHandle": "{fieldName:neo4j_credentials,id:CustomComponent-3humn,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "CustomComponent-3humn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-3OzVQ",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-3OzVQ{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}-CustomComponent-3humn{fieldName:neo4j_credentials,id:CustomComponent-3humn,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "KnowledgeGraphIndexKRetrieverComponent-565D8",
        "sourceHandle": "{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}",
        "target": "CustomComponent-3humn",
        "targetHandle": "{fieldName:data,id:CustomComponent-3humn,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "CustomComponent-3humn",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "KnowledgeGraphIndexKRetrieverComponent",
            "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-565D8{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}-CustomComponent-3humn{fieldName:data,id:CustomComponent-3humn,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "CustomComponent-3humn",
        "sourceHandle": "{dataType:DocumentNameParser,id:CustomComponent-3humn,name:text,output_types:[Message]}",
        "target": "Prompt-EuTRv",
        "targetHandle": "{fieldName:labeled_documents,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "labeled_documents",
            "id": "Prompt-EuTRv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "DocumentNameParser",
            "id": "CustomComponent-3humn",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-3humn{dataType:DocumentNameParser,id:CustomComponent-3humn,name:text,output_types:[Message]}-Prompt-EuTRv{fieldName:labeled_documents,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 759.0814793470773,
      "y": -89.4966701852149,
      "zoom": 0.36097491824267963
    }
  },
  "metadata": {
    "KnowledgeGraphIndexKRetrieverComponent": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "Neo4jCredentialLoader": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "VectorRetrieverParserComponent": {
      "count": 1
    },
    "GraphTransformer": {
      "count": 1
    },
    "GraphSearchCypher": {
      "count": 1
    },
    "GraphRetriever": {
      "count": 1
    },
    "CombineText": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "OpenAIEmbeddings": {
      "count": 1
    },
    "VectorRetriever": {
      "count": 1
    },
    "TextInput": {
      "count": 1
    },
    "CustomComponent": {
      "count": 1
    },
    "total": 16
  },
  "original": {
    "id": "8b990fd4-cc8a-41a2-80eb-b9be2a8a9c91",
    "name": "[demo] GraphRAG conversation",
    "description": "Demonstration of graphRAG conversation. Click \"Playground\" at bottom right corner to start conversation.",
    "is_component": false,
    "liked_by_count": "1",
    "downloads_count": "14",
    "metadata": {
      "KnowledgeGraphIndexKRetrieverComponent": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "Neo4jCredentialLoader": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "VectorRetrieverParserComponent": {
        "count": 1
      },
      "GraphTransformer": {
        "count": 1
      },
      "GraphSearchCypher": {
        "count": 1
      },
      "GraphRetriever": {
        "count": 1
      },
      "CombineText": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "OpenAIEmbeddings": {
        "count": 1
      },
      "VectorRetriever": {
        "count": 1
      },
      "TextInput": {
        "count": 1
      },
      "CustomComponent": {
        "count": 1
      },
      "total": 16
    },
    "last_tested_version": "1.0.17",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
          "type": "genericNode",
          "position": {
            "x": -1334.687732541277,
            "y": 66.58733553312331
          },
          "data": {
            "type": "KnowledgeGraphIndexKRetrieverComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nimport json\r\nclass KnowledgeGraphIndexKRetrieverComponent(Component):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        # Populate the node_type dropdown after credentials are set\r\n        if self.neo4j_credentials:\r\n            self.populate_node_type_options()\r\n    \r\n    display_name = \"KnowledgeGraphIndexKRetriever\"\r\n    description = \"Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.\"\r\n    icon = \"custom_components\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", \r\n                         display_name=\"Query\",\r\n                         info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4),\r\n        DropdownInput(\r\n            name=\"node_type\",\r\n            display_name=\"Nodes to be returned\",\r\n            options=[\r\n            ],\r\n            value=\"\"\r\n        ),\r\n        \r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n        \r\n    def populate_node_type_options(self):\r\n        # Fetch node types from Neo4j and populate the options\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        node_types = set()\r\n        with driver.session() as session:\r\n            result = session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\")\r\n            for record in result:\r\n                node_types.update(record[\"labels\"])\r\n\r\n        driver.close()\r\n        \r\n        # Update the dropdown options\r\n        node_type_input = self._get_input_by_name(\"node_type\")\r\n        if node_type_input:\r\n            node_type_input.options = list(node_types)\r\n            if node_types:\r\n                node_type_input.value = list(node_types)[0]  # Set a default value if needed\r\n                \r\n    def build_output(self) -> Data:\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key,\r\n            model=self.openai_embedding_model\r\n        )\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=self.node_type,\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n        results = vector_index.similarity_search(self.user_query, k=self.k)\r\n        # data = Data(data=results)\r\n        self.status = results\r\n        return results\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "k",
                  "value": 4,
                  "display_name": "Number of results to return",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "node_type": {
                  "trace_as_metadata": true,
                  "options": [],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "node_type",
                  "value": "Document",
                  "display_name": "Nodes to be returned",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput",
                  "load_from_db": false
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_embedding_model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_embedding_model",
                  "value": "text-embedding-3-small",
                  "display_name": "Embedding Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "user_query": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_query",
                  "value": "",
                  "display_name": "Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "User query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "Neo4J K Retriever (Vector Search)",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "user_query",
                "k",
                "node_type",
                "openai_embedding_model",
                "openai_api_key",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "KnowledgeGraphIndexKRetrieverComponent-565D8"
          },
          "selected": false,
          "width": 384,
          "height": 768,
          "positionAbsolute": {
            "x": -1334.687732541277,
            "y": 66.58733553312331
          },
          "dragging": false
        },
        {
          "id": "Prompt-EuTRv",
          "type": "genericNode",
          "position": {
            "x": 889.5310184103306,
            "y": 277.6003144750475
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Conversation Memory: {memory}\nContext: {context}\nLabeled Documents: {labeled_documents}\nUser File: {user_file}\nQuestion: {question}\n",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "question",
                  "display_name": "question",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "memory": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "memory",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "user_file": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_file",
                  "display_name": "user_file",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "labeled_documents": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "labeled_documents",
                  "display_name": "labeled_documents",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Generate a prompt for LLM to process query",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "memory",
                  "context",
                  "labeled_documents",
                  "user_file",
                  "question"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Prompt-EuTRv"
          },
          "selected": false,
          "width": 384,
          "height": 726,
          "positionAbsolute": {
            "x": 889.5310184103306,
            "y": 277.6003144750475
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-CbbWh",
          "type": "genericNode",
          "position": {
            "x": 1403.3436178353643,
            "y": 1275.1313254043337
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-CbbWh"
          },
          "selected": false,
          "width": 384,
          "height": 685,
          "positionAbsolute": {
            "x": 1403.3436178353643,
            "y": 1275.1313254043337
          },
          "dragging": false
        },
        {
          "id": "Neo4jCredentialLoader-3OzVQ",
          "type": "genericNode",
          "position": {
            "x": -2597.1327148085256,
            "y": -205.3840003152996
          },
          "data": {
            "type": "Neo4jCredentialLoader",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "neo4j_password": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_password",
                  "value": "Jingconsult",
                  "display_name": "Neo4j Password",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_url": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_url",
                  "value": "neo4j://jingconsult.tech:7687",
                  "display_name": "Neo4j URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_username": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_username",
                  "value": "neo4j",
                  "display_name": "Neo4j Username",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "A handy component to load neo4j credentials",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Neo4j Credential Loader",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "credentials",
                  "display_name": "Credentials",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "neo4j_url",
                "neo4j_username",
                "neo4j_password"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "Neo4jCredentialLoader-3OzVQ"
          },
          "selected": false,
          "width": 384,
          "height": 469,
          "positionAbsolute": {
            "x": -2597.1327148085256,
            "y": -205.3840003152996
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-GLZBq",
          "type": "genericNode",
          "position": {
            "x": 1917.1052240661318,
            "y": 986.3484963560147
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatOutput-GLZBq"
          },
          "selected": false,
          "width": 384,
          "height": 297,
          "positionAbsolute": {
            "x": 1917.1052240661318,
            "y": 986.3484963560147
          },
          "dragging": false
        },
        {
          "id": "VectorRetrieverParserComponent-CHqZl",
          "type": "genericNode",
          "position": {
            "x": -690.318341057922,
            "y": 504.67586328169546
          },
          "data": {
            "type": "VectorRetrieverParserComponent",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nclass VectorRetrieverParserComponent(Component):\r\n    display_name = \"Vector Retriever Parser\"\r\n    description = \"Parse retrieved Documents\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetrieverParserComponent\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n\r\n    def parsed_data(self) -> Message:\r\n        documents = []\r\n        if self.data:\r\n            for document in self.data:\r\n                documents.append(\r\n                    {\r\n                        \"metadata\": document.metadata,\r\n                        \"page_content\": document.page_content\r\n                    }\r\n                )\r\n        \r\n            return json.dumps(documents)\r\n        else:\r\n            return None\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Parse retrieved Documents",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Vector Retriever Parser",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parsed_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "VectorRetrieverParserComponent-CHqZl"
          },
          "selected": false,
          "width": 384,
          "height": 259,
          "positionAbsolute": {
            "x": -690.318341057922,
            "y": 504.67586328169546
          },
          "dragging": false
        },
        {
          "id": "GraphTransformer-UoIbP",
          "type": "genericNode",
          "position": {
            "x": -2063.35031516878,
            "y": 1101.345286530143
          },
          "data": {
            "type": "GraphTransformer",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output, DropdownInput\r\nfrom axiestudio.schema import Data\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_experimental.graph_transformers import LLMGraphTransformer\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom langchain_core.documents import Document\r\nimport json\r\nclass GraphTransformer(Component):\r\n    display_name = \"Graph Transformer\"\r\n    description = \"Transform any text input into graph. Input: text, schema in JSON to control\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphTransformer\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_text\", display_name=\"Input Text\", value=\"Hello, World!\"),\r\n        MessageTextInput(name=\"schema_text\", display_name=\"Schema Text\", value=\"\"\"{\r\n    \"allowed_nodes\": [],\r\n    \"allowed_relationships\": [],\r\n    \"prompt\": null,\r\n    \"strict_mode\": true,\r\n    \"node_properties\": true,\r\n    \"relationship_properties\": true\r\n}\"\"\"),\r\n        DropdownInput(\r\n            name=\"openai_model\",\r\n            display_name=\"Graph Transformation Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"gpt-4o-mini\",\r\n                \"gpt-4o\",\r\n                \"gpt-4-turbo\",\r\n                \"gpt-3.5-turbo\",\r\n            ],\r\n            value=\"gpt-4o-mini\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    def process_text(self,text: str, transformer: LLMGraphTransformer) -> List[GraphDocument]:\r\n        doc = Document(page_content=text)\r\n        return transformer.convert_to_graph_documents([doc])\r\n    def build_output(self) -> Data:\r\n        schema = json.loads(self.schema_text)\r\n        llm = ChatOpenAI(\r\n            temperature=0,\r\n            model_name=self.openai_model,\r\n            api_key=self.openai_api_key\r\n        )\r\n        llm_transformer = LLMGraphTransformer(\r\n            llm = llm,\r\n            allowed_nodes=schema.get(\"allowed_nodes\", []),  \r\n            allowed_relationships=schema.get(\"allowed_relationships\", []),  \r\n            prompt=schema.get(\"prompt\", None),  \r\n            strict_mode=schema.get(\"strict_mode\", True),  \r\n            node_properties=schema.get(\"node_properties\", True),  \r\n            relationship_properties=schema.get(\"relationship_properties\", True) \r\n        )\r\n        result = self.process_text(self.input_text, llm_transformer)\r\n        self.status = result\r\n        return result\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_text",
                  "value": "",
                  "display_name": "Input Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_model": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-3.5-turbo"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_model",
                  "value": "gpt-4o-mini",
                  "display_name": "Graph Transformation Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "schema_text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "schema_text",
                  "value": "{\n    \"allowed_nodes\": [],\n    \"allowed_relationships\": [],\n    \"prompt\": null,\n    \"strict_mode\": true,\n    \"node_properties\": true,\n    \"relationship_properties\": true\n}",
                  "display_name": "Schema Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Transform any text input into graph. Input: text, schema in JSON to control",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "Graph Transfomrer",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_text",
                "schema_text",
                "openai_model",
                "openai_api_key"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17",
              "official": false
            },
            "id": "GraphTransformer-UoIbP"
          },
          "selected": false,
          "width": 384,
          "height": 582,
          "positionAbsolute": {
            "x": -2063.35031516878,
            "y": 1101.345286530143
          },
          "dragging": false
        },
        {
          "id": "GraphSearchCypher-U5N9V",
          "type": "genericNode",
          "position": {
            "x": -1487.1418763829224,
            "y": 1570.1649038372038
          },
          "data": {
            "type": "GraphSearchCypher",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "User's query graph data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nclass GraphSearchCypherComponent(Component):\r\n    display_name = \"Graph Search Cypher\"\r\n    description = \"Generate cypher to search nodes in the graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphSearchCypher\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"User's query graph data\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Cypher Query\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # only generate queries for nodes search\r\n        output_str = \"\"\r\n        documents = self.data\r\n        node_ids =[]\r\n        for document in documents:\r\n            for node in document.nodes:\r\n                node_ids.append(node.id)\r\n        query = f\"\"\"\r\n        UNWIND {node_ids} as node_id\r\n        MATCH (n {{id: node_id}})\r\n        OPTIONAL MATCH (n)-[]-(doc:Document)\r\n        WITH doc, [key IN keys(doc) WHERE NOT key IN ['elementId', 'id', 'embedding']] AS filteredKeys\r\n        RETURN collect(apoc.map.submap(doc, filteredKeys)) AS docAttributes\r\n        \"\"\"\r\n        self.status = query\r\n        return query\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Generate cypher to search nodes in the graph",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Graph Search Cypher",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Cypher Query",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "GraphSearchCypher-U5N9V"
          },
          "selected": false,
          "width": 384,
          "height": 259,
          "dragging": false,
          "positionAbsolute": {
            "x": -1487.1418763829224,
            "y": 1570.1649038372038
          }
        },
        {
          "id": "GraphRetriever-BX0SN",
          "type": "genericNode",
          "position": {
            "x": -826.3130606407302,
            "y": 1148.594519863012
          },
          "data": {
            "type": "GraphRetriever",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom neo4j import GraphDatabase\r\n\r\nimport json\r\nclass GraphRetriever(Component):\r\n\r\n    \r\n    display_name = \"Graph Retriever\"\r\n    description = \"Execute cypher query to retrieve from knowledge graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRetriever\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"cypher_query\", \r\n                         display_name=\"Cypher Query\",\r\n                         info=\"Cypher query\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n       \r\n                \r\n    def build_output(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        results = None\r\n        with driver.session() as session:\r\n            results = session.run(self.cypher_query)\r\n            data = json.dumps([doc[\"docAttributes\"] for doc in results.data()])\r\n\r\n        driver.close()\r\n        self.status = data  # Update status with extracted data\r\n        return Message(text=data)\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "cypher_query": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cypher_query",
                  "value": "",
                  "display_name": "Cypher Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Cypher query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Execute cypher query to retrieve from knowledge graph",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Graph Retriever",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cypher_query",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "GraphRetriever-BX0SN"
          },
          "selected": false,
          "width": 384,
          "height": 411,
          "positionAbsolute": {
            "x": -826.3130606407302,
            "y": 1148.594519863012
          },
          "dragging": false
        },
        {
          "id": "CombineText-D63qf",
          "type": "genericNode",
          "position": {
            "x": -33.43760090079604,
            "y": 485.7503649564312
          },
          "data": {
            "type": "CombineText",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "delimiter": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "delimiter",
                  "value": "",
                  "display_name": "Delimiter",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text1": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text1",
                  "value": "",
                  "display_name": "First Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The first text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text2": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text2",
                  "value": "",
                  "display_name": "Second Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The second text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
              "icon": "merge",
              "base_classes": [
                "Message"
              ],
              "display_name": "Combine Text",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "combined_text",
                  "display_name": "Combined Text",
                  "method": "combine_texts",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text1",
                "text2",
                "delimiter"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "CombineText-D63qf"
          },
          "selected": false,
          "width": 384,
          "height": 497,
          "positionAbsolute": {
            "x": -33.43760090079604,
            "y": 485.7503649564312
          },
          "dragging": false
        },
        {
          "id": "ChatInput-vYDBl",
          "type": "genericNode",
          "position": {
            "x": -2587.3926718110406,
            "y": 663.7444501525915
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "show me the documents that are labeled as 'Education_GeneralEducation' in the graph database",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatInput-vYDBl"
          },
          "selected": true,
          "width": 384,
          "height": 299,
          "positionAbsolute": {
            "x": -2587.3926718110406,
            "y": 663.7444501525915
          },
          "dragging": false
        },
        {
          "id": "Memory-CEDv8",
          "type": "genericNode",
          "position": {
            "x": -443.3263533525806,
            "y": 1681.6828277169948
          },
          "data": {
            "type": "Memory",
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n_messages",
                  "value": 100,
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "order": {
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "order",
                  "value": "Ascending",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine and User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Filter by sender type.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Filter by sender name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{sender_name}: {text}",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
              "icon": "message-square-more",
              "base_classes": [
                "BaseChatMemory",
                "Data",
                "Message"
              ],
              "display_name": "Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "messages",
                  "display_name": "Messages (Data)",
                  "method": "retrieve_messages",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "messages_text",
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "BaseChatMemory"
                  ],
                  "selected": "BaseChatMemory",
                  "name": "lc_memory",
                  "display_name": "Memory",
                  "method": "build_lc_memory",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Memory-CEDv8"
          },
          "selected": false,
          "width": 384,
          "height": 377,
          "positionAbsolute": {
            "x": -443.3263533525806,
            "y": 1681.6828277169948
          },
          "dragging": false
        },
        {
          "id": "OpenAIEmbeddings-krlUW",
          "type": "genericNode",
          "position": {
            "x": -1063.7148191296403,
            "y": 2297.4415901852467
          },
          "data": {
            "type": "OpenAIEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "client": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "client",
                  "value": "",
                  "display_name": "Client",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom axiestudio.base.embeddings.model import LCEmbeddingsModel\nfrom axiestudio.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "default_headers": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "default_headers",
                  "value": {},
                  "display_name": "Default Headers",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Default headers to use for the API request.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "default_query": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "default_query",
                  "value": {},
                  "display_name": "Default Query",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Default query parameters to use for the API request.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "deployment",
                  "value": "",
                  "display_name": "Deployment",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "dimensions": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "dimensions",
                  "value": "",
                  "display_name": "Dimensions",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "embedding_ctx_length": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding_ctx_length",
                  "value": 1536,
                  "display_name": "Embedding Context Length",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "max_retries": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_retries",
                  "value": 3,
                  "display_name": "Max Retries",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "text-embedding-3-small",
                  "display_name": "Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "openai_api_base": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_type": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_type",
                  "value": "",
                  "display_name": "OpenAI API Type",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_version": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_version",
                  "value": "",
                  "display_name": "OpenAI API Version",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_organization": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_organization",
                  "value": "",
                  "display_name": "OpenAI Organization",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_proxy": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_proxy",
                  "value": "",
                  "display_name": "OpenAI Proxy",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "request_timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "request_timeout",
                  "value": "",
                  "display_name": "Request Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "show_progress_bar": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "show_progress_bar",
                  "value": false,
                  "display_name": "Show Progress Bar",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "skip_empty": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "skip_empty",
                  "value": false,
                  "display_name": "Skip Empty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tiktoken_enable": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tiktoken_enable",
                  "value": true,
                  "display_name": "TikToken Enable",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If False, you must have transformers installed.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tiktoken_model_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tiktoken_model_name",
                  "value": "",
                  "display_name": "TikToken Model Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generate embeddings using OpenAI models.",
              "icon": "OpenAI",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "OpenAI Embeddings",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "default_headers",
                "default_query",
                "chunk_size",
                "client",
                "deployment",
                "embedding_ctx_length",
                "max_retries",
                "model",
                "model_kwargs",
                "openai_api_base",
                "openai_api_key",
                "openai_api_type",
                "openai_api_version",
                "openai_organization",
                "openai_proxy",
                "request_timeout",
                "show_progress_bar",
                "skip_empty",
                "tiktoken_model_name",
                "tiktoken_enable",
                "dimensions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIEmbeddings-krlUW"
          },
          "selected": false,
          "width": 384,
          "height": 383,
          "positionAbsolute": {
            "x": -1063.7148191296403,
            "y": 2297.4415901852467
          },
          "dragging": false
        },
        {
          "id": "VectorRetriever-dfR8T",
          "type": "genericNode",
          "position": {
            "x": 40.713063203535285,
            "y": 2076.1273088332687
          },
          "data": {
            "type": "VectorRetriever",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "chat_session_id": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_session_id",
                  "value": "",
                  "display_name": "Chat Session ID",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Chat Session ID",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom typing import List\r\nfrom langchain_community.vectorstores import PGVector\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom axiestudio.helpers.data import docs_to_data\r\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.utils.connection_string_parser import transform_connection_string\r\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\r\nimport psycopg2\r\nimport numpy as np\r\n\r\nclass VectorRetriever(Component):\r\n    display_name = \"Vector Retriever\"\r\n    description = \"Retrieve vector from postgres database.\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetriever\"\r\n    inputs = [\r\n        StrInput(\r\n            name=\"chat_session_id\",\r\n            display_name=\"Chat Session ID\",\r\n            value=\"\",\r\n            info=\"Chat Session ID\",\r\n        ),\r\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of results to return.\",\r\n            value=4,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        if self.chat_session_id and self.search_query:\r\n            conn = psycopg2.connect(\r\n                host=\"localhost\", \r\n                database=\"ai_tutor\", \r\n                user=\"postgres\", \r\n                password=\"Jing_consult\"\r\n            )\r\n            cursor = conn.cursor()\r\n            chat_session_id = self.chat_session_id\r\n            search_vector = self.embedding.embed_query(str(self.search_query))\r\n            query = \"\"\"\r\n                SELECT file_content\r\n                FROM embedding\r\n                WHERE session_id = %s\r\n                ORDER BY vector <-> %s::vector\r\n                LIMIT 5;\r\n            \"\"\"\r\n            \r\n            cursor.execute(query, (chat_session_id, search_vector))\r\n            # Fetch the top results\r\n            results = cursor.fetchall()\r\n            cursor.close()\r\n            conn.close()\r\n            self.status = results\r\n            return Message(text=str(results))\r\n        else:\r\n            return None",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 4,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieve vector from postgres database.",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Vector store retriever",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "chat_session_id",
                "search_query",
                "embedding",
                "number_of_results",
                "embedding"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "VectorRetriever-dfR8T"
          },
          "selected": false,
          "width": 384,
          "height": 431,
          "positionAbsolute": {
            "x": 40.713063203535285,
            "y": 2076.1273088332687
          },
          "dragging": false
        },
        {
          "id": "TextInput-S2UdH",
          "type": "genericNode",
          "position": {
            "x": 509.4787434629718,
            "y": 1899.0768948644693
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.text import TextComponent\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema.message import Message\r\n\r\n\r\nclass SystemPromptComponent(TextComponent):\r\n    display_name = \"System prompt\"\r\n    description = \"Inject systemprompt\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    inputs = [\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"System Prompt\", name=\"text\", method=\"text_response\"),\r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        sys_prompt = \"\"\"\r\n\r\nYou are an answer generation component to answer the user's question based on the context information of some documents stored in the graph database and content from user uploaded files that is associated with user's question.\r\n\r\n**Guidelines for Answering Questions:**\r\n1. **Question Analysis:**\r\n   - First, analyze the user's question based on the Conversation Memory if given.\r\n   - The context does not contain the label explicitly. **Never** respond something like 'The document related to that label is not explicitly mentioned in the provided context.'.\r\n   \r\n2. **Label Related Questions:**\r\n   - Both Labeled Documents and Context contain the data retrieved from the graph database, they are always the documents stored in the graph database.\r\n   - If the question is related to the name of documents related to a particular label, check that in Labeled Documents, and answer the user's question based on that.\r\n   - Ignore page numbers, if the documents have same name, they are same documents.\r\n   - If the label is not found, respond with the documents and their labels found in the Labeled Documents the user.\r\n   \r\n3. **Use Conversation Memory:**\r\n   - If the question does not clearly reference a label or document, review the conversation memory. Use it to guide your response, interpreting the user's intent based on prior interactions. \r\n   \r\n4. **Context and User File Priority:**\r\n   - The context is combined text retrieved from the Neo4j graph database from the documents related to the user's question.\r\n   - Always prioritize the context and the user file for answers. If the answer is found in the user file, respond using it as the highest priority source. If the context contains the necessary data, generate a response based on the documents retrieved from the context.\r\n   \r\n5. **Response Generation:**\r\n   - If the answer cannot be derived from conversation memory, context, or the user file, generate an appropriate answer based on your general knowledge. However, if no valid answer can be generated, provide a clear, reasonable explanation or politely decline if it involves sharing raw data or if the information is unavailable.\r\n\r\n6. **Data Handling:**\r\n   - Never provide raw data directly to the user, even if the question asks for it. Instead, summarize or analyze the data from the context and user file to deliver a comprehensive answer.\r\n\r\n7. **Format:**\r\n   - Responses should be concise, accurate, and relevant to the user's question. Do not mention conversation memory, context, or the user file unless the question directly involves them.\r\n\r\n**Contextual Breakdown for Answering Questions:**\r\n- **Conversation Memory:** Previous exchanges during the ongoing chat session.\r\n- **Context:** This includes database documents, their names, and contents.\r\n- **Labeled Documents:** Documents retrieved from the graph database and their labels formatted in JSON format.\r\n- **User File:** Any uploaded or associated files provided by the user, not part of graph database.\r\n- **Question:** user's question.\r\n\r\n\r\n\"\"\"\r\n        message = Message(\r\n            text=sys_prompt,\r\n        )\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Inject systemprompt",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "System Prompt",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "System Prompt",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "TextInput-S2UdH"
          },
          "selected": false,
          "width": 384,
          "height": 215,
          "positionAbsolute": {
            "x": 509.4787434629718,
            "y": 1899.0768948644693
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-3humn",
          "type": "genericNode",
          "position": {
            "x": -631.1558347701043,
            "y": -54.806402603556236
          },
          "data": {
            "type": "DocumentNameParser",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to parse.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nfrom neo4j import GraphDatabase\r\nclass DocumentNameParser(Component):\r\n    display_name = \"Document Name parser\"\r\n    description = \"Parse the retrieved document, extract document names and find their related labels.\"\r\n    icon = \"custom_components\"\r\n    name = \"DocumentNameParser\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to parse.\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Parsed document names with labels\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n    def get_node_labels(self, driver ,source, page):\r\n        \"\"\"Query Neo4j to retrieve the labels of nodes matching the source and page.\"\"\"\r\n        query = \"\"\"\r\n        MATCH (n:Document) WHERE n.source =$source\r\n        RETURN n.source AS source, labels(n) AS labels\r\n        \"\"\"\r\n        with driver.session() as session:\r\n            result = session.run(query, source=source, page=page)\r\n            return [{\"source\": source, \"labels\": record[\"labels\"]} for record in result]\r\n\r\n    def parsed_data(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        url=credentials[\"url\"]\r\n        username=credentials[\"username\"]\r\n        password=credentials[\"password\"]\r\n        driver = GraphDatabase.driver(url, auth=(username, password))\r\n        \r\n        result = []\r\n        seen = set()\r\n        for document in self.data:\r\n            source = document.metadata.get(\"source\")\r\n            page = document.metadata.get(\"page\")\r\n            labels = self.get_node_labels(driver, source, page)\r\n            if labels:\r\n                labels_list = self.get_node_labels(driver, source, page)\r\n\r\n                # Check for uniqueness using a tuple (source, tuple(labels))\r\n                for labels_dict in labels_list:\r\n                    source = labels_dict[\"source\"]\r\n                    labels = tuple(labels_dict[\"labels\"])  # Convert labels to tuple to use in a set\r\n\r\n                    identifier = (source, labels)\r\n                    if identifier not in seen:\r\n                        seen.add(identifier)\r\n                        result.append({\r\n                            \"source\": source,\r\n                            \"labels\": list(labels)  # Convert back to list for JSON output\r\n                        })\r\n        driver.close()\r\n        if result:\r\n            return Message(text=json.dumps(result))\r\n        else:\r\n            return Message(text=\"No nodes found for the given documents.\")\r\n\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Parse the retrieved document, extract document names and find their related labels.",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Document Name parser",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Parsed document names with labels",
                  "method": "parsed_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CustomComponent-3humn"
          },
          "selected": false,
          "width": 384,
          "height": 373,
          "dragging": false,
          "positionAbsolute": {
            "x": -631.1558347701043,
            "y": -54.806402603556236
          }
        }
      ],
      "edges": [
        {
          "source": "Neo4jCredentialLoader-3OzVQ",
          "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}",
          "target": "KnowledgeGraphIndexKRetrieverComponent-565D8",
          "targetHandle": "{fieldName:neo4j_credentials,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-3OzVQ",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-3OzVQ{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}-KnowledgeGraphIndexKRetrieverComponent-565D8{fieldName:neo4j_credentials,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "KnowledgeGraphIndexKRetrieverComponent-565D8",
          "sourceHandle": "{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}",
          "target": "VectorRetrieverParserComponent-CHqZl",
          "targetHandle": "{fieldName:data,id:VectorRetrieverParserComponent-CHqZl,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "VectorRetrieverParserComponent-CHqZl",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KnowledgeGraphIndexKRetrieverComponent",
              "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-565D8{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}-VectorRetrieverParserComponent-CHqZl{fieldName:data,id:VectorRetrieverParserComponent-CHqZl,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "GraphTransformer-UoIbP",
          "sourceHandle": "{dataType:GraphTransformer,id:GraphTransformer-UoIbP,name:output,output_types:[Data]}",
          "target": "GraphSearchCypher-U5N9V",
          "targetHandle": "{fieldName:data,id:GraphSearchCypher-U5N9V,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "GraphSearchCypher-U5N9V",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "GraphTransformer",
              "id": "GraphTransformer-UoIbP",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-GraphTransformer-UoIbP{dataType:GraphTransformer,id:GraphTransformer-UoIbP,name:output,output_types:[Data]}-GraphSearchCypher-U5N9V{fieldName:data,id:GraphSearchCypher-U5N9V,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "GraphSearchCypher-U5N9V",
          "sourceHandle": "{dataType:GraphSearchCypher,id:GraphSearchCypher-U5N9V,name:output,output_types:[Message]}",
          "target": "GraphRetriever-BX0SN",
          "targetHandle": "{fieldName:cypher_query,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "cypher_query",
              "id": "GraphRetriever-BX0SN",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphSearchCypher",
              "id": "GraphSearchCypher-U5N9V",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphSearchCypher-U5N9V{dataType:GraphSearchCypher,id:GraphSearchCypher-U5N9V,name:output,output_types:[Message]}-GraphRetriever-BX0SN{fieldName:cypher_query,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-3OzVQ",
          "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}",
          "target": "GraphRetriever-BX0SN",
          "targetHandle": "{fieldName:neo4j_credentials,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "GraphRetriever-BX0SN",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-3OzVQ",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-3OzVQ{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}-GraphRetriever-BX0SN{fieldName:neo4j_credentials,id:GraphRetriever-BX0SN,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "VectorRetrieverParserComponent-CHqZl",
          "sourceHandle": "{dataType:VectorRetrieverParserComponent,id:VectorRetrieverParserComponent-CHqZl,name:text,output_types:[Message]}",
          "target": "CombineText-D63qf",
          "targetHandle": "{fieldName:text1,id:CombineText-D63qf,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "text1",
              "id": "CombineText-D63qf",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "VectorRetrieverParserComponent",
              "id": "VectorRetrieverParserComponent-CHqZl",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-VectorRetrieverParserComponent-CHqZl{dataType:VectorRetrieverParserComponent,id:VectorRetrieverParserComponent-CHqZl,name:text,output_types:[Message]}-CombineText-D63qf{fieldName:text1,id:CombineText-D63qf,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "GraphRetriever-BX0SN",
          "sourceHandle": "{dataType:GraphRetriever,id:GraphRetriever-BX0SN,name:output,output_types:[Message]}",
          "target": "CombineText-D63qf",
          "targetHandle": "{fieldName:text2,id:CombineText-D63qf,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "text2",
              "id": "CombineText-D63qf",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRetriever",
              "id": "GraphRetriever-BX0SN",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRetriever-BX0SN{dataType:GraphRetriever,id:GraphRetriever-BX0SN,name:output,output_types:[Message]}-CombineText-D63qf{fieldName:text2,id:CombineText-D63qf,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "ChatInput-vYDBl",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
          "target": "KnowledgeGraphIndexKRetrieverComponent-565D8",
          "targetHandle": "{fieldName:user_query,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "user_query",
              "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-vYDBl",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-KnowledgeGraphIndexKRetrieverComponent-565D8{fieldName:user_query,id:KnowledgeGraphIndexKRetrieverComponent-565D8,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "ChatInput-vYDBl",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
          "target": "Prompt-EuTRv",
          "targetHandle": "{fieldName:question,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "question",
              "id": "Prompt-EuTRv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-vYDBl",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-Prompt-EuTRv{fieldName:question,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "ChatInput-vYDBl",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
          "target": "GraphTransformer-UoIbP",
          "targetHandle": "{fieldName:input_text,id:GraphTransformer-UoIbP,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_text",
              "id": "GraphTransformer-UoIbP",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-vYDBl",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-GraphTransformer-UoIbP{fieldName:input_text,id:GraphTransformer-UoIbP,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "Memory-CEDv8",
          "sourceHandle": "{dataType:Memory,id:Memory-CEDv8,name:messages_text,output_types:[Message]}",
          "target": "Prompt-EuTRv",
          "targetHandle": "{fieldName:memory,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "Prompt-EuTRv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-CEDv8",
              "name": "messages_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Memory-CEDv8{dataType:Memory,id:Memory-CEDv8,name:messages_text,output_types:[Message]}-Prompt-EuTRv{fieldName:memory,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "OpenAIEmbeddings-krlUW",
          "sourceHandle": "{dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-krlUW,name:embeddings,output_types:[Embeddings]}",
          "target": "VectorRetriever-dfR8T",
          "targetHandle": "{fieldName:embedding,id:VectorRetriever-dfR8T,inputTypes:[Embeddings],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "VectorRetriever-dfR8T",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIEmbeddings",
              "id": "OpenAIEmbeddings-krlUW",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIEmbeddings-krlUW{dataType:OpenAIEmbeddings,id:OpenAIEmbeddings-krlUW,name:embeddings,output_types:[Embeddings]}-VectorRetriever-dfR8T{fieldName:embedding,id:VectorRetriever-dfR8T,inputTypes:[Embeddings],type:other}",
          "className": ""
        },
        {
          "source": "ChatInput-vYDBl",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}",
          "target": "VectorRetriever-dfR8T",
          "targetHandle": "{fieldName:search_query,id:VectorRetriever-dfR8T,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "search_query",
              "id": "VectorRetriever-dfR8T",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-vYDBl",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-vYDBl{dataType:ChatInput,id:ChatInput-vYDBl,name:message,output_types:[Message]}-VectorRetriever-dfR8T{fieldName:search_query,id:VectorRetriever-dfR8T,inputTypes:[Message],type:str}",
          "className": "",
          "selected": false
        },
        {
          "source": "VectorRetriever-dfR8T",
          "sourceHandle": "{dataType:VectorRetriever,id:VectorRetriever-dfR8T,name:output,output_types:[Message]}",
          "target": "Prompt-EuTRv",
          "targetHandle": "{fieldName:user_file,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "user_file",
              "id": "Prompt-EuTRv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "VectorRetriever",
              "id": "VectorRetriever-dfR8T",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-VectorRetriever-dfR8T{dataType:VectorRetriever,id:VectorRetriever-dfR8T,name:output,output_types:[Message]}-Prompt-EuTRv{fieldName:user_file,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "TextInput-S2UdH",
          "sourceHandle": "{dataType:TextInput,id:TextInput-S2UdH,name:text,output_types:[Message]}",
          "target": "OpenAIModel-CbbWh",
          "targetHandle": "{fieldName:system_message,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "system_message",
              "id": "OpenAIModel-CbbWh",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TextInput",
              "id": "TextInput-S2UdH",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-TextInput-S2UdH{dataType:TextInput,id:TextInput-S2UdH,name:text,output_types:[Message]}-OpenAIModel-CbbWh{fieldName:system_message,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "CombineText-D63qf",
          "sourceHandle": "{dataType:CombineText,id:CombineText-D63qf,name:combined_text,output_types:[Message]}",
          "target": "Prompt-EuTRv",
          "targetHandle": "{fieldName:context,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-EuTRv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CombineText",
              "id": "CombineText-D63qf",
              "name": "combined_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CombineText-D63qf{dataType:CombineText,id:CombineText-D63qf,name:combined_text,output_types:[Message]}-Prompt-EuTRv{fieldName:context,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "Prompt-EuTRv",
          "sourceHandle": "{dataType:Prompt,id:Prompt-EuTRv,name:prompt,output_types:[Message]}",
          "target": "OpenAIModel-CbbWh",
          "targetHandle": "{fieldName:input_value,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-CbbWh",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-EuTRv",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-EuTRv{dataType:Prompt,id:Prompt-EuTRv,name:prompt,output_types:[Message]}-OpenAIModel-CbbWh{fieldName:input_value,id:OpenAIModel-CbbWh,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "OpenAIModel-CbbWh",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-CbbWh,name:text_output,output_types:[Message]}",
          "target": "ChatOutput-GLZBq",
          "targetHandle": "{fieldName:input_value,id:ChatOutput-GLZBq,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-GLZBq",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-CbbWh",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-CbbWh{dataType:OpenAIModel,id:OpenAIModel-CbbWh,name:text_output,output_types:[Message]}-ChatOutput-GLZBq{fieldName:input_value,id:ChatOutput-GLZBq,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-3OzVQ",
          "sourceHandle": "{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}",
          "target": "CustomComponent-3humn",
          "targetHandle": "{fieldName:neo4j_credentials,id:CustomComponent-3humn,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "CustomComponent-3humn",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-3OzVQ",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-3OzVQ{dataType:Neo4jCredentialLoader,id:Neo4jCredentialLoader-3OzVQ,name:credentials,output_types:[Message]}-CustomComponent-3humn{fieldName:neo4j_credentials,id:CustomComponent-3humn,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "KnowledgeGraphIndexKRetrieverComponent-565D8",
          "sourceHandle": "{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}",
          "target": "CustomComponent-3humn",
          "targetHandle": "{fieldName:data,id:CustomComponent-3humn,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "CustomComponent-3humn",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KnowledgeGraphIndexKRetrieverComponent",
              "id": "KnowledgeGraphIndexKRetrieverComponent-565D8",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-565D8{dataType:KnowledgeGraphIndexKRetrieverComponent,id:KnowledgeGraphIndexKRetrieverComponent-565D8,name:output,output_types:[Data]}-CustomComponent-3humn{fieldName:data,id:CustomComponent-3humn,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "CustomComponent-3humn",
          "sourceHandle": "{dataType:DocumentNameParser,id:CustomComponent-3humn,name:text,output_types:[Message]}",
          "target": "Prompt-EuTRv",
          "targetHandle": "{fieldName:labeled_documents,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "labeled_documents",
              "id": "Prompt-EuTRv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "DocumentNameParser",
              "id": "CustomComponent-3humn",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-3humn{dataType:DocumentNameParser,id:CustomComponent-3humn,name:text,output_types:[Message]}-Prompt-EuTRv{fieldName:labeled_documents,id:Prompt-EuTRv,inputTypes:[Message,Text],type:str}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 759.0814793470773,
        "y": -89.4966701852149,
        "zoom": 0.36097491824267963
      }
    },
    "date_created": "2024-09-26T03:46:01.191Z",
    "date_updated": "2024-10-01T09:05:10.290Z",
    "status": "Public",
    "sort": null,
    "user_updated": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "user_created": {
      "username": "jingconsult",
      "first_name": "Jing",
      "last_name": "Consulting",
      "id": "6decf44a-a4d8-438a-92d3-df07d49ad213"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:01.437Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 170,
    "converter_version": "1.0.0"
  }
}