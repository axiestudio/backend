{
  "id": "ba76586d-3ee5-43f8-84ce-cc7200389bf0",
  "name": "LinkedIn Vector Store Rag temp",
  "description": "Stores the data from the linked in saved_items csv file to a vector store database (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "SahilSapte",
    "first_name": "Sahil",
    "last_name": "Sapte",
    "id": "694f46e0-3805-4a2c-9852-cd3f52377859",
    "full_name": "Sahil Sapte"
  },
  "store_url": "https://www.langflow.store/store/component/ba76586d-3ee5-43f8-84ce-cc7200389bf0",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-25T07:10:32.392Z",
    "updated": "2024-09-25T07:10:32.487Z",
    "downloaded": "2025-08-19T17:50:07.055Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "CreateListFromFileWithURLParsing-PgDKq",
        "type": "genericNode",
        "position": {
          "x": -45.24037647877924,
          "y": 163.61477234495408
        },
        "data": {
          "type": "CreateListFromFileWithURLParsing",
          "node": {
            "template": {
              "_type": "Component",
              "file_path": {
                "trace_as_metadata": true,
                "file_path": "7eeb8545-4506-4b20-b142-aaaf03ba3d5d\\2024-09-13_09-23-49_Saved_Items.csv",
                "fileTypes": [
                  "csv",
                  "json",
                  "txt"
                ],
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "",
                "display_name": "File Path",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nimport pandas as pd\r\nimport json\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\n\r\nclass CreateListComponent(Component):\r\n    display_name = \"Create List from File with URL Parsing\"\r\n    description = \"Creates a list of texts from a file and fetches content from URLs if present.\"\r\n    icon = \"list\"\r\n    name = \"CreateListFromFileWithURLParsing\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from the provided URLs.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        if self.file_path.endswith(\".csv\"):\r\n            # If the file is a CSV, read using pandas\r\n            df = pd.read_csv(self.file_path)\r\n            # Extract data based on specified column or the entire row as needed\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n        elif self.file_path.endswith(\".json\"):\r\n            # If the file is a JSON, read using the json module\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                else:\r\n                    texts = [str(json_data)]\r\n        else:\r\n            # For text files, read the content directly\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n\r\n        # Separate URLs from regular text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n            else:\r\n                data_list.append(Data(text=text))\r\n\r\n        # If URLs are present, fetch their content\r\n        if urls:\r\n            data_list.extend(self.fetch_url_content(urls))\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "column_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "column_name",
                "value": "savedItem",
                "display_name": "Column Name (for CSV/JSON)",
                "advanced": false,
                "dynamic": false,
                "info": "Specify the column name if using CSV or JSON files.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Creates a list of texts from a file and fetches content from URLs if present.",
            "icon": "list",
            "base_classes": [
              "Data"
            ],
            "display_name": "Create List",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "list",
                "display_name": "Data List",
                "method": "create_list",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_path",
              "column_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CreateListFromFileWithURLParsing-PgDKq"
        },
        "selected": false,
        "width": 384,
        "height": 410,
        "positionAbsolute": {
          "x": -45.24037647877924,
          "y": 163.61477234495408
        },
        "dragging": false
      },
      {
        "id": "Chroma-tqgXG",
        "type": "genericNode",
        "position": {
          "x": 1079.833636986872,
          "y": 136.29324102690651
        },
        "data": {
          "type": "Chroma",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "allow_duplicates": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_duplicates",
                "value": false,
                "display_name": "Allow Duplicates",
                "advanced": true,
                "dynamic": false,
                "info": "If false, will not add documents that are already in the Vector Store.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "chroma_server_cors_allow_origins": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_cors_allow_origins",
                "value": "",
                "display_name": "Server CORS Allow Origins",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "chroma_server_grpc_port": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_grpc_port",
                "value": "",
                "display_name": "Server gRPC Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chroma_server_host": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_host",
                "value": "",
                "display_name": "Server Host",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "chroma_server_http_port": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_http_port",
                "value": "",
                "display_name": "Server HTTP Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chroma_server_ssl_enabled": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_ssl_enabled",
                "value": false,
                "display_name": "Server SSL Enabled",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.base.vectorstores.utils import chroma_collection_to_data\nfrom axiestudio.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom axiestudio.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"axiestudio\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "axiestudio",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "limit": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "limit",
                "value": "",
                "display_name": "Limit",
                "advanced": true,
                "dynamic": false,
                "info": "Limit the number of records to compare when Allow Duplicates is False.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 10,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "persist_directory",
                "value": "C:\\Users\\sahil\\OneDrive\\Desktop\\internship\\axiestudio",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "search_type": {
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "MMR"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_type",
                "value": "Similarity",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Chroma Vector Store with search capabilities",
            "icon": "Chroma",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "Chroma DB",
            "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "collection_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "embedding",
              "chroma_server_cors_allow_origins",
              "chroma_server_host",
              "chroma_server_http_port",
              "chroma_server_grpc_port",
              "chroma_server_ssl_enabled",
              "allow_duplicates",
              "search_type",
              "number_of_results",
              "limit"
            ],
            "beta": false,
            "edited": false
          },
          "id": "Chroma-tqgXG"
        },
        "selected": false,
        "width": 384,
        "height": 653,
        "positionAbsolute": {
          "x": 1079.833636986872,
          "y": 136.29324102690651
        },
        "dragging": false
      },
      {
        "id": "RecursiveCharacterTextSplitter-jBqJZ",
        "type": "genericNode",
        "position": {
          "x": 515.5040103904057,
          "y": -99.13306811944449
        },
        "data": {
          "type": "RecursiveCharacterTextSplitter",
          "node": {
            "template": {
              "_type": "Component",
              "data_input": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_input",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Data"
                ],
                "dynamic": false,
                "info": "The texts to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom axiestudio.base.textsplitters.model import LCTextSplitterComponent\nfrom axiestudio.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom axiestudio.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separators": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separators",
                "value": "",
                "display_name": "Separators",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text trying to keep all related text together.",
            "base_classes": [
              "Data"
            ],
            "display_name": "Recursive Character Text Splitter",
            "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "split_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "chunk_size",
              "chunk_overlap",
              "data_input",
              "separators"
            ],
            "beta": false,
            "edited": false
          },
          "id": "RecursiveCharacterTextSplitter-jBqJZ"
        },
        "selected": false,
        "width": 384,
        "height": 515,
        "positionAbsolute": {
          "x": 515.5040103904057,
          "y": -99.13306811944449
        },
        "dragging": false
      },
      {
        "id": "CohereEmbeddings-3IoMM",
        "type": "genericNode",
        "position": {
          "x": 442.8887226659634,
          "y": 553.3211133188571
        },
        "data": {
          "type": "CohereEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"cohere_api_key\", display_name=\"Cohere API Key\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=self.cohere_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "cohere_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cohere_api_key",
                "value": "",
                "display_name": "Cohere API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "embed-english-v2.0",
                  "embed-multilingual-v2.0",
                  "embed-english-light-v2.0",
                  "embed-multilingual-light-v2.0"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "embed-english-v2.0",
                "display_name": "Model",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "truncate": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "truncate",
                "value": "",
                "display_name": "Truncate",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_agent": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_agent",
                "value": "langchain",
                "display_name": "User Agent",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using Cohere models.",
            "icon": "Cohere",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Cohere Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cohere_api_key",
              "model",
              "truncate",
              "max_retries",
              "user_agent",
              "request_timeout"
            ],
            "beta": false,
            "edited": false
          },
          "id": "CohereEmbeddings-3IoMM"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": 442.8887226659634,
          "y": 553.3211133188571
        },
        "dragging": false
      },
      {
        "id": "CreateListFromFileWithURLParsing-2k4L9",
        "type": "genericNode",
        "position": {
          "x": -1859.426462842832,
          "y": 1318.6188816434924
        },
        "data": {
          "type": "CreateListWithCohere",
          "node": {
            "template": {
              "_type": "Component",
              "file_path": {
                "trace_as_metadata": true,
                "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-09-16_15-23-22_Saved_Items.csv",
                "fileTypes": [
                  "csv",
                  "json",
                  "txt"
                ],
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "",
                "display_name": "File Path",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nimport pandas as pd\r\nimport json\r\nfrom cohere import Client  # Ensure cohere-python is installed\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\nclass CreateListComponentWithCohere(Component):\r\n    display_name = \"Create List with Metadata Extraction using Cohere\"\r\n    description = \"Creates a list of texts from a file and extracts metadata using Cohere.\"\r\n    icon = \"list\"\r\n    name = \"CreateListWithCohere\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        # Initialize Cohere API client with your API key\r\n        super().__init__(**kwargs)  # Pass kwargs to the parent class\r\n        self.cohere_client = Client(\"9zqVEoS4nb8H5tBxVSRDgs9uieiIiwWfmzCpiO1z\")  # Ensure you replace this with your actual API key\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?(www\\.)?([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,})?(:\\d+)?(\\/[^\\s]*)?$\", re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def extract_metadata(self, text: str) -> dict:\r\n        \"\"\"\r\n        Extract metadata like author, timestamp, likes, and comments using Cohere.\r\n        \"\"\"\r\n        response = self.cohere_client.generate(\r\n            model='large',  # Select appropriate Cohere model\r\n            prompt=f\"Extract metadata from the following LinkedIn post:\\n\\n{text}\\n\\nMetadata format: Author, Timestamp, Likes, Comments.\",\r\n            max_tokens=100,\r\n            temperature=0.5\r\n        )\r\n        \r\n        # Assuming the response returns the metadata in the specified format\r\n        metadata_lines = response.generations[0].text.strip().split(',')\r\n        \r\n        # Safely parse the metadata from the Cohere response\r\n        try:\r\n            author = metadata_lines[0].strip()\r\n            timestamp = metadata_lines[1].strip()\r\n            likes = metadata_lines[2].strip()\r\n            comments = metadata_lines[3].strip()\r\n        except IndexError:\r\n            author, timestamp, likes, comments = None, None, None, None\r\n\r\n        return {\r\n            \"author\": author,\r\n            \"timestamp\": timestamp,\r\n            \"likes\": likes,\r\n            \"comments\": comments\r\n        }\r\n\r\n    def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        \r\n        if self.file_path.endswith(\".csv\"):\r\n            df = pd.read_csv(self.file_path)\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n\r\n        elif self.file_path.endswith(\".json\"):\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                else:\r\n                    texts = [str(json_data)]\r\n\r\n        else:\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n\r\n        # Separate URLs from regular text and extract metadata for each text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n            else:\r\n                # Use Cohere to extract metadata\r\n                metadata = self.extract_metadata(text)\r\n                data_list.append(Data(\r\n                    text=text, \r\n                    metadata=metadata\r\n                ))\r\n\r\n        if urls:\r\n            data_list.extend(self.fetch_url_content(urls))\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "column_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "column_name",
                "value": "savedItem",
                "display_name": "Column Name (for CSV/JSON)",
                "advanced": false,
                "dynamic": false,
                "info": "Specify the column name if using CSV or JSON files.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Creates a list of texts from a file and extracts metadata using Cohere.",
            "icon": "list",
            "base_classes": [
              "Data"
            ],
            "display_name": "Create List",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "list",
                "display_name": "Data List",
                "method": "create_list",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_path",
              "column_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CreateListFromFileWithURLParsing-2k4L9"
        },
        "selected": false,
        "width": 384,
        "height": 410,
        "positionAbsolute": {
          "x": -1859.426462842832,
          "y": 1318.6188816434924
        },
        "dragging": false
      },
      {
        "id": "CreateListFromFileWithURLParsing-VXq0w",
        "type": "genericNode",
        "position": {
          "x": -736.0680685720132,
          "y": 1808.8803914491564
        },
        "data": {
          "type": "CreateListFromFileWithURLParsing",
          "node": {
            "template": {
              "_type": "Component",
              "file_path": {
                "trace_as_metadata": true,
                "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-09-16_15-25-50_Saved_Items.csv",
                "fileTypes": [
                  "csv",
                  "json",
                  "txt"
                ],
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "",
                "display_name": "File Path",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nimport pandas as pd\r\nimport json\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\n\r\nclass CreateListComponent(Component):\r\n    display_name = \"Create List from File with URL Parsing\"\r\n    description = \"Creates a list of texts from a file and fetches content from URLs if present.\"\r\n    icon = \"list\"\r\n    name = \"CreateListFromFileWithURLParsing\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from the provided URLs.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        if self.file_path.endswith(\".csv\"):\r\n            # If the file is a CSV, read using pandas\r\n            df = pd.read_csv(self.file_path)\r\n            # Extract data based on specified column or the entire row as needed\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n        elif self.file_path.endswith(\".json\"):\r\n            # If the file is a JSON, read using the json module\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                else:\r\n                    texts = [str(json_data)]\r\n        else:\r\n            # For text files, read the content directly\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n\r\n        # Separate URLs from regular text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n            else:\r\n                data_list.append(Data(text=text))\r\n\r\n        # If URLs are present, fetch their content\r\n        if urls:\r\n            data_list.extend(self.fetch_url_content(urls))\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "column_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "column_name",
                "value": "savedItem",
                "display_name": "Column Name (for CSV/JSON)",
                "advanced": false,
                "dynamic": false,
                "info": "Specify the column name if using CSV or JSON files.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Creates a list of texts from a file and fetches content from URLs if present.",
            "icon": "list",
            "base_classes": [
              "Data"
            ],
            "display_name": "Create List",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "list",
                "display_name": "Data List",
                "method": "create_list",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_path",
              "column_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CreateListFromFileWithURLParsing-VXq0w"
        },
        "selected": false,
        "width": 384,
        "height": 410,
        "positionAbsolute": {
          "x": -736.0680685720132,
          "y": 1808.8803914491564
        },
        "dragging": false
      },
      {
        "id": "ParseData-75n4n",
        "type": "genericNode",
        "position": {
          "x": -225.0545874072593,
          "y": 1710.7346098029468
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{source}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ParseData-75n4n"
        },
        "selected": false,
        "width": 384,
        "height": 372,
        "positionAbsolute": {
          "x": -225.0545874072593,
          "y": 1710.7346098029468
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-NM1VO",
        "type": "genericNode",
        "position": {
          "x": -1916.4439167106952,
          "y": 1783.9095101240175
        },
        "data": {
          "type": "CustomComponentWithMetadata",
          "node": {
            "template": {
              "_type": "Component",
              "file_path": {
                "trace_as_metadata": true,
                "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-09-16_23-46-18_Saved_Items.csv",
                "fileTypes": [
                  "csv",
                  "json",
                  "txt"
                ],
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "",
                "display_name": "File Path",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nimport pandas as pd\r\nimport json\r\nimport logging  # Add logging for debugging\r\nfrom cohere import Client\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\n\r\nclass CustomComponent(Component):\r\n    display_name = \"Custom Component with Metadata Extraction\"\r\n    description = \"Processes a file, extracts metadata using Cohere, and handles URLs.\"\r\n    icon = \"custom_components\"\r\n    name = \"CustomComponentWithMetadata\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.cohere_client = Client(\"9zqVEoS4nb8H5tBxVSRDgs9uieiIiwWfmzCpiO1z\")  # Replace with actual API key\r\n        logging.basicConfig(level=logging.INFO)  # Set logging level\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"Ensures that a URL is valid and formatted correctly.\"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?(www\\.)?([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,})?(:\\d+)?(\\/[^\\s]*)?$\", re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from a list of URLs.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def extract_metadata(self, text: str) -> dict:\r\n        \"\"\"\r\n        Extract metadata like author, timestamp, likes, and comments using Cohere.\r\n        This version adds more robust error handling and logging.\r\n        \"\"\"\r\n        logging.info(f\"Extracting metadata for text: {text[:100]}...\")  # Log the beginning of the text\r\n\r\n        try:\r\n            response = self.cohere_client.generate(\r\n                model='large',\r\n                prompt=f\"Extract metadata from the following LinkedIn post:\\n\\n{text}\\n\\nMetadata format: Author, Timestamp, Likes, Comments.\",\r\n                max_tokens=100,\r\n                temperature=0.5\r\n            )\r\n\r\n            # Log the raw response to inspect it\r\n            logging.info(f\"Cohere Response: {response.generations[0].text.strip()}\")\r\n\r\n            metadata_lines = response.generations[0].text.strip().split(',')\r\n\r\n            # Safely parse the metadata from the Cohere response\r\n            if len(metadata_lines) >= 4:\r\n                author = metadata_lines[0].strip()\r\n                timestamp = metadata_lines[1].strip()\r\n                likes = metadata_lines[2].strip()\r\n                comments = metadata_lines[3].strip()\r\n            else:\r\n                author, timestamp, likes, comments = None, None, None, None\r\n                logging.warning(f\"Metadata parsing error for text: {text[:100]}...\")\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Error while extracting metadata: {e}\")\r\n            author, timestamp, likes, comments = None, None, None, None\r\n\r\n        return {\r\n            \"author\": author,\r\n            \"timestamp\": timestamp,\r\n            \"likes\": likes,\r\n            \"comments\": comments\r\n        }\r\n\r\n    def create_list(self) -> list[Data]:\r\n        \"\"\"\r\n        Reads the input file, processes the text, extracts metadata,\r\n        and returns a list of Data objects.\r\n        \"\"\"\r\n        data_list = []\r\n        urls = []\r\n\r\n        try:\r\n            # Check file type and read accordingly\r\n            if self.file_path.endswith(\".csv\"):\r\n                df = pd.read_csv(self.file_path)\r\n                if self.column_name and self.column_name in df.columns:\r\n                    texts = df[self.column_name].tolist()\r\n                else:\r\n                    texts = df.to_string(index=False).splitlines()\r\n\r\n            elif self.file_path.endswith(\".json\"):\r\n                with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                    json_data = json.load(f)\r\n                    if self.column_name and self.column_name in json_data:\r\n                        texts = json_data[self.column_name]\r\n                    else:\r\n                        texts = [str(json_data)]\r\n\r\n            else:\r\n                with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                    texts = f.readlines()\r\n\r\n            # Separate URLs and regular text, extract metadata\r\n            for text in texts:\r\n                text = text.strip()\r\n                if re.match(r'^(https?:\\/\\/)', text):\r\n                    urls.append(text)\r\n                else:\r\n                    # Extract metadata for regular text using Cohere\r\n                    metadata = self.extract_metadata(text)\r\n                    data_list.append(Data(\r\n                        text=text,\r\n                        metadata=metadata\r\n                    ))\r\n\r\n            # Fetch content for URLs\r\n            if urls:\r\n                data_list.extend(self.fetch_url_content(urls))\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Error in processing file: {e}\")\r\n\r\n        self.status = data_list  # Save the final data list to the component status\r\n        return data_list\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "column_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "column_name",
                "value": "savedItem",
                "display_name": "Column Name (for CSV/JSON)",
                "advanced": false,
                "dynamic": false,
                "info": "Specify the column name if using CSV or JSON files.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Processes a file, extracts metadata using Cohere, and handles URLs.",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "Custom Component",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "list",
                "display_name": "Data List",
                "method": "create_list",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_path",
              "column_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CustomComponent-NM1VO"
        },
        "selected": false,
        "width": 384,
        "height": 410,
        "dragging": false,
        "positionAbsolute": {
          "x": -1916.4439167106952,
          "y": 1783.9095101240175
        }
      },
      {
        "id": "URL-u9xKc",
        "type": "genericNode",
        "position": {
          "x": 284.65151025710816,
          "y": 1400.3331167649205
        },
        "data": {
          "type": "URL",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n\r\n        Parameters:\r\n            text (str): The text from which URLs will be extracted.\r\n\r\n        Returns:\r\n            list[str]: A list of extracted URLs.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        # Extract URLs from the text input\r\n        urls = self.extract_urls(self.text_input)\r\n        \r\n        # Ensure each URL is correctly formatted\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        \r\n        # Load content from URLs\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        \r\n        # Prepare data for output\r\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n        self.status = data\r\n        return data\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "text_input": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_input",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter text containing one or more URLs.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Fetch content from one or more URLs.",
            "icon": "layout-template",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "fetch_content",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text_input"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "URL-u9xKc"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": 284.65151025710816,
          "y": 1400.3331167649205
        },
        "dragging": false
      },
      {
        "id": "URL-oy8gp",
        "type": "genericNode",
        "position": {
          "x": 237.9759125319339,
          "y": 2188.199505973903
        },
        "data": {
          "type": "URL",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nfrom datetime import datetime\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n\r\n        Parameters:\r\n            text (str): The text from which URLs will be extracted.\r\n\r\n        Returns:\r\n            list[str]: A list of extracted URLs.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in self.extract_urls(self.text_input) if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        \r\n        data = []\r\n        for doc in docs:\r\n            # Customize metadata extraction\r\n            metadata = {\r\n                \"url\": doc.metadata.get(\"url\", \"\"),\r\n                \"timestamp\": doc.metadata.get(\"timestamp\", datetime.utcnow().isoformat()),\r\n                \"name\": doc.metadata.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": doc.metadata.get(\"number_of_likes\", 0),\r\n                \"comments\": doc.metadata.get(\"comments\", [])\r\n            }\r\n            data.append(Data(text=doc.page_content, metadata=metadata))\r\n        \r\n        self.status = data\r\n        return data\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "text_input": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_input",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter text containing one or more URLs.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Fetch content from one or more URLs.",
            "icon": "layout-template",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "fetch_content",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text_input"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "URL-oy8gp"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": 237.9759125319339,
          "y": 2188.199505973903
        },
        "dragging": false
      },
      {
        "id": "URL-zEgrB",
        "type": "genericNode",
        "position": {
          "x": 291.6942047521329,
          "y": 1810.7537998858177
        },
        "data": {
          "type": "URL",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nfrom datetime import datetime\r\nimport openai\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\n# Set your OpenAI API key\r\nopenai.api_key = \"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\"\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://' and validates it.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def generate_metadata(self, content: str) -> dict:\r\n        \"\"\"\r\n        Generates metadata using OpenAI's LLM.\r\n        \"\"\"\r\n        response = openai.Completion.create(\r\n            model=\"text-davinci-003\",\r\n            prompt=f\"Extract metadata from the following content:\\n\\n{content}\",\r\n            max_tokens=150\r\n        )\r\n        metadata_str = response.choices[0].text.strip()\r\n        # Parse metadata_str into a dictionary if needed\r\n        # For demonstration, returning metadata_str directly\r\n        return {\"metadata\": metadata_str}\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in self.extract_urls(self.text_input) if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        \r\n        data = []\r\n        for doc in docs:\r\n            # Use OpenAI to enhance metadata extraction\r\n            metadata_content = self.generate_metadata(doc.page_content)\r\n            # Adjust how metadata_content is used based on actual response format\r\n            metadata = {\r\n                \"url\": doc.metadata.get(\"url\", \"\"),\r\n                \"timestamp\": doc.metadata.get(\"timestamp\", datetime.utcnow().isoformat()),\r\n                \"name\": metadata_content.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": metadata_content.get(\"number_of_likes\", 0),\r\n                \"comments\": metadata_content.get(\"comments\", [])\r\n            }\r\n            data.append(Data(text=doc.page_content, metadata=metadata))\r\n        \r\n        self.status = data\r\n        return data\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "text_input": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_input",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter text containing one or more URLs.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Fetch content from one or more URLs.",
            "icon": "layout-template",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "fetch_content",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text_input"
            ],
            "beta": false,
            "edited": true
          },
          "id": "URL-zEgrB"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": 291.6942047521329,
          "y": 1810.7537998858177
        },
        "dragging": false
      },
      {
        "id": "URL-fKgJc",
        "type": "genericNode",
        "position": {
          "x": 749.8831047469989,
          "y": 1677.5585002908444
        },
        "data": {
          "type": "URL",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nfrom datetime import datetime\r\nimport openai\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\n# Set your OpenAI API key\r\nopenai.api_key = \"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\"\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://' and validates it.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def generate_metadata(self, content: str) -> dict:\r\n        \"\"\"\r\n        Generates metadata using OpenAI's LLM.\r\n        \"\"\"\r\n        response = openai.ChatCompletion.create(\r\n            model=\"gpt-3.5-turbo\",  # You can use \"gpt-4\" if you have access\r\n            messages=[\r\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts metadata.\"},\r\n                {\"role\": \"user\", \"content\": f\"Extract metadata from the following content:\\n\\n{content}\"}\r\n            ],\r\n            max_tokens=150\r\n        )\r\n        metadata_str = response.choices[0].message['content'].strip()\r\n        return {\"metadata\": metadata_str}\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in self.extract_urls(self.text_input) if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n\r\n        data = []\r\n        for doc in docs:\r\n            # Use OpenAI to enhance metadata extraction\r\n            metadata_content = self.generate_metadata(doc.page_content)\r\n            # Adjust how metadata_content is used based on actual response format\r\n            metadata = {\r\n                \"url\": doc.metadata.get(\"url\", \"\"),\r\n                \"timestamp\": doc.metadata.get(\"timestamp\", datetime.utcnow().isoformat()),\r\n                \"name\": metadata_content.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": metadata_content.get(\"number_of_likes\", 0),\r\n                \"comments\": metadata_content.get(\"comments\", [])\r\n            }\r\n            data.append(Data(text=doc.page_content, metadata=metadata))\r\n\r\n        self.status = data\r\n        return data\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "text_input": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_input",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter text containing one or more URLs.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Fetch content from one or more URLs.",
            "icon": "layout-template",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "fetch_content",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text_input"
            ],
            "beta": false,
            "edited": true
          },
          "id": "URL-fKgJc"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": 749.8831047469989,
          "y": 1677.5585002908444
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "CreateListFromFileWithURLParsing-PgDKq",
        "sourceHandle": "{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-PgDKq,name:list,output_types:[Data]}",
        "target": "RecursiveCharacterTextSplitter-jBqJZ",
        "targetHandle": "{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data_input",
            "id": "RecursiveCharacterTextSplitter-jBqJZ",
            "inputTypes": [
              "Document",
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CreateListFromFileWithURLParsing",
            "id": "CreateListFromFileWithURLParsing-PgDKq",
            "name": "list",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CreateListFromFileWithURLParsing-PgDKq{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-PgDKq,name:list,output_types:[Data]}-RecursiveCharacterTextSplitter-jBqJZ{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
        "className": ""
      },
      {
        "source": "RecursiveCharacterTextSplitter-jBqJZ",
        "sourceHandle": "{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}",
        "target": "Chroma-tqgXG",
        "targetHandle": "{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "Chroma-tqgXG",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "RecursiveCharacterTextSplitter",
            "id": "RecursiveCharacterTextSplitter-jBqJZ",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-RecursiveCharacterTextSplitter-jBqJZ{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}-Chroma-tqgXG{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "CohereEmbeddings-3IoMM",
        "sourceHandle": "{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}",
        "target": "Chroma-tqgXG",
        "targetHandle": "{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Chroma-tqgXG",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CohereEmbeddings",
            "id": "CohereEmbeddings-3IoMM",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-CohereEmbeddings-3IoMM{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}-Chroma-tqgXG{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
        "className": ""
      },
      {
        "source": "CreateListFromFileWithURLParsing-VXq0w",
        "sourceHandle": "{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-VXq0w,name:list,output_types:[Data]}",
        "target": "ParseData-75n4n",
        "targetHandle": "{fieldName:data,id:ParseData-75n4n,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-75n4n",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CreateListFromFileWithURLParsing",
            "id": "CreateListFromFileWithURLParsing-VXq0w",
            "name": "list",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CreateListFromFileWithURLParsing-VXq0w{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-VXq0w,name:list,output_types:[Data]}-ParseData-75n4n{fieldName:data,id:ParseData-75n4n,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "ParseData-75n4n",
        "sourceHandle": "{dataType:ParseData,id:ParseData-75n4n,name:text,output_types:[Message]}",
        "target": "URL-fKgJc",
        "targetHandle": "{fieldName:text_input,id:URL-fKgJc,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "text_input",
            "id": "URL-fKgJc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-75n4n",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-75n4n{dataType:ParseData,id:ParseData-75n4n,name:text,output_types:[Message]}-URL-fKgJc{fieldName:text_input,id:URL-fKgJc,inputTypes:[Message],type:str}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 381.2169676456191,
      "y": -888.4980293495748,
      "zoom": 0.6075618420861497
    }
  },
  "metadata": {
    "CreateListFromFileWithURLParsing": {
      "count": 3
    },
    "Chroma": {
      "count": 1
    },
    "RecursiveCharacterTextSplitter": {
      "count": 1
    },
    "CohereEmbeddings": {
      "count": 1
    },
    "ParseData": {
      "count": 1
    },
    "CustomComponent": {
      "count": 1
    },
    "URL": {
      "count": 4
    },
    "total": 12
  },
  "original": {
    "id": "ba76586d-3ee5-43f8-84ce-cc7200389bf0",
    "name": "LinkedIn Vector Store Rag temp",
    "description": "Stores the data from the linked in saved_items csv file to a vector store database",
    "is_component": false,
    "liked_by_count": "5",
    "downloads_count": "25",
    "metadata": {
      "CreateListFromFileWithURLParsing": {
        "count": 3
      },
      "Chroma": {
        "count": 1
      },
      "RecursiveCharacterTextSplitter": {
        "count": 1
      },
      "CohereEmbeddings": {
        "count": 1
      },
      "ParseData": {
        "count": 1
      },
      "CustomComponent": {
        "count": 1
      },
      "URL": {
        "count": 4
      },
      "total": 12
    },
    "last_tested_version": "1.0.17",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "CreateListFromFileWithURLParsing-PgDKq",
          "type": "genericNode",
          "position": {
            "x": -45.24037647877924,
            "y": 163.61477234495408
          },
          "data": {
            "type": "CreateListFromFileWithURLParsing",
            "node": {
              "template": {
                "_type": "Component",
                "file_path": {
                  "trace_as_metadata": true,
                  "file_path": "7eeb8545-4506-4b20-b142-aaaf03ba3d5d\\2024-09-13_09-23-49_Saved_Items.csv",
                  "fileTypes": [
                    "csv",
                    "json",
                    "txt"
                  ],
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "file_path",
                  "value": "",
                  "display_name": "File Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nimport pandas as pd\r\nimport json\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\n\r\nclass CreateListComponent(Component):\r\n    display_name = \"Create List from File with URL Parsing\"\r\n    description = \"Creates a list of texts from a file and fetches content from URLs if present.\"\r\n    icon = \"list\"\r\n    name = \"CreateListFromFileWithURLParsing\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from the provided URLs.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        if self.file_path.endswith(\".csv\"):\r\n            # If the file is a CSV, read using pandas\r\n            df = pd.read_csv(self.file_path)\r\n            # Extract data based on specified column or the entire row as needed\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n        elif self.file_path.endswith(\".json\"):\r\n            # If the file is a JSON, read using the json module\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                else:\r\n                    texts = [str(json_data)]\r\n        else:\r\n            # For text files, read the content directly\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n\r\n        # Separate URLs from regular text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n            else:\r\n                data_list.append(Data(text=text))\r\n\r\n        # If URLs are present, fetch their content\r\n        if urls:\r\n            data_list.extend(self.fetch_url_content(urls))\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "column_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "column_name",
                  "value": "savedItem",
                  "display_name": "Column Name (for CSV/JSON)",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Specify the column name if using CSV or JSON files.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Creates a list of texts from a file and fetches content from URLs if present.",
              "icon": "list",
              "base_classes": [
                "Data"
              ],
              "display_name": "Create List",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "list",
                  "display_name": "Data List",
                  "method": "create_list",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "file_path",
                "column_name"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CreateListFromFileWithURLParsing-PgDKq"
          },
          "selected": false,
          "width": 384,
          "height": 410,
          "positionAbsolute": {
            "x": -45.24037647877924,
            "y": 163.61477234495408
          },
          "dragging": false
        },
        {
          "id": "Chroma-tqgXG",
          "type": "genericNode",
          "position": {
            "x": 1079.833636986872,
            "y": 136.29324102690651
          },
          "data": {
            "type": "Chroma",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ingest_data",
                  "value": "",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "allow_duplicates": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_duplicates",
                  "value": false,
                  "display_name": "Allow Duplicates",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If false, will not add documents that are already in the Vector Store.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "chroma_server_cors_allow_origins": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_cors_allow_origins",
                  "value": "",
                  "display_name": "Server CORS Allow Origins",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "chroma_server_grpc_port": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_grpc_port",
                  "value": "",
                  "display_name": "Server gRPC Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chroma_server_host": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_host",
                  "value": "",
                  "display_name": "Server Host",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "chroma_server_http_port": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_http_port",
                  "value": "",
                  "display_name": "Server HTTP Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chroma_server_ssl_enabled": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_ssl_enabled",
                  "value": false,
                  "display_name": "Server SSL Enabled",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.base.vectorstores.utils import chroma_collection_to_data\nfrom axiestudio.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom axiestudio.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"axiestudio\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "collection_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "collection_name",
                  "value": "axiestudio",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "limit": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "limit",
                  "value": "",
                  "display_name": "Limit",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limit the number of records to compare when Allow Duplicates is False.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 10,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "persist_directory",
                  "value": "C:\\Users\\sahil\\OneDrive\\Desktop\\internship\\axiestudio",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "search_type": {
                  "trace_as_metadata": true,
                  "options": [
                    "Similarity",
                    "MMR"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_type",
                  "value": "Similarity",
                  "display_name": "Search Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                }
              },
              "description": "Chroma Vector Store with search capabilities",
              "icon": "Chroma",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "Chroma DB",
              "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "collection_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "embedding",
                "chroma_server_cors_allow_origins",
                "chroma_server_host",
                "chroma_server_http_port",
                "chroma_server_grpc_port",
                "chroma_server_ssl_enabled",
                "allow_duplicates",
                "search_type",
                "number_of_results",
                "limit"
              ],
              "beta": false,
              "edited": false
            },
            "id": "Chroma-tqgXG"
          },
          "selected": false,
          "width": 384,
          "height": 653,
          "positionAbsolute": {
            "x": 1079.833636986872,
            "y": 136.29324102690651
          },
          "dragging": false
        },
        {
          "id": "RecursiveCharacterTextSplitter-jBqJZ",
          "type": "genericNode",
          "position": {
            "x": 515.5040103904057,
            "y": -99.13306811944449
          },
          "data": {
            "type": "RecursiveCharacterTextSplitter",
            "node": {
              "template": {
                "_type": "Component",
                "data_input": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_input",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The texts to split.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "chunk_overlap": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_overlap",
                  "value": 200,
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The amount of overlap between chunks.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum length of each chunk.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom axiestudio.base.textsplitters.model import LCTextSplitterComponent\nfrom axiestudio.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom axiestudio.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separators": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "separators",
                  "value": "",
                  "display_name": "Separators",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Split text trying to keep all related text together.",
              "base_classes": [
                "Data"
              ],
              "display_name": "Recursive Character Text Splitter",
              "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "split_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "chunk_size",
                "chunk_overlap",
                "data_input",
                "separators"
              ],
              "beta": false,
              "edited": false
            },
            "id": "RecursiveCharacterTextSplitter-jBqJZ"
          },
          "selected": false,
          "width": 384,
          "height": 515,
          "positionAbsolute": {
            "x": 515.5040103904057,
            "y": -99.13306811944449
          },
          "dragging": false
        },
        {
          "id": "CohereEmbeddings-3IoMM",
          "type": "genericNode",
          "position": {
            "x": 442.8887226659634,
            "y": 553.3211133188571
          },
          "data": {
            "type": "CohereEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"cohere_api_key\", display_name=\"Cohere API Key\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=self.cohere_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "cohere_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cohere_api_key",
                  "value": "",
                  "display_name": "Cohere API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "max_retries": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_retries",
                  "value": 3,
                  "display_name": "Max Retries",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "embed-english-v2.0",
                    "embed-multilingual-v2.0",
                    "embed-english-light-v2.0",
                    "embed-multilingual-light-v2.0"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "embed-english-v2.0",
                  "display_name": "Model",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "request_timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "request_timeout",
                  "value": "",
                  "display_name": "Request Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "truncate": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "truncate",
                  "value": "",
                  "display_name": "Truncate",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user_agent": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_agent",
                  "value": "langchain",
                  "display_name": "User Agent",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generate embeddings using Cohere models.",
              "icon": "Cohere",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Cohere Embeddings",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cohere_api_key",
                "model",
                "truncate",
                "max_retries",
                "user_agent",
                "request_timeout"
              ],
              "beta": false,
              "edited": false
            },
            "id": "CohereEmbeddings-3IoMM"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": 442.8887226659634,
            "y": 553.3211133188571
          },
          "dragging": false
        },
        {
          "id": "CreateListFromFileWithURLParsing-2k4L9",
          "type": "genericNode",
          "position": {
            "x": -1859.426462842832,
            "y": 1318.6188816434924
          },
          "data": {
            "type": "CreateListWithCohere",
            "node": {
              "template": {
                "_type": "Component",
                "file_path": {
                  "trace_as_metadata": true,
                  "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-09-16_15-23-22_Saved_Items.csv",
                  "fileTypes": [
                    "csv",
                    "json",
                    "txt"
                  ],
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "file_path",
                  "value": "",
                  "display_name": "File Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput",
                  "load_from_db": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nimport pandas as pd\r\nimport json\r\nfrom cohere import Client  # Ensure cohere-python is installed\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\nclass CreateListComponentWithCohere(Component):\r\n    display_name = \"Create List with Metadata Extraction using Cohere\"\r\n    description = \"Creates a list of texts from a file and extracts metadata using Cohere.\"\r\n    icon = \"list\"\r\n    name = \"CreateListWithCohere\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        # Initialize Cohere API client with your API key\r\n        super().__init__(**kwargs)  # Pass kwargs to the parent class\r\n        self.cohere_client = Client(\"9zqVEoS4nb8H5tBxVSRDgs9uieiIiwWfmzCpiO1z\")  # Ensure you replace this with your actual API key\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?(www\\.)?([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,})?(:\\d+)?(\\/[^\\s]*)?$\", re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def extract_metadata(self, text: str) -> dict:\r\n        \"\"\"\r\n        Extract metadata like author, timestamp, likes, and comments using Cohere.\r\n        \"\"\"\r\n        response = self.cohere_client.generate(\r\n            model='large',  # Select appropriate Cohere model\r\n            prompt=f\"Extract metadata from the following LinkedIn post:\\n\\n{text}\\n\\nMetadata format: Author, Timestamp, Likes, Comments.\",\r\n            max_tokens=100,\r\n            temperature=0.5\r\n        )\r\n        \r\n        # Assuming the response returns the metadata in the specified format\r\n        metadata_lines = response.generations[0].text.strip().split(',')\r\n        \r\n        # Safely parse the metadata from the Cohere response\r\n        try:\r\n            author = metadata_lines[0].strip()\r\n            timestamp = metadata_lines[1].strip()\r\n            likes = metadata_lines[2].strip()\r\n            comments = metadata_lines[3].strip()\r\n        except IndexError:\r\n            author, timestamp, likes, comments = None, None, None, None\r\n\r\n        return {\r\n            \"author\": author,\r\n            \"timestamp\": timestamp,\r\n            \"likes\": likes,\r\n            \"comments\": comments\r\n        }\r\n\r\n    def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        \r\n        if self.file_path.endswith(\".csv\"):\r\n            df = pd.read_csv(self.file_path)\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n\r\n        elif self.file_path.endswith(\".json\"):\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                else:\r\n                    texts = [str(json_data)]\r\n\r\n        else:\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n\r\n        # Separate URLs from regular text and extract metadata for each text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n            else:\r\n                # Use Cohere to extract metadata\r\n                metadata = self.extract_metadata(text)\r\n                data_list.append(Data(\r\n                    text=text, \r\n                    metadata=metadata\r\n                ))\r\n\r\n        if urls:\r\n            data_list.extend(self.fetch_url_content(urls))\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "column_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "column_name",
                  "value": "savedItem",
                  "display_name": "Column Name (for CSV/JSON)",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Specify the column name if using CSV or JSON files.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Creates a list of texts from a file and extracts metadata using Cohere.",
              "icon": "list",
              "base_classes": [
                "Data"
              ],
              "display_name": "Create List",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "list",
                  "display_name": "Data List",
                  "method": "create_list",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "file_path",
                "column_name"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CreateListFromFileWithURLParsing-2k4L9"
          },
          "selected": false,
          "width": 384,
          "height": 410,
          "positionAbsolute": {
            "x": -1859.426462842832,
            "y": 1318.6188816434924
          },
          "dragging": false
        },
        {
          "id": "CreateListFromFileWithURLParsing-VXq0w",
          "type": "genericNode",
          "position": {
            "x": -736.0680685720132,
            "y": 1808.8803914491564
          },
          "data": {
            "type": "CreateListFromFileWithURLParsing",
            "node": {
              "template": {
                "_type": "Component",
                "file_path": {
                  "trace_as_metadata": true,
                  "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-09-16_15-25-50_Saved_Items.csv",
                  "fileTypes": [
                    "csv",
                    "json",
                    "txt"
                  ],
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "file_path",
                  "value": "",
                  "display_name": "File Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nimport pandas as pd\r\nimport json\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\n\r\nclass CreateListComponent(Component):\r\n    display_name = \"Create List from File with URL Parsing\"\r\n    description = \"Creates a list of texts from a file and fetches content from URLs if present.\"\r\n    icon = \"list\"\r\n    name = \"CreateListFromFileWithURLParsing\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from the provided URLs.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        if self.file_path.endswith(\".csv\"):\r\n            # If the file is a CSV, read using pandas\r\n            df = pd.read_csv(self.file_path)\r\n            # Extract data based on specified column or the entire row as needed\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n        elif self.file_path.endswith(\".json\"):\r\n            # If the file is a JSON, read using the json module\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                else:\r\n                    texts = [str(json_data)]\r\n        else:\r\n            # For text files, read the content directly\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n\r\n        # Separate URLs from regular text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n            else:\r\n                data_list.append(Data(text=text))\r\n\r\n        # If URLs are present, fetch their content\r\n        if urls:\r\n            data_list.extend(self.fetch_url_content(urls))\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "column_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "column_name",
                  "value": "savedItem",
                  "display_name": "Column Name (for CSV/JSON)",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Specify the column name if using CSV or JSON files.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Creates a list of texts from a file and fetches content from URLs if present.",
              "icon": "list",
              "base_classes": [
                "Data"
              ],
              "display_name": "Create List",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "list",
                  "display_name": "Data List",
                  "method": "create_list",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "file_path",
                "column_name"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CreateListFromFileWithURLParsing-VXq0w"
          },
          "selected": false,
          "width": 384,
          "height": 410,
          "positionAbsolute": {
            "x": -736.0680685720132,
            "y": 1808.8803914491564
          },
          "dragging": false
        },
        {
          "id": "ParseData-75n4n",
          "type": "genericNode",
          "position": {
            "x": -225.0545874072593,
            "y": 1710.7346098029468
          },
          "data": {
            "type": "ParseData",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sep": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sep",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{source}",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Convert Data into plain text following a specified template.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Parse Data",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ParseData-75n4n"
          },
          "selected": false,
          "width": 384,
          "height": 372,
          "positionAbsolute": {
            "x": -225.0545874072593,
            "y": 1710.7346098029468
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-NM1VO",
          "type": "genericNode",
          "position": {
            "x": -1916.4439167106952,
            "y": 1783.9095101240175
          },
          "data": {
            "type": "CustomComponentWithMetadata",
            "node": {
              "template": {
                "_type": "Component",
                "file_path": {
                  "trace_as_metadata": true,
                  "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-09-16_23-46-18_Saved_Items.csv",
                  "fileTypes": [
                    "csv",
                    "json",
                    "txt"
                  ],
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "file_path",
                  "value": "",
                  "display_name": "File Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput",
                  "load_from_db": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nimport pandas as pd\r\nimport json\r\nimport logging  # Add logging for debugging\r\nfrom cohere import Client\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\n\r\n\r\nclass CustomComponent(Component):\r\n    display_name = \"Custom Component with Metadata Extraction\"\r\n    description = \"Processes a file, extracts metadata using Cohere, and handles URLs.\"\r\n    icon = \"custom_components\"\r\n    name = \"CustomComponentWithMetadata\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.cohere_client = Client(\"9zqVEoS4nb8H5tBxVSRDgs9uieiIiwWfmzCpiO1z\")  # Replace with actual API key\r\n        logging.basicConfig(level=logging.INFO)  # Set logging level\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"Ensures that a URL is valid and formatted correctly.\"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?(www\\.)?([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,})?(:\\d+)?(\\/[^\\s]*)?$\", re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from a list of URLs.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        return [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n\r\n    def extract_metadata(self, text: str) -> dict:\r\n        \"\"\"\r\n        Extract metadata like author, timestamp, likes, and comments using Cohere.\r\n        This version adds more robust error handling and logging.\r\n        \"\"\"\r\n        logging.info(f\"Extracting metadata for text: {text[:100]}...\")  # Log the beginning of the text\r\n\r\n        try:\r\n            response = self.cohere_client.generate(\r\n                model='large',\r\n                prompt=f\"Extract metadata from the following LinkedIn post:\\n\\n{text}\\n\\nMetadata format: Author, Timestamp, Likes, Comments.\",\r\n                max_tokens=100,\r\n                temperature=0.5\r\n            )\r\n\r\n            # Log the raw response to inspect it\r\n            logging.info(f\"Cohere Response: {response.generations[0].text.strip()}\")\r\n\r\n            metadata_lines = response.generations[0].text.strip().split(',')\r\n\r\n            # Safely parse the metadata from the Cohere response\r\n            if len(metadata_lines) >= 4:\r\n                author = metadata_lines[0].strip()\r\n                timestamp = metadata_lines[1].strip()\r\n                likes = metadata_lines[2].strip()\r\n                comments = metadata_lines[3].strip()\r\n            else:\r\n                author, timestamp, likes, comments = None, None, None, None\r\n                logging.warning(f\"Metadata parsing error for text: {text[:100]}...\")\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Error while extracting metadata: {e}\")\r\n            author, timestamp, likes, comments = None, None, None, None\r\n\r\n        return {\r\n            \"author\": author,\r\n            \"timestamp\": timestamp,\r\n            \"likes\": likes,\r\n            \"comments\": comments\r\n        }\r\n\r\n    def create_list(self) -> list[Data]:\r\n        \"\"\"\r\n        Reads the input file, processes the text, extracts metadata,\r\n        and returns a list of Data objects.\r\n        \"\"\"\r\n        data_list = []\r\n        urls = []\r\n\r\n        try:\r\n            # Check file type and read accordingly\r\n            if self.file_path.endswith(\".csv\"):\r\n                df = pd.read_csv(self.file_path)\r\n                if self.column_name and self.column_name in df.columns:\r\n                    texts = df[self.column_name].tolist()\r\n                else:\r\n                    texts = df.to_string(index=False).splitlines()\r\n\r\n            elif self.file_path.endswith(\".json\"):\r\n                with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                    json_data = json.load(f)\r\n                    if self.column_name and self.column_name in json_data:\r\n                        texts = json_data[self.column_name]\r\n                    else:\r\n                        texts = [str(json_data)]\r\n\r\n            else:\r\n                with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                    texts = f.readlines()\r\n\r\n            # Separate URLs and regular text, extract metadata\r\n            for text in texts:\r\n                text = text.strip()\r\n                if re.match(r'^(https?:\\/\\/)', text):\r\n                    urls.append(text)\r\n                else:\r\n                    # Extract metadata for regular text using Cohere\r\n                    metadata = self.extract_metadata(text)\r\n                    data_list.append(Data(\r\n                        text=text,\r\n                        metadata=metadata\r\n                    ))\r\n\r\n            # Fetch content for URLs\r\n            if urls:\r\n                data_list.extend(self.fetch_url_content(urls))\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Error in processing file: {e}\")\r\n\r\n        self.status = data_list  # Save the final data list to the component status\r\n        return data_list\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "column_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "column_name",
                  "value": "savedItem",
                  "display_name": "Column Name (for CSV/JSON)",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Specify the column name if using CSV or JSON files.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Processes a file, extracts metadata using Cohere, and handles URLs.",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "Custom Component",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "list",
                  "display_name": "Data List",
                  "method": "create_list",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "file_path",
                "column_name"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CustomComponent-NM1VO"
          },
          "selected": false,
          "width": 384,
          "height": 410,
          "dragging": false,
          "positionAbsolute": {
            "x": -1916.4439167106952,
            "y": 1783.9095101240175
          }
        },
        {
          "id": "URL-u9xKc",
          "type": "genericNode",
          "position": {
            "x": 284.65151025710816,
            "y": 1400.3331167649205
          },
          "data": {
            "type": "URL",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n\r\n        Parameters:\r\n            text (str): The text from which URLs will be extracted.\r\n\r\n        Returns:\r\n            list[str]: A list of extracted URLs.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        # Extract URLs from the text input\r\n        urls = self.extract_urls(self.text_input)\r\n        \r\n        # Ensure each URL is correctly formatted\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        \r\n        # Load content from URLs\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        \r\n        # Prepare data for output\r\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\r\n        self.status = data\r\n        return data\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "text_input": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_input",
                  "value": "",
                  "display_name": "Text Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter text containing one or more URLs.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Fetch content from one or more URLs.",
              "icon": "layout-template",
              "base_classes": [
                "Data"
              ],
              "display_name": "URL",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "fetch_content",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text_input"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "URL-u9xKc"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": 284.65151025710816,
            "y": 1400.3331167649205
          },
          "dragging": false
        },
        {
          "id": "URL-oy8gp",
          "type": "genericNode",
          "position": {
            "x": 237.9759125319339,
            "y": 2188.199505973903
          },
          "data": {
            "type": "URL",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nfrom datetime import datetime\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n\r\n        Parameters:\r\n            text (str): The text from which URLs will be extracted.\r\n\r\n        Returns:\r\n            list[str]: A list of extracted URLs.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\r\n        Raises an error if the string is not a valid URL.\r\n\r\n        Parameters:\r\n            string (str): The string to be checked and possibly modified.\r\n\r\n        Returns:\r\n            str: The modified string that is ensured to be a URL.\r\n\r\n        Raises:\r\n            ValueError: If the string is not a valid URL.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in self.extract_urls(self.text_input) if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        \r\n        data = []\r\n        for doc in docs:\r\n            # Customize metadata extraction\r\n            metadata = {\r\n                \"url\": doc.metadata.get(\"url\", \"\"),\r\n                \"timestamp\": doc.metadata.get(\"timestamp\", datetime.utcnow().isoformat()),\r\n                \"name\": doc.metadata.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": doc.metadata.get(\"number_of_likes\", 0),\r\n                \"comments\": doc.metadata.get(\"comments\", [])\r\n            }\r\n            data.append(Data(text=doc.page_content, metadata=metadata))\r\n        \r\n        self.status = data\r\n        return data\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "text_input": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_input",
                  "value": "",
                  "display_name": "Text Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter text containing one or more URLs.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Fetch content from one or more URLs.",
              "icon": "layout-template",
              "base_classes": [
                "Data"
              ],
              "display_name": "URL",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "fetch_content",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text_input"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "URL-oy8gp"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": 237.9759125319339,
            "y": 2188.199505973903
          },
          "dragging": false
        },
        {
          "id": "URL-zEgrB",
          "type": "genericNode",
          "position": {
            "x": 291.6942047521329,
            "y": 1810.7537998858177
          },
          "data": {
            "type": "URL",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nfrom datetime import datetime\r\nimport openai\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\n# Set your OpenAI API key\r\nopenai.api_key = \"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\"\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://' and validates it.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def generate_metadata(self, content: str) -> dict:\r\n        \"\"\"\r\n        Generates metadata using OpenAI's LLM.\r\n        \"\"\"\r\n        response = openai.Completion.create(\r\n            model=\"text-davinci-003\",\r\n            prompt=f\"Extract metadata from the following content:\\n\\n{content}\",\r\n            max_tokens=150\r\n        )\r\n        metadata_str = response.choices[0].text.strip()\r\n        # Parse metadata_str into a dictionary if needed\r\n        # For demonstration, returning metadata_str directly\r\n        return {\"metadata\": metadata_str}\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in self.extract_urls(self.text_input) if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        \r\n        data = []\r\n        for doc in docs:\r\n            # Use OpenAI to enhance metadata extraction\r\n            metadata_content = self.generate_metadata(doc.page_content)\r\n            # Adjust how metadata_content is used based on actual response format\r\n            metadata = {\r\n                \"url\": doc.metadata.get(\"url\", \"\"),\r\n                \"timestamp\": doc.metadata.get(\"timestamp\", datetime.utcnow().isoformat()),\r\n                \"name\": metadata_content.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": metadata_content.get(\"number_of_likes\", 0),\r\n                \"comments\": metadata_content.get(\"comments\", [])\r\n            }\r\n            data.append(Data(text=doc.page_content, metadata=metadata))\r\n        \r\n        self.status = data\r\n        return data\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "text_input": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_input",
                  "value": "",
                  "display_name": "Text Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter text containing one or more URLs.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Fetch content from one or more URLs.",
              "icon": "layout-template",
              "base_classes": [
                "Data"
              ],
              "display_name": "URL",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "fetch_content",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text_input"
              ],
              "beta": false,
              "edited": true
            },
            "id": "URL-zEgrB"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": 291.6942047521329,
            "y": 1810.7537998858177
          },
          "dragging": false
        },
        {
          "id": "URL-fKgJc",
          "type": "genericNode",
          "position": {
            "x": 749.8831047469989,
            "y": 1677.5585002908444
          },
          "data": {
            "type": "URL",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nfrom datetime import datetime\r\nimport openai\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\n\r\n# Set your OpenAI API key\r\nopenai.api_key = \"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\"\r\n\r\nclass URLComponent(Component):\r\n    display_name = \"URL\"\r\n    description = \"Fetch content from one or more URLs.\"\r\n    icon = \"layout-template\"\r\n    name = \"URL\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"text_input\",\r\n            display_name=\"Text Input\",\r\n            info=\"Enter text containing one or more URLs.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\r\n    ]\r\n\r\n    def extract_urls(self, text: str) -> list[str]:\r\n        \"\"\"\r\n        Extracts URLs from the given text using a regular expression.\r\n        \"\"\"\r\n        url_pattern = re.compile(\r\n            r'(https?://[^\\s]+)',  # Basic URL pattern\r\n            re.IGNORECASE,\r\n        )\r\n        return url_pattern.findall(text)\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"\r\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://' and validates it.\r\n        \"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)?\"  # optional protocol\r\n            r\"(www\\.)?\"  # optional www\r\n            r\"([a-zA-Z0-9.-]+)\"  # domain\r\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\r\n            r\"(:\\d+)?\"  # optional port\r\n            r\"(\\/[^\\s]*)?$\",  # optional path\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    def generate_metadata(self, content: str) -> dict:\r\n        \"\"\"\r\n        Generates metadata using OpenAI's LLM.\r\n        \"\"\"\r\n        response = openai.ChatCompletion.create(\r\n            model=\"gpt-3.5-turbo\",  # You can use \"gpt-4\" if you have access\r\n            messages=[\r\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts metadata.\"},\r\n                {\"role\": \"user\", \"content\": f\"Extract metadata from the following content:\\n\\n{content}\"}\r\n            ],\r\n            max_tokens=150\r\n        )\r\n        metadata_str = response.choices[0].message['content'].strip()\r\n        return {\"metadata\": metadata_str}\r\n\r\n    def fetch_content(self) -> list[Data]:\r\n        urls = [self.ensure_url(url.strip()) for url in self.extract_urls(self.text_input) if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n\r\n        data = []\r\n        for doc in docs:\r\n            # Use OpenAI to enhance metadata extraction\r\n            metadata_content = self.generate_metadata(doc.page_content)\r\n            # Adjust how metadata_content is used based on actual response format\r\n            metadata = {\r\n                \"url\": doc.metadata.get(\"url\", \"\"),\r\n                \"timestamp\": doc.metadata.get(\"timestamp\", datetime.utcnow().isoformat()),\r\n                \"name\": metadata_content.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": metadata_content.get(\"number_of_likes\", 0),\r\n                \"comments\": metadata_content.get(\"comments\", [])\r\n            }\r\n            data.append(Data(text=doc.page_content, metadata=metadata))\r\n\r\n        self.status = data\r\n        return data\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "text_input": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_input",
                  "value": "",
                  "display_name": "Text Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter text containing one or more URLs.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Fetch content from one or more URLs.",
              "icon": "layout-template",
              "base_classes": [
                "Data"
              ],
              "display_name": "URL",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "fetch_content",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text_input"
              ],
              "beta": false,
              "edited": true
            },
            "id": "URL-fKgJc"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": 749.8831047469989,
            "y": 1677.5585002908444
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "CreateListFromFileWithURLParsing-PgDKq",
          "sourceHandle": "{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-PgDKq,name:list,output_types:[Data]}",
          "target": "RecursiveCharacterTextSplitter-jBqJZ",
          "targetHandle": "{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data_input",
              "id": "RecursiveCharacterTextSplitter-jBqJZ",
              "inputTypes": [
                "Document",
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CreateListFromFileWithURLParsing",
              "id": "CreateListFromFileWithURLParsing-PgDKq",
              "name": "list",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-CreateListFromFileWithURLParsing-PgDKq{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-PgDKq,name:list,output_types:[Data]}-RecursiveCharacterTextSplitter-jBqJZ{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
          "className": ""
        },
        {
          "source": "RecursiveCharacterTextSplitter-jBqJZ",
          "sourceHandle": "{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}",
          "target": "Chroma-tqgXG",
          "targetHandle": "{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "Chroma-tqgXG",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "RecursiveCharacterTextSplitter",
              "id": "RecursiveCharacterTextSplitter-jBqJZ",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-RecursiveCharacterTextSplitter-jBqJZ{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}-Chroma-tqgXG{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "CohereEmbeddings-3IoMM",
          "sourceHandle": "{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}",
          "target": "Chroma-tqgXG",
          "targetHandle": "{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "Chroma-tqgXG",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CohereEmbeddings",
              "id": "CohereEmbeddings-3IoMM",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-CohereEmbeddings-3IoMM{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}-Chroma-tqgXG{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
          "className": ""
        },
        {
          "source": "CreateListFromFileWithURLParsing-VXq0w",
          "sourceHandle": "{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-VXq0w,name:list,output_types:[Data]}",
          "target": "ParseData-75n4n",
          "targetHandle": "{fieldName:data,id:ParseData-75n4n,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ParseData-75n4n",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CreateListFromFileWithURLParsing",
              "id": "CreateListFromFileWithURLParsing-VXq0w",
              "name": "list",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-CreateListFromFileWithURLParsing-VXq0w{dataType:CreateListFromFileWithURLParsing,id:CreateListFromFileWithURLParsing-VXq0w,name:list,output_types:[Data]}-ParseData-75n4n{fieldName:data,id:ParseData-75n4n,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "ParseData-75n4n",
          "sourceHandle": "{dataType:ParseData,id:ParseData-75n4n,name:text,output_types:[Message]}",
          "target": "URL-fKgJc",
          "targetHandle": "{fieldName:text_input,id:URL-fKgJc,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "text_input",
              "id": "URL-fKgJc",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ParseData",
              "id": "ParseData-75n4n",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ParseData-75n4n{dataType:ParseData,id:ParseData-75n4n,name:text,output_types:[Message]}-URL-fKgJc{fieldName:text_input,id:URL-fKgJc,inputTypes:[Message],type:str}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 381.2169676456191,
        "y": -888.4980293495748,
        "zoom": 0.6075618420861497
      }
    },
    "date_created": "2024-09-25T07:10:32.392Z",
    "date_updated": "2024-09-25T07:10:32.487Z",
    "status": "Public",
    "sort": null,
    "user_updated": "694f46e0-3805-4a2c-9852-cd3f52377859",
    "user_created": {
      "username": "SahilSapte",
      "first_name": "Sahil",
      "last_name": "Sapte",
      "id": "694f46e0-3805-4a2c-9852-cd3f52377859"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:04.597Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 94,
    "converter_version": "1.0.0"
  }
}