{
  "id": "43eb6af8-9c31-42a0-a29d-8c5a9035a6a4",
  "name": "Memory Chatbot (1)",
  "description": "This project can be used as a starting point for building a Chat experience with user specific memory. You can set a different Session ID to start a new message history. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "SkylerZeng",
    "first_name": "Skyler",
    "last_name": "zeng",
    "id": "6c2b8ddb-0368-495e-8398-58e6adca98ba",
    "full_name": "Skyler zeng"
  },
  "store_url": "https://www.langflow.store/store/component/43eb6af8-9c31-42a0-a29d-8c5a9035a6a4",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-08-06T07:59:12.293Z",
    "updated": "2024-08-06T07:59:12.524Z",
    "downloaded": "2025-08-19T17:50:06.288Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.14",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-TEskx",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
              },
              "user_message": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_message",
                "display_name": "user_message",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "user_message"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 523,
        "id": "Prompt-TEskx",
        "position": {
          "x": 1880.8227904110583,
          "y": 625.8049209882275
        },
        "positionAbsolute": {
          "x": 1880.8227904110583,
          "y": 625.8049209882275
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-m93BG",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "files",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n        Output(display_name=\"Email\", name=\"email\", method=\"email_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n    \n    def email_response(self) -> Message:\n        message = Message(\n            text=self.sender_name,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        \n        return message\n        \n    def id_response(self) -> Message:\n  \n        message = Message(\n            text=self.session_id,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        \n        return message",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "dede@outlook.com",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "should_store_message",
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "email",
                "display_name": "Email",
                "method": "email_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": true
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 372,
        "id": "ChatInput-m93BG",
        "position": {
          "x": 1046.38609474629,
          "y": 1218.1446669513678
        },
        "positionAbsolute": {
          "x": 1046.38609474629,
          "y": 1218.1446669513678
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI",
          "id": "OpenAIModel-ouWi2",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "json_mode",
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "gpt-3.5-turbo",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "output_schema",
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1,
                "name": "seed",
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.1,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 637,
        "id": "OpenAIModel-ouWi2",
        "position": {
          "x": 2472.324656663969,
          "y": 568.4272622187696
        },
        "positionAbsolute": {
          "x": 2472.324656663969,
          "y": 568.4272622187696
        },
        "selected": true,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-Yw3HD",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "ChatOutput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "data_template": {
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "Session ID for the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            }
          },
          "type": "ChatOutput"
        },
        "height": 316,
        "id": "ChatOutput-Yw3HD",
        "position": {
          "x": 6342.035881273489,
          "y": 1707.1285165623424
        },
        "selected": false,
        "type": "genericNode",
        "width": 384,
        "dragging": false,
        "positionAbsolute": {
          "x": 6342.035881273489,
          "y": 1707.1285165623424
        }
      },
      {
        "data": {
          "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
          "display_name": "Chat Memory",
          "id": "Memory-mdaMN",
          "node": {
            "base_classes": [
              "BaseChatMemory",
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Chat Memory",
            "documentation": "",
            "edited": false,
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Messages (Data)",
                "method": "retrieve_messages",
                "name": "messages",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "name": "messages_text",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Memory",
                "method": "build_lc_memory",
                "name": "lc_memory",
                "selected": "BaseChatMemory",
                "types": [
                  "BaseChatMemory"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import get_messages, LCBuiltinChatMemory\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.field_typing import BaseChatMemory\nfrom langchain.memory import ConversationBufferMemory\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\", \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"Session ID of the chat history.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            if sender:\n                expected_type = \"Machine\" if sender == \"Machine\" else \"User\"\n                stored = [m for m in stored if m.type == expected_type]\n            if order == \"ASC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.graph.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n"
              },
              "memory": {
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "advanced": true,
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "Session ID of the chat history.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            }
          },
          "type": "Memory"
        },
        "dragging": false,
        "height": 418,
        "id": "Memory-mdaMN",
        "position": {
          "x": 1322.606180294707,
          "y": 355.8871607067641
        },
        "positionAbsolute": {
          "x": 1322.606180294707,
          "y": 355.8871607067641
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "APIRequest-cRGHI",
        "type": "genericNode",
        "position": {
          "x": 2142.0168460237783,
          "y": 1685.8371117436343
        },
        "data": {
          "type": "APIRequest",
          "node": {
            "template": {
              "_type": "Component",
              "query_params": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "query_params",
                "display_name": "Query Parameters",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "body": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {
                  "email": "shreyc10@tuesdayfi.com",
                  "password": "Shreya123",
                  "data": {
                    "email": "shreyc10@tuesdayfi.com",
                    "password": "Shreya123"
                  }
                },
                "name": "body",
                "display_name": "Body",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import asyncio\nimport json\nfrom typing import Any, List, Optional\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport httpx\nfrom loguru import logger\n\nfrom axiestudio.base.curl.parse import parse_context\nfrom axiestudio.custom import Component\nfrom axiestudio.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = (\n        \"This component allows you to make HTTP requests to one or more URLs. \"\n        \"You can provide headers and body as either dictionaries or Data objects. \"\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\n        \"**Note:** Check advanced options for more settings.\"\n    )\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n        ),\n        MessageTextInput(\n            name=\"curl\",\n            display_name=\"Curl\",\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\n            value=\"GET\",\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\n        ),\n        NestedDictInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        NestedDictInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=5,\n            info=\"The timeout to use for the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n    ]\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        try:\n            parsed = parse_context(curl)\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"value\"] = dict(parsed.headers)\n\n            if parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    build_config[\"body\"][\"value\"] = json_data\n                except json.JSONDecodeError as e:\n                    logger.error(f\"Error decoding JSON data: {e}\")\n            else:\n                build_config[\"body\"][\"value\"] = {}\n        except Exception as exc:\n            logger.error(f\"Error parsing curl: {exc}\")\n            raise ValueError(f\"Error parsing curl: {exc}\")\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"curl\" and field_value:\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: Optional[dict] = None,\n        body: Optional[dict] = None,\n        timeout: int = 5,\n    ) -> Data:\n        method = method.upper()\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\n            raise ValueError(f\"Unsupported method: {method}\")\n\n        if isinstance(body, str) and body:\n            try:\n                body = json.loads(body)\n            except Exception as e:\n                logger.error(f\"Error decoding JSON data: {e}\")\n                body = None\n                raise ValueError(f\"Error decoding JSON data: {e}\")\n\n        data = body if body else None\n\n        try:\n            response = await client.request(method, url, headers=headers, json=data, timeout=timeout)\n            try:\n                result = response.json()\n            except Exception:\n                result = response.text\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": response.status_code,\n                    \"result\": result,\n                },\n            )\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> List[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        curl = self.curl\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        query_params = self.query_params.data if self.query_params else {}\n\n        if curl:\n            self._build_config = self.parse_curl(curl, dotdict())\n\n        if isinstance(headers, Data):\n            headers = headers.data\n\n        if isinstance(body, Data):\n            body = body.data\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\n            )\n        self.status = results\n        return results\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "curl": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "curl",
                "display_name": "Curl",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "headers": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {
                  "Accept": "application/json",
                  "Content-Type": "application/json",
                  "data": {
                    "Accept": "application/json",
                    "Content-Type": "application/json"
                  }
                },
                "name": "headers",
                "display_name": "Headers",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "method": {
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "POST",
                "name": "method",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 5,
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": false,
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "urls": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": [
                  "http://127.0.0.1:8000/api/user/login/"
                ],
                "name": "urls",
                "display_name": "URLs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter one or more URLs, separated by commas.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Login Request",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "make_requests",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "urls",
              "curl",
              "method",
              "headers",
              "body",
              "query_params",
              "timeout"
            ],
            "beta": false,
            "edited": false
          },
          "id": "APIRequest-cRGHI"
        },
        "selected": false,
        "width": 384,
        "height": 1032,
        "positionAbsolute": {
          "x": 2142.0168460237783,
          "y": 1685.8371117436343
        },
        "dragging": false
      },
      {
        "id": "MongoDBAtlasVector-s3hCe",
        "type": "genericNode",
        "position": {
          "x": 678.9135543907967,
          "y": 210.38333837375893
        },
        "data": {
          "type": "MongoDBAtlasVector",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "ingest_data",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom axiestudio.schema import Data\n\n\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/mongodb_atlas\"\n    name = \"MongoDBAtlasVector\"\n    icon = \"MongoDB\"\n\n    inputs = [\n        SecretStrInput(name=\"mongodb_atlas_cluster_uri\", display_name=\"MongoDB Atlas Cluster URI\", required=True),\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\n        return self._build_mongodb_atlas()\n\n    def _build_mongodb_atlas(self) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError:\n            raise ImportError(\"Please install pymongo to use MongoDB Atlas Vector Store\")\n\n        try:\n            mongo_client: MongoClient = MongoClient(self.mongodb_atlas_cluster_uri)\n            collection = mongo_client[self.db_name][self.collection_name]\n        except Exception as e:\n            raise ValueError(f\"Failed to connect to MongoDB Atlas: {e}\")\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n            if documents:\n                vector_store = MongoDBAtlasVectorSearch.from_documents(\n                    documents=documents, embedding=self.embedding, collection=collection, index_name=self.index_name\n                )\n            else:\n                vector_store = MongoDBAtlasVectorSearch(\n                    embedding=self.embedding,\n                    collection=collection,\n                    index_name=self.index_name,\n                )\n        else:\n            vector_store = MongoDBAtlasVectorSearch(\n                embedding=self.embedding,\n                collection=collection,\n                index_name=self.index_name,\n            )\n\n        return vector_store\n\n    def search_documents(self) -> List[Data]:\n        from bson import ObjectId\n\n        vector_store = self._build_mongodb_atlas()\n\n        if self.search_query and isinstance(self.search_query, str):\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            for doc in docs:\n                doc.metadata = {\n                    key: str(value) if isinstance(value, ObjectId) else value for key, value in doc.metadata.items()\n                }\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "collection_name",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "db_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "db_name",
                "display_name": "Database Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "index_name",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "mongodb_atlas_cluster_uri": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "mongodb_atlas_cluster_uri",
                "display_name": "MongoDB Atlas Cluster URI",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 4,
                "name": "number_of_results",
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "search_query",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "MongoDB Atlas Vector Store with search capabilities",
            "icon": "MongoDB",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "MongoDB Atlas",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/mongodb_atlas",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "mongodb_atlas_cluster_uri",
              "db_name",
              "collection_name",
              "index_name",
              "search_query",
              "ingest_data",
              "embedding",
              "number_of_results"
            ],
            "beta": false,
            "edited": false
          },
          "id": "MongoDBAtlasVector-s3hCe"
        },
        "selected": false,
        "width": 384,
        "height": 918,
        "positionAbsolute": {
          "x": 678.9135543907967,
          "y": 210.38333837375893
        },
        "dragging": false
      },
      {
        "id": "ParseData-VJq1Z",
        "type": "genericNode",
        "position": {
          "x": 2691.586020176408,
          "y": 2089.117328559663
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "data",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "\n",
                "name": "sep",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{text}",
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ParseData-VJq1Z"
        },
        "selected": false,
        "width": 384,
        "height": 400,
        "positionAbsolute": {
          "x": 2691.586020176408,
          "y": 2089.117328559663
        },
        "dragging": false
      },
      {
        "id": "CombineText-wvPwC",
        "type": "genericNode",
        "position": {
          "x": 1624.2123774236263,
          "y": 1660.277023791771
        },
        "data": {
          "type": "CombineText",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n         MessageTextInput(\n            name=\"text3\",\n            display_name=\"Third Text\",\n            info=\"The third text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the three text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2, self.text3])\n        self.status = combined\n        return Message(text=combined)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "delimiter": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": " ",
                "name": "delimiter",
                "display_name": "Delimiter",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A string used to separate the three text inputs. Defaults to a whitespace.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text1": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "curl -X POST -d  '{\"email\":\"",
                "name": "text1",
                "display_name": "First Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text2": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "text2",
                "display_name": "Second Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text3": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "\", \"password\":\"Shreya123\"}' -H \"Accept:application/json\"  -H \"Content-Type:application/json\" http://127.0.0.1:8000/api/user/login/",
                "name": "text3",
                "display_name": "Third Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The third text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "icon": "merge",
            "base_classes": [
              "Message"
            ],
            "display_name": "Genrate HTTP Request",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "combined_text",
                "display_name": "Combined Text",
                "method": "combine_texts",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text1",
              "text2",
              "text3",
              "delimiter"
            ],
            "beta": false,
            "edited": true
          },
          "id": "CombineText-wvPwC"
        },
        "selected": false,
        "width": 384,
        "height": 625,
        "dragging": false,
        "positionAbsolute": {
          "x": 1624.2123774236263,
          "y": 1660.277023791771
        }
      },
      {
        "id": "ConditionalRouter-jxc96",
        "type": "genericNode",
        "position": {
          "x": 3159.281487367428,
          "y": 544.7344580582932
        },
        "data": {
          "type": "ConditionalRouter",
          "node": {
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "case_sensitive",
                "display_name": "Case Sensitive",
                "advanced": true,
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DropdownInput, MessageInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"equal\"\n    name = \"ConditionalRouter\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageTextInput(\n            name=\"task1\",\n            display_name=\"Task1\",\n            info=\"The text input to compare against.\",\n            value=\"Task1\",\n        ),\n        MessageTextInput(\n            name=\"task2\",\n            display_name=\"Task2\",\n            info=\"The text input to compare against.\",\n            value=\"Task2\",\n        ),\n        MessageTextInput(\n            name=\"task3\",\n            display_name=\"Task3\",\n            info=\"The text input to compare against.\",\n            value=\"Task3\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n      \n    ]\n\n    outputs = [\n        Output(display_name=\"Task1 Route\", name=\"task1_result\", method=\"task1_response\"),\n        Output(display_name=\"Task2 Route\", name=\"task2_result\", method=\"task2_response\"),\n        Output(display_name=\"Task3 Route\", name=\"task3_result\", method=\"task3_response\"),\n    ]\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, case_sensitive: bool) -> bool:\n        if not case_sensitive:\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        elif operator == \"not equals\":\n            return input_text != match_text\n        elif operator == \"contains\":\n            return match_text in input_text\n        elif operator == \"starts with\":\n            return input_text.startswith(match_text)\n        elif operator == \"ends with\":\n            return input_text.endswith(match_text)\n        return False\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"true_result\")\n            return None  # type: ignore\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if not result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"false_result\")\n            return None  # type: ignore\n    \n    def task1_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.task1, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"task1_result\")\n            return None  # type: ignore\n            \n    def task2_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.task2, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"task2_result\")\n            return None  # type: ignore\n\n    def task3_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.task3, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"task3_result\")\n            return None  # type: ignore",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_text",
                "display_name": "Input Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "message",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "operator": {
                "trace_as_metadata": true,
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "equals",
                "name": "operator",
                "display_name": "Operator",
                "advanced": true,
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "task1": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Task1",
                "name": "task1",
                "display_name": "Task1",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "task2": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Task2",
                "name": "task2",
                "display_name": "Task2",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "task3": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Task3",
                "name": "task3",
                "display_name": "Task3",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "icon": "equal",
            "base_classes": [
              "Message"
            ],
            "display_name": "Conditional Router",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "task1_result",
                "display_name": "Task1 Route",
                "method": "task1_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "task2_result",
                "display_name": "Task2 Route",
                "method": "task2_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "task3_result",
                "display_name": "Task3 Route",
                "method": "task3_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_text",
              "task1",
              "task2",
              "task3",
              "operator",
              "case_sensitive",
              "message"
            ],
            "beta": false,
            "edited": true
          },
          "id": "ConditionalRouter-jxc96"
        },
        "selected": false,
        "width": 384,
        "height": 830,
        "positionAbsolute": {
          "x": 3159.281487367428,
          "y": 544.7344580582932
        },
        "dragging": false
      },
      {
        "id": "Prompt-6wy0q",
        "type": "genericNode",
        "position": {
          "x": 4427.831611162238,
          "y": 893.0273506499984
        },
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-6wy0q",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
              },
              "user_message": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_message",
                "display_name": "user_message",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "user_message"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 523,
        "positionAbsolute": {
          "x": 4427.831611162238,
          "y": 893.0273506499984
        },
        "dragging": false
      },
      {
        "id": "Prompt-TF4GE",
        "type": "genericNode",
        "position": {
          "x": 3917.7295560140083,
          "y": 1346.136383268706
        },
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-TF4GE",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
              },
              "user_message": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_message",
                "display_name": "user_message",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "user_message"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 523,
        "positionAbsolute": {
          "x": 3917.7295560140083,
          "y": 1346.136383268706
        },
        "dragging": false
      },
      {
        "id": "Prompt-ZXUU6",
        "type": "genericNode",
        "position": {
          "x": 3911.112590223929,
          "y": 1940.3141313103638
        },
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-ZXUU6",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
              },
              "user_message": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_message",
                "display_name": "user_message",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "user_message"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 523,
        "positionAbsolute": {
          "x": 3911.112590223929,
          "y": 1940.3141313103638
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-qbv4K",
        "type": "genericNode",
        "position": {
          "x": 5119.220385070991,
          "y": 3018.2457612229923
        },
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI",
          "id": "OpenAIModel-qbv4K",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "json_mode",
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "gpt-3.5-turbo",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "output_schema",
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1,
                "name": "seed",
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.1,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false
          },
          "type": "OpenAIModel"
        },
        "selected": false,
        "width": 384,
        "height": 543,
        "positionAbsolute": {
          "x": 5119.220385070991,
          "y": 3018.2457612229923
        },
        "dragging": false
      },
      {
        "id": "FAISS-bMOmL",
        "type": "genericNode",
        "position": {
          "x": 5096.226505516078,
          "y": 2146.002152601459
        },
        "data": {
          "type": "FAISS",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "ingest_data",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "allow_dangerous_deserialization": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "allow_dangerous_deserialization",
                "display_name": "Allow Dangerous Deserialization",
                "advanced": true,
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "axiestudio_index",
                "name": "index_name",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 4,
                "name": "number_of_results",
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "persist_directory",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "search_query",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "FAISS Vector Store with search capabilities",
            "icon": "FAISS",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "FAISS",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "index_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "beta": false,
            "edited": false
          },
          "id": "FAISS-bMOmL"
        },
        "selected": false,
        "width": 384,
        "height": 711,
        "positionAbsolute": {
          "x": 5096.226505516078,
          "y": 2146.002152601459
        },
        "dragging": false
      },
      {
        "id": "HuggingFaceEmbeddings-s3Dgs",
        "type": "genericNode",
        "position": {
          "x": 4493.59668039198,
          "y": 2347.092216357498
        },
        "data": {
          "type": "HuggingFaceEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "cache_folder": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "cache_folder",
                "display_name": "Cache Folder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, MessageTextInput, Output\n\n\nclass HuggingFaceEmbeddingsComponent(LCModelComponent):\n    display_name = \"Hugging Face Embeddings\"\n    description = \"Generate embeddings using HuggingFace models.\"\n    documentation = (\n        \"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers\"\n    )\n    icon = \"HuggingFace\"\n    name = \"HuggingFaceEmbeddings\"\n\n    inputs = [\n        MessageTextInput(name=\"cache_folder\", display_name=\"Cache Folder\", advanced=True),\n        DictInput(name=\"encode_kwargs\", display_name=\"Encode Kwargs\", advanced=True),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"sentence-transformers/all-mpnet-base-v2\"),\n        BoolInput(name=\"multi_process\", display_name=\"Multi Process\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return HuggingFaceEmbeddings(\n            cache_folder=self.cache_folder,\n            encode_kwargs=self.encode_kwargs,\n            model_kwargs=self.model_kwargs,\n            model_name=self.model_name,\n            multi_process=self.multi_process,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "encode_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "encode_kwargs",
                "display_name": "Encode Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "sentence-transformers/all-mpnet-base-v2",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "multi_process": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "multi_process",
                "display_name": "Multi Process",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Generate embeddings using HuggingFace models.",
            "icon": "HuggingFace",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Hugging Face Embeddings",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cache_folder",
              "encode_kwargs",
              "model_kwargs",
              "model_name",
              "multi_process"
            ],
            "beta": false,
            "edited": false
          },
          "id": "HuggingFaceEmbeddings-s3Dgs"
        },
        "selected": false,
        "width": 384,
        "height": 344,
        "positionAbsolute": {
          "x": 4493.59668039198,
          "y": 2347.092216357498
        },
        "dragging": true
      },
      {
        "id": "RetrievalQA-H6j3r",
        "type": "genericNode",
        "position": {
          "x": 5878.690988614894,
          "y": 2058.233610859458
        },
        "data": {
          "type": "RetrievalQA",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMemory"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "retriever": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "retriever",
                "display_name": "Retriever",
                "advanced": false,
                "input_types": [
                  "Retriever"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chain_type": {
                "trace_as_metadata": true,
                "options": [
                  "Stuff",
                  "Map Reduce",
                  "Refine",
                  "Map Rerank"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Stuff",
                "name": "chain_type",
                "display_name": "Chain Type",
                "advanced": true,
                "dynamic": false,
                "info": "Chain type to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.chains import RetrievalQA\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import HandleInput, MultilineInput, BoolInput, DropdownInput\n\n\nclass RetrievalQAComponent(LCChainComponent):\n    display_name = \"Retrieval QA\"\n    description = \"Chain for question-answering querying sources from a retriever.\"\n    name = \"RetrievalQA\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        DropdownInput(\n            name=\"chain_type\",\n            display_name=\"Chain Type\",\n            info=\"Chain type to use.\",\n            options=[\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n            value=\"Stuff\",\n            advanced=True,\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(name=\"retriever\", display_name=\"Retriever\", input_types=[\"Retriever\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n        BoolInput(\n            name=\"return_source_documents\",\n            display_name=\"Return Source Documents\",\n            value=False,\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        chain_type = self.chain_type.lower().replace(\" \", \"_\")\n        if self.memory:\n            self.memory.input_key = \"query\"\n            self.memory.output_key = \"result\"\n\n        runnable = RetrievalQA.from_chain_type(\n            llm=self.llm,\n            chain_type=chain_type,\n            retriever=self.retriever,\n            memory=self.memory,\n            # always include to help debugging\n            #\n            return_source_documents=True,\n        )\n\n        result = runnable.invoke({\"query\": self.input_value})\n\n        source_docs = self.to_data(result.get(\"source_documents\", []))\n        result_str = str(result.get(\"result\", \"\"))\n        if self.return_source_documents and len(source_docs):\n            references_str = self.create_references_from_data(source_docs)\n            result_str = \"\\n\".join([result_str, references_str])\n        # put the entire result to debug history, query and content\n        self.status = {**result, \"source_documents\": source_docs, \"output\": result_str}\n        return result_str\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input value to pass to the chain.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "return_source_documents": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "return_source_documents",
                "display_name": "Return Source Documents",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Chain for question-answering querying sources from a retriever.",
            "base_classes": [
              "Message"
            ],
            "display_name": "Retrieval QA",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "invoke_chain",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "chain_type",
              "llm",
              "retriever",
              "memory",
              "return_source_documents"
            ],
            "beta": false,
            "edited": false
          },
          "id": "RetrievalQA-H6j3r"
        },
        "selected": false,
        "width": 384,
        "height": 584,
        "positionAbsolute": {
          "x": 5878.690988614894,
          "y": 2058.233610859458
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-TEskx",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-ouWi2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-TEskx{dataType:Prompt,id:Prompt-TEskx,name:prompt,output_types:[Message]}-OpenAIModel-ouWi2{fieldName:input_value,id:OpenAIModel-ouWi2,inputTypes:[Message],type:str}",
        "source": "Prompt-TEskx",
        "sourceHandle": "{dataType:Prompt,id:Prompt-TEskx,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-ouWi2",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-ouWi2,inputTypes:[Message],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-mdaMN",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-TEskx",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}-Prompt-TEskx{fieldName:context,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
        "source": "Memory-mdaMN",
        "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}",
        "target": "Prompt-TEskx",
        "targetHandle": "{fieldName:context,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
        "selected": false
      },
      {
        "source": "ChatInput-m93BG",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}",
        "target": "Prompt-TEskx",
        "targetHandle": "{fieldName:user_message,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "user_message",
            "id": "Prompt-TEskx",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-m93BG",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-m93BG{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}-Prompt-TEskx{fieldName:user_message,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
        "selected": false,
        "className": ""
      },
      {
        "source": "Memory-mdaMN",
        "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages,output_types:[Data]}",
        "target": "MongoDBAtlasVector-s3hCe",
        "targetHandle": "{fieldName:ingest_data,id:MongoDBAtlasVector-s3hCe,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "MongoDBAtlasVector-s3hCe",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-mdaMN",
            "name": "messages",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages,output_types:[Data]}-MongoDBAtlasVector-s3hCe{fieldName:ingest_data,id:MongoDBAtlasVector-s3hCe,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "APIRequest-cRGHI",
        "sourceHandle": "{dataType:APIRequest,id:APIRequest-cRGHI,name:data,output_types:[Data]}",
        "target": "ParseData-VJq1Z",
        "targetHandle": "{fieldName:data,id:ParseData-VJq1Z,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-VJq1Z",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "APIRequest",
            "id": "APIRequest-cRGHI",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-APIRequest-cRGHI{dataType:APIRequest,id:APIRequest-cRGHI,name:data,output_types:[Data]}-ParseData-VJq1Z{fieldName:data,id:ParseData-VJq1Z,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "ChatInput-m93BG",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-m93BG,name:email,output_types:[Message]}",
        "target": "CombineText-wvPwC",
        "targetHandle": "{fieldName:text2,id:CombineText-wvPwC,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-wvPwC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-m93BG",
            "name": "email",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-m93BG{dataType:ChatInput,id:ChatInput-m93BG,name:email,output_types:[Message]}-CombineText-wvPwC{fieldName:text2,id:CombineText-wvPwC,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "CombineText-wvPwC",
        "sourceHandle": "{dataType:CombineText,id:CombineText-wvPwC,name:combined_text,output_types:[Message]}",
        "target": "APIRequest-cRGHI",
        "targetHandle": "{fieldName:curl,id:APIRequest-cRGHI,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "curl",
            "id": "APIRequest-cRGHI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-wvPwC",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CombineText-wvPwC{dataType:CombineText,id:CombineText-wvPwC,name:combined_text,output_types:[Message]}-APIRequest-cRGHI{fieldName:curl,id:APIRequest-cRGHI,inputTypes:[Message],type:str}",
        "selected": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-ouWi2",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-ouWi2,name:text_output,output_types:[Message]}",
        "target": "ConditionalRouter-jxc96",
        "targetHandle": "{fieldName:input_text,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-jxc96",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-ouWi2",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-ouWi2{dataType:OpenAIModel,id:OpenAIModel-ouWi2,name:text_output,output_types:[Message]}-ConditionalRouter-jxc96{fieldName:input_text,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "ChatInput-m93BG",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}",
        "target": "ConditionalRouter-jxc96",
        "targetHandle": "{fieldName:message,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-jxc96",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-m93BG",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-m93BG{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}-ConditionalRouter-jxc96{fieldName:message,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "Memory-mdaMN",
        "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}",
        "target": "Prompt-6wy0q",
        "targetHandle": "{fieldName:context,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-6wy0q",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-mdaMN",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}-Prompt-6wy0q{fieldName:context,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "ConditionalRouter-jxc96",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task1_result,output_types:[Message]}",
        "target": "Prompt-6wy0q",
        "targetHandle": "{fieldName:user_message,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "user_message",
            "id": "Prompt-6wy0q",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-jxc96",
            "name": "task1_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-jxc96{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task1_result,output_types:[Message]}-Prompt-6wy0q{fieldName:user_message,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "ConditionalRouter-jxc96",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task2_result,output_types:[Message]}",
        "target": "Prompt-TF4GE",
        "targetHandle": "{fieldName:user_message,id:Prompt-TF4GE,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "user_message",
            "id": "Prompt-TF4GE",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-jxc96",
            "name": "task2_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-jxc96{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task2_result,output_types:[Message]}-Prompt-TF4GE{fieldName:user_message,id:Prompt-TF4GE,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "Memory-mdaMN",
        "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}",
        "target": "Prompt-ZXUU6",
        "targetHandle": "{fieldName:context,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-ZXUU6",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-mdaMN",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}-Prompt-ZXUU6{fieldName:context,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "ConditionalRouter-jxc96",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task3_result,output_types:[Message]}",
        "target": "Prompt-ZXUU6",
        "targetHandle": "{fieldName:user_message,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "user_message",
            "id": "Prompt-ZXUU6",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-jxc96",
            "name": "task3_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-jxc96{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task3_result,output_types:[Message]}-Prompt-ZXUU6{fieldName:user_message,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
        "className": ""
      },
      {
        "source": "HuggingFaceEmbeddings-s3Dgs",
        "sourceHandle": "{dataType:HuggingFaceEmbeddings,id:HuggingFaceEmbeddings-s3Dgs,name:embeddings,output_types:[Embeddings]}",
        "target": "FAISS-bMOmL",
        "targetHandle": "{fieldName:embedding,id:FAISS-bMOmL,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-bMOmL",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "HuggingFaceEmbeddings",
            "id": "HuggingFaceEmbeddings-s3Dgs",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-HuggingFaceEmbeddings-s3Dgs{dataType:HuggingFaceEmbeddings,id:HuggingFaceEmbeddings-s3Dgs,name:embeddings,output_types:[Embeddings]}-FAISS-bMOmL{fieldName:embedding,id:FAISS-bMOmL,inputTypes:[Embeddings],type:other}",
        "className": ""
      },
      {
        "source": "FAISS-bMOmL",
        "sourceHandle": "{dataType:FAISS,id:FAISS-bMOmL,name:base_retriever,output_types:[Retriever]}",
        "target": "RetrievalQA-H6j3r",
        "targetHandle": "{fieldName:retriever,id:RetrievalQA-H6j3r,inputTypes:[Retriever],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "retriever",
            "id": "RetrievalQA-H6j3r",
            "inputTypes": [
              "Retriever"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-bMOmL",
            "name": "base_retriever",
            "output_types": [
              "Retriever"
            ]
          }
        },
        "id": "reactflow__edge-FAISS-bMOmL{dataType:FAISS,id:FAISS-bMOmL,name:base_retriever,output_types:[Retriever]}-RetrievalQA-H6j3r{fieldName:retriever,id:RetrievalQA-H6j3r,inputTypes:[Retriever],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIModel-qbv4K",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-qbv4K,name:model_output,output_types:[LanguageModel]}",
        "target": "RetrievalQA-H6j3r",
        "targetHandle": "{fieldName:llm,id:RetrievalQA-H6j3r,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "RetrievalQA-H6j3r",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-qbv4K",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-qbv4K{dataType:OpenAIModel,id:OpenAIModel-qbv4K,name:model_output,output_types:[LanguageModel]}-RetrievalQA-H6j3r{fieldName:llm,id:RetrievalQA-H6j3r,inputTypes:[LanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "Memory-mdaMN",
        "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:lc_memory,output_types:[BaseChatMemory]}",
        "target": "RetrievalQA-H6j3r",
        "targetHandle": "{fieldName:memory,id:RetrievalQA-H6j3r,inputTypes:[BaseChatMemory],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "RetrievalQA-H6j3r",
            "inputTypes": [
              "BaseChatMemory"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-mdaMN",
            "name": "lc_memory",
            "output_types": [
              "BaseChatMemory"
            ]
          }
        },
        "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:lc_memory,output_types:[BaseChatMemory]}-RetrievalQA-H6j3r{fieldName:memory,id:RetrievalQA-H6j3r,inputTypes:[BaseChatMemory],type:other}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 115.14079235477533,
      "y": 53.072975125132984,
      "zoom": 0.12266007341946632
    }
  },
  "metadata": {
    "Prompt": {
      "count": 4
    },
    "ChatInput": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 2
    },
    "ChatOutput": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "APIRequest": {
      "count": 1
    },
    "MongoDBAtlasVector": {
      "count": 1
    },
    "ParseData": {
      "count": 1
    },
    "CombineText": {
      "count": 1
    },
    "ConditionalRouter": {
      "count": 1
    },
    "FAISS": {
      "count": 1
    },
    "HuggingFaceEmbeddings": {
      "count": 1
    },
    "RetrievalQA": {
      "count": 1
    },
    "total": 17
  },
  "original": {
    "id": "43eb6af8-9c31-42a0-a29d-8c5a9035a6a4",
    "name": "Memory Chatbot (1)",
    "description": "This project can be used as a starting point for building a Chat experience with user specific memory. You can set a different Session ID to start a new message history.",
    "is_component": false,
    "liked_by_count": "1",
    "downloads_count": "5",
    "metadata": {
      "Prompt": {
        "count": 4
      },
      "ChatInput": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 2
      },
      "ChatOutput": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "APIRequest": {
        "count": 1
      },
      "MongoDBAtlasVector": {
        "count": 1
      },
      "ParseData": {
        "count": 1
      },
      "CombineText": {
        "count": 1
      },
      "ConditionalRouter": {
        "count": 1
      },
      "FAISS": {
        "count": 1
      },
      "HuggingFaceEmbeddings": {
        "count": 1
      },
      "RetrievalQA": {
        "count": 1
      },
      "total": 17
    },
    "last_tested_version": "1.0.14",
    "private": false,
    "data": {
      "nodes": [
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-TEskx",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
                },
                "user_message": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_message",
                  "display_name": "user_message",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "user_message"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 523,
          "id": "Prompt-TEskx",
          "position": {
            "x": 1880.8227904110583,
            "y": 625.8049209882275
          },
          "positionAbsolute": {
            "x": 1880.8227904110583,
            "y": 625.8049209882275
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "id": "ChatInput-m93BG",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "files",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n        Output(display_name=\"Email\", name=\"email\", method=\"email_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n    \n    def email_response(self) -> Message:\n        message = Message(\n            text=self.sender_name,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        \n        return message\n        \n    def id_response(self) -> Message:\n  \n        message = Message(\n            text=self.session_id,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        \n        return message",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "dede@outlook.com",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "should_store_message",
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "email",
                  "display_name": "Email",
                  "method": "email_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": true
            },
            "type": "ChatInput"
          },
          "dragging": false,
          "height": 372,
          "id": "ChatInput-m93BG",
          "position": {
            "x": 1046.38609474629,
            "y": 1218.1446669513678
          },
          "positionAbsolute": {
            "x": 1046.38609474629,
            "y": 1218.1446669513678
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "id": "OpenAIModel-ouWi2",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "json_mode",
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "gpt-3.5-turbo",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput",
                  "load_from_db": false
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "output_schema",
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1,
                  "name": "seed",
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.1,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 637,
          "id": "OpenAIModel-ouWi2",
          "position": {
            "x": 2472.324656663969,
            "y": 568.4272622187696
          },
          "positionAbsolute": {
            "x": 2472.324656663969,
            "y": 568.4272622187696
          },
          "selected": true,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "id": "ChatOutput-Yw3HD",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Display a chat message in the Playground.",
              "display_name": "Chat Output",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "frozen": false,
              "icon": "ChatOutput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "data_template": {
                  "advanced": true,
                  "display_name": "Data Template",
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "data_template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "{text}"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Machine"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "AI"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "store_message": {
                  "advanced": true,
                  "display_name": "Store Messages",
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "store_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              }
            },
            "type": "ChatOutput"
          },
          "height": 316,
          "id": "ChatOutput-Yw3HD",
          "position": {
            "x": 6342.035881273489,
            "y": 1707.1285165623424
          },
          "selected": false,
          "type": "genericNode",
          "width": 384,
          "dragging": false,
          "positionAbsolute": {
            "x": 6342.035881273489,
            "y": 1707.1285165623424
          }
        },
        {
          "data": {
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Chat Memory",
            "id": "Memory-mdaMN",
            "node": {
              "base_classes": [
                "BaseChatMemory",
                "Data",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
              "display_name": "Chat Memory",
              "documentation": "",
              "edited": false,
              "field_order": [
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "frozen": false,
              "icon": "message-square-more",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Messages (Data)",
                  "method": "retrieve_messages",
                  "name": "messages",
                  "selected": "Data",
                  "types": [
                    "Data"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "name": "messages_text",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Memory",
                  "method": "build_lc_memory",
                  "name": "lc_memory",
                  "selected": "BaseChatMemory",
                  "types": [
                    "BaseChatMemory"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import get_messages, LCBuiltinChatMemory\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.field_typing import BaseChatMemory\nfrom langchain.memory import ConversationBufferMemory\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\", \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"Session ID of the chat history.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            if sender:\n                expected_type = \"Machine\" if sender == \"Machine\" else \"User\"\n                stored = [m for m in stored if m.type == expected_type]\n            if order == \"ASC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.graph.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n"
                },
                "memory": {
                  "advanced": false,
                  "display_name": "External Memory",
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "n_messages": {
                  "advanced": true,
                  "display_name": "Number of Messages",
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "list": false,
                  "name": "n_messages",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 100
                },
                "order": {
                  "advanced": true,
                  "display_name": "Order",
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "name": "order",
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Ascending"
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Machine and User"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "Session ID of the chat history.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "template": {
                  "advanced": true,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "{sender_name}: {text}"
                }
              }
            },
            "type": "Memory"
          },
          "dragging": false,
          "height": 418,
          "id": "Memory-mdaMN",
          "position": {
            "x": 1322.606180294707,
            "y": 355.8871607067641
          },
          "positionAbsolute": {
            "x": 1322.606180294707,
            "y": 355.8871607067641
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "APIRequest-cRGHI",
          "type": "genericNode",
          "position": {
            "x": 2142.0168460237783,
            "y": 1685.8371117436343
          },
          "data": {
            "type": "APIRequest",
            "node": {
              "template": {
                "_type": "Component",
                "query_params": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "query_params",
                  "display_name": "Query Parameters",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The query parameters to append to the URL.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "body": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {
                    "email": "shreyc10@tuesdayfi.com",
                    "password": "Shreya123",
                    "data": {
                      "email": "shreyc10@tuesdayfi.com",
                      "password": "Shreya123"
                    }
                  },
                  "name": "body",
                  "display_name": "Body",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
                  "title_case": false,
                  "type": "NestedDict",
                  "_input_type": "NestedDictInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import asyncio\nimport json\nfrom typing import Any, List, Optional\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport httpx\nfrom loguru import logger\n\nfrom axiestudio.base.curl.parse import parse_context\nfrom axiestudio.custom import Component\nfrom axiestudio.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = (\n        \"This component allows you to make HTTP requests to one or more URLs. \"\n        \"You can provide headers and body as either dictionaries or Data objects. \"\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\n        \"**Note:** Check advanced options for more settings.\"\n    )\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n        ),\n        MessageTextInput(\n            name=\"curl\",\n            display_name=\"Curl\",\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\n            value=\"GET\",\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\n        ),\n        NestedDictInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        NestedDictInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\n            input_types=[\"Data\"],\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=5,\n            info=\"The timeout to use for the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n    ]\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        try:\n            parsed = parse_context(curl)\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"value\"] = dict(parsed.headers)\n\n            if parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    build_config[\"body\"][\"value\"] = json_data\n                except json.JSONDecodeError as e:\n                    logger.error(f\"Error decoding JSON data: {e}\")\n            else:\n                build_config[\"body\"][\"value\"] = {}\n        except Exception as exc:\n            logger.error(f\"Error parsing curl: {exc}\")\n            raise ValueError(f\"Error parsing curl: {exc}\")\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"curl\" and field_value:\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: Optional[dict] = None,\n        body: Optional[dict] = None,\n        timeout: int = 5,\n    ) -> Data:\n        method = method.upper()\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\n            raise ValueError(f\"Unsupported method: {method}\")\n\n        if isinstance(body, str) and body:\n            try:\n                body = json.loads(body)\n            except Exception as e:\n                logger.error(f\"Error decoding JSON data: {e}\")\n                body = None\n                raise ValueError(f\"Error decoding JSON data: {e}\")\n\n        data = body if body else None\n\n        try:\n            response = await client.request(method, url, headers=headers, json=data, timeout=timeout)\n            try:\n                result = response.json()\n            except Exception:\n                result = response.text\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": response.status_code,\n                    \"result\": result,\n                },\n            )\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> List[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        curl = self.curl\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        query_params = self.query_params.data if self.query_params else {}\n\n        if curl:\n            self._build_config = self.parse_curl(curl, dotdict())\n\n        if isinstance(headers, Data):\n            headers = headers.data\n\n        if isinstance(body, Data):\n            body = body.data\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\n            )\n        self.status = results\n        return results\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "curl": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "curl",
                  "display_name": "Curl",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "headers": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {
                    "Accept": "application/json",
                    "Content-Type": "application/json",
                    "data": {
                      "Accept": "application/json",
                      "Content-Type": "application/json"
                    }
                  },
                  "name": "headers",
                  "display_name": "Headers",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
                  "title_case": false,
                  "type": "NestedDict",
                  "_input_type": "NestedDictInput"
                },
                "method": {
                  "trace_as_metadata": true,
                  "options": [
                    "GET",
                    "POST",
                    "PATCH",
                    "PUT"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "POST",
                  "name": "method",
                  "display_name": "Method",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 5,
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The timeout to use for the request.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "urls": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": [
                    "http://127.0.0.1:8000/api/user/login/"
                  ],
                  "name": "urls",
                  "display_name": "URLs",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter one or more URLs, separated by commas.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
              "icon": "Globe",
              "base_classes": [
                "Data"
              ],
              "display_name": "Login Request",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "make_requests",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "urls",
                "curl",
                "method",
                "headers",
                "body",
                "query_params",
                "timeout"
              ],
              "beta": false,
              "edited": false
            },
            "id": "APIRequest-cRGHI"
          },
          "selected": false,
          "width": 384,
          "height": 1032,
          "positionAbsolute": {
            "x": 2142.0168460237783,
            "y": 1685.8371117436343
          },
          "dragging": false
        },
        {
          "id": "MongoDBAtlasVector-s3hCe",
          "type": "genericNode",
          "position": {
            "x": 678.9135543907967,
            "y": 210.38333837375893
          },
          "data": {
            "type": "MongoDBAtlasVector",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "embedding",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "ingest_data",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom axiestudio.schema import Data\n\n\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/mongodb_atlas\"\n    name = \"MongoDBAtlasVector\"\n    icon = \"MongoDB\"\n\n    inputs = [\n        SecretStrInput(name=\"mongodb_atlas_cluster_uri\", display_name=\"MongoDB Atlas Cluster URI\", required=True),\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\n        return self._build_mongodb_atlas()\n\n    def _build_mongodb_atlas(self) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError:\n            raise ImportError(\"Please install pymongo to use MongoDB Atlas Vector Store\")\n\n        try:\n            mongo_client: MongoClient = MongoClient(self.mongodb_atlas_cluster_uri)\n            collection = mongo_client[self.db_name][self.collection_name]\n        except Exception as e:\n            raise ValueError(f\"Failed to connect to MongoDB Atlas: {e}\")\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n            if documents:\n                vector_store = MongoDBAtlasVectorSearch.from_documents(\n                    documents=documents, embedding=self.embedding, collection=collection, index_name=self.index_name\n                )\n            else:\n                vector_store = MongoDBAtlasVectorSearch(\n                    embedding=self.embedding,\n                    collection=collection,\n                    index_name=self.index_name,\n                )\n        else:\n            vector_store = MongoDBAtlasVectorSearch(\n                embedding=self.embedding,\n                collection=collection,\n                index_name=self.index_name,\n            )\n\n        return vector_store\n\n    def search_documents(self) -> List[Data]:\n        from bson import ObjectId\n\n        vector_store = self._build_mongodb_atlas()\n\n        if self.search_query and isinstance(self.search_query, str):\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            for doc in docs:\n                doc.metadata = {\n                    key: str(value) if isinstance(value, ObjectId) else value for key, value in doc.metadata.items()\n                }\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "collection_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "collection_name",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "db_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "db_name",
                  "display_name": "Database Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "index_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "index_name",
                  "display_name": "Index Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "mongodb_atlas_cluster_uri": {
                  "load_from_db": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "mongodb_atlas_cluster_uri",
                  "display_name": "MongoDB Atlas Cluster URI",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 4,
                  "name": "number_of_results",
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "search_query",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "MongoDB Atlas Vector Store with search capabilities",
              "icon": "MongoDB",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "MongoDB Atlas",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/mongodb_atlas",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "mongodb_atlas_cluster_uri",
                "db_name",
                "collection_name",
                "index_name",
                "search_query",
                "ingest_data",
                "embedding",
                "number_of_results"
              ],
              "beta": false,
              "edited": false
            },
            "id": "MongoDBAtlasVector-s3hCe"
          },
          "selected": false,
          "width": 384,
          "height": 918,
          "positionAbsolute": {
            "x": 678.9135543907967,
            "y": 210.38333837375893
          },
          "dragging": false
        },
        {
          "id": "ParseData-VJq1Z",
          "type": "genericNode",
          "position": {
            "x": 2691.586020176408,
            "y": 2089.117328559663
          },
          "data": {
            "type": "ParseData",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "data",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sep": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "\n",
                  "name": "sep",
                  "display_name": "Separator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{text}",
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Convert Data into plain text following a specified template.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Parse Data",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ParseData-VJq1Z"
          },
          "selected": false,
          "width": 384,
          "height": 400,
          "positionAbsolute": {
            "x": 2691.586020176408,
            "y": 2089.117328559663
          },
          "dragging": false
        },
        {
          "id": "CombineText-wvPwC",
          "type": "genericNode",
          "position": {
            "x": 1624.2123774236263,
            "y": 1660.277023791771
          },
          "data": {
            "type": "CombineText",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n         MessageTextInput(\n            name=\"text3\",\n            display_name=\"Third Text\",\n            info=\"The third text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the three text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2, self.text3])\n        self.status = combined\n        return Message(text=combined)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "delimiter": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": " ",
                  "name": "delimiter",
                  "display_name": "Delimiter",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "A string used to separate the three text inputs. Defaults to a whitespace.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text1": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "curl -X POST -d  '{\"email\":\"",
                  "name": "text1",
                  "display_name": "First Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The first text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text2": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "text2",
                  "display_name": "Second Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The second text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text3": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "\", \"password\":\"Shreya123\"}' -H \"Accept:application/json\"  -H \"Content-Type:application/json\" http://127.0.0.1:8000/api/user/login/",
                  "name": "text3",
                  "display_name": "Third Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The third text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
              "icon": "merge",
              "base_classes": [
                "Message"
              ],
              "display_name": "Genrate HTTP Request",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "combined_text",
                  "display_name": "Combined Text",
                  "method": "combine_texts",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text1",
                "text2",
                "text3",
                "delimiter"
              ],
              "beta": false,
              "edited": true
            },
            "id": "CombineText-wvPwC"
          },
          "selected": false,
          "width": 384,
          "height": 625,
          "dragging": false,
          "positionAbsolute": {
            "x": 1624.2123774236263,
            "y": 1660.277023791771
          }
        },
        {
          "id": "ConditionalRouter-jxc96",
          "type": "genericNode",
          "position": {
            "x": 3159.281487367428,
            "y": 544.7344580582932
          },
          "data": {
            "type": "ConditionalRouter",
            "node": {
              "template": {
                "_type": "Component",
                "case_sensitive": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "case_sensitive",
                  "display_name": "Case Sensitive",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, the comparison will be case sensitive.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DropdownInput, MessageInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"equal\"\n    name = \"ConditionalRouter\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageTextInput(\n            name=\"task1\",\n            display_name=\"Task1\",\n            info=\"The text input to compare against.\",\n            value=\"Task1\",\n        ),\n        MessageTextInput(\n            name=\"task2\",\n            display_name=\"Task2\",\n            info=\"The text input to compare against.\",\n            value=\"Task2\",\n        ),\n        MessageTextInput(\n            name=\"task3\",\n            display_name=\"Task3\",\n            info=\"The text input to compare against.\",\n            value=\"Task3\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n      \n    ]\n\n    outputs = [\n        Output(display_name=\"Task1 Route\", name=\"task1_result\", method=\"task1_response\"),\n        Output(display_name=\"Task2 Route\", name=\"task2_result\", method=\"task2_response\"),\n        Output(display_name=\"Task3 Route\", name=\"task3_result\", method=\"task3_response\"),\n    ]\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, case_sensitive: bool) -> bool:\n        if not case_sensitive:\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        elif operator == \"not equals\":\n            return input_text != match_text\n        elif operator == \"contains\":\n            return match_text in input_text\n        elif operator == \"starts with\":\n            return input_text.startswith(match_text)\n        elif operator == \"ends with\":\n            return input_text.endswith(match_text)\n        return False\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"true_result\")\n            return None  # type: ignore\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if not result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"false_result\")\n            return None  # type: ignore\n    \n    def task1_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.task1, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"task1_result\")\n            return None  # type: ignore\n            \n    def task2_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.task2, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"task2_result\")\n            return None  # type: ignore\n\n    def task3_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.task3, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"task3_result\")\n            return None  # type: ignore",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_text",
                  "display_name": "Input Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The primary text input for the operation.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "message",
                  "display_name": "Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The message to pass through either route.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "operator": {
                  "trace_as_metadata": true,
                  "options": [
                    "equals",
                    "not equals",
                    "contains",
                    "starts with",
                    "ends with"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "equals",
                  "name": "operator",
                  "display_name": "Operator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The operator to apply for comparing the texts.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "task1": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Task1",
                  "name": "task1",
                  "display_name": "Task1",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The text input to compare against.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "task2": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Task2",
                  "name": "task2",
                  "display_name": "Task2",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The text input to compare against.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "task3": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Task3",
                  "name": "task3",
                  "display_name": "Task3",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The text input to compare against.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Routes an input message to a corresponding output based on text comparison.",
              "icon": "equal",
              "base_classes": [
                "Message"
              ],
              "display_name": "Conditional Router",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "task1_result",
                  "display_name": "Task1 Route",
                  "method": "task1_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "task2_result",
                  "display_name": "Task2 Route",
                  "method": "task2_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "task3_result",
                  "display_name": "Task3 Route",
                  "method": "task3_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_text",
                "task1",
                "task2",
                "task3",
                "operator",
                "case_sensitive",
                "message"
              ],
              "beta": false,
              "edited": true
            },
            "id": "ConditionalRouter-jxc96"
          },
          "selected": false,
          "width": 384,
          "height": 830,
          "positionAbsolute": {
            "x": 3159.281487367428,
            "y": 544.7344580582932
          },
          "dragging": false
        },
        {
          "id": "Prompt-6wy0q",
          "type": "genericNode",
          "position": {
            "x": 4427.831611162238,
            "y": 893.0273506499984
          },
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-6wy0q",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
                },
                "user_message": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_message",
                  "display_name": "user_message",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "user_message"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "selected": false,
          "width": 384,
          "height": 523,
          "positionAbsolute": {
            "x": 4427.831611162238,
            "y": 893.0273506499984
          },
          "dragging": false
        },
        {
          "id": "Prompt-TF4GE",
          "type": "genericNode",
          "position": {
            "x": 3917.7295560140083,
            "y": 1346.136383268706
          },
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-TF4GE",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
                },
                "user_message": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_message",
                  "display_name": "user_message",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "user_message"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "selected": false,
          "width": 384,
          "height": 523,
          "positionAbsolute": {
            "x": 3917.7295560140083,
            "y": 1346.136383268706
          },
          "dragging": false
        },
        {
          "id": "Prompt-ZXUU6",
          "type": "genericNode",
          "position": {
            "x": 3911.112590223929,
            "y": 1940.3141313103638
          },
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-ZXUU6",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Using following {context}.\nYou are a chatbot web service for delivering a training course for parents of children with autism. And you are developed by The School of Nursing and Health Studies at Hong Kong Metropolitan University (HKMU) .\nAnalysis the user message: {user_message}, define which category the input message is. Choose among below list:\n[\"personal story\", \"assessment\", \"courses\", \"other\"].\n\nReturn with the name of the category.\n\nYour task is to guide users through 8 course modules, interacting and assessing performance to determine advancement. You can provide sudo link of modules if user ask about courses or if you think it's reasonable to provide user with some extra knowledge.\nIf user shares a personal story, please response with empathy and related story if possible.\nIf user tend to have a course, please use some text instruction for course content as if you're a teacher.\nIf user ask to take a assessment, give 5 questions, but only one question at a time. After you ask all five and user answer all of them, give a summary of  evaluation about the anwsers.\n\n\n"
                },
                "user_message": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_message",
                  "display_name": "user_message",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "user_message"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "selected": false,
          "width": 384,
          "height": 523,
          "positionAbsolute": {
            "x": 3911.112590223929,
            "y": 1940.3141313103638
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-qbv4K",
          "type": "genericNode",
          "position": {
            "x": 5119.220385070991,
            "y": 3018.2457612229923
          },
          "data": {
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "id": "OpenAIModel-qbv4K",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "json_mode",
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "gpt-3.5-turbo",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput",
                  "load_from_db": false
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "output_schema",
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1,
                  "name": "seed",
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.1,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false
            },
            "type": "OpenAIModel"
          },
          "selected": false,
          "width": 384,
          "height": 543,
          "positionAbsolute": {
            "x": 5119.220385070991,
            "y": 3018.2457612229923
          },
          "dragging": false
        },
        {
          "id": "FAISS-bMOmL",
          "type": "genericNode",
          "position": {
            "x": 5096.226505516078,
            "y": 2146.002152601459
          },
          "data": {
            "type": "FAISS",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "embedding",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "ingest_data",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "allow_dangerous_deserialization": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "allow_dangerous_deserialization",
                  "display_name": "Allow Dangerous Deserialization",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "index_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "axiestudio_index",
                  "name": "index_name",
                  "display_name": "Index Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 4,
                  "name": "number_of_results",
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "persist_directory",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "search_query",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "FAISS Vector Store with search capabilities",
              "icon": "FAISS",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "FAISS",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "index_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "allow_dangerous_deserialization",
                "embedding",
                "number_of_results"
              ],
              "beta": false,
              "edited": false
            },
            "id": "FAISS-bMOmL"
          },
          "selected": false,
          "width": 384,
          "height": 711,
          "positionAbsolute": {
            "x": 5096.226505516078,
            "y": 2146.002152601459
          },
          "dragging": false
        },
        {
          "id": "HuggingFaceEmbeddings-s3Dgs",
          "type": "genericNode",
          "position": {
            "x": 4493.59668039198,
            "y": 2347.092216357498
          },
          "data": {
            "type": "HuggingFaceEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "cache_folder": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "cache_folder",
                  "display_name": "Cache Folder",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, MessageTextInput, Output\n\n\nclass HuggingFaceEmbeddingsComponent(LCModelComponent):\n    display_name = \"Hugging Face Embeddings\"\n    description = \"Generate embeddings using HuggingFace models.\"\n    documentation = (\n        \"https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers\"\n    )\n    icon = \"HuggingFace\"\n    name = \"HuggingFaceEmbeddings\"\n\n    inputs = [\n        MessageTextInput(name=\"cache_folder\", display_name=\"Cache Folder\", advanced=True),\n        DictInput(name=\"encode_kwargs\", display_name=\"Encode Kwargs\", advanced=True),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"sentence-transformers/all-mpnet-base-v2\"),\n        BoolInput(name=\"multi_process\", display_name=\"Multi Process\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return HuggingFaceEmbeddings(\n            cache_folder=self.cache_folder,\n            encode_kwargs=self.encode_kwargs,\n            model_kwargs=self.model_kwargs,\n            model_name=self.model_name,\n            multi_process=self.multi_process,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "encode_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "encode_kwargs",
                  "display_name": "Encode Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "sentence-transformers/all-mpnet-base-v2",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "multi_process": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "multi_process",
                  "display_name": "Multi Process",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Generate embeddings using HuggingFace models.",
              "icon": "HuggingFace",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Hugging Face Embeddings",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/sentence_transformers",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cache_folder",
                "encode_kwargs",
                "model_kwargs",
                "model_name",
                "multi_process"
              ],
              "beta": false,
              "edited": false
            },
            "id": "HuggingFaceEmbeddings-s3Dgs"
          },
          "selected": false,
          "width": 384,
          "height": 344,
          "positionAbsolute": {
            "x": 4493.59668039198,
            "y": 2347.092216357498
          },
          "dragging": true
        },
        {
          "id": "RetrievalQA-H6j3r",
          "type": "genericNode",
          "position": {
            "x": 5878.690988614894,
            "y": 2058.233610859458
          },
          "data": {
            "type": "RetrievalQA",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMemory"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "retriever": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "retriever",
                  "display_name": "Retriever",
                  "advanced": false,
                  "input_types": [
                    "Retriever"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "chain_type": {
                  "trace_as_metadata": true,
                  "options": [
                    "Stuff",
                    "Map Reduce",
                    "Refine",
                    "Map Rerank"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Stuff",
                  "name": "chain_type",
                  "display_name": "Chain Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Chain type to use.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.chains import RetrievalQA\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import HandleInput, MultilineInput, BoolInput, DropdownInput\n\n\nclass RetrievalQAComponent(LCChainComponent):\n    display_name = \"Retrieval QA\"\n    description = \"Chain for question-answering querying sources from a retriever.\"\n    name = \"RetrievalQA\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        DropdownInput(\n            name=\"chain_type\",\n            display_name=\"Chain Type\",\n            info=\"Chain type to use.\",\n            options=[\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n            value=\"Stuff\",\n            advanced=True,\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(name=\"retriever\", display_name=\"Retriever\", input_types=[\"Retriever\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n        BoolInput(\n            name=\"return_source_documents\",\n            display_name=\"Return Source Documents\",\n            value=False,\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        chain_type = self.chain_type.lower().replace(\" \", \"_\")\n        if self.memory:\n            self.memory.input_key = \"query\"\n            self.memory.output_key = \"result\"\n\n        runnable = RetrievalQA.from_chain_type(\n            llm=self.llm,\n            chain_type=chain_type,\n            retriever=self.retriever,\n            memory=self.memory,\n            # always include to help debugging\n            #\n            return_source_documents=True,\n        )\n\n        result = runnable.invoke({\"query\": self.input_value})\n\n        source_docs = self.to_data(result.get(\"source_documents\", []))\n        result_str = str(result.get(\"result\", \"\"))\n        if self.return_source_documents and len(source_docs):\n            references_str = self.create_references_from_data(source_docs)\n            result_str = \"\\n\".join([result_str, references_str])\n        # put the entire result to debug history, query and content\n        self.status = {**result, \"source_documents\": source_docs, \"output\": result_str}\n        return result_str\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The input value to pass to the chain.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "return_source_documents": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "return_source_documents",
                  "display_name": "Return Source Documents",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Chain for question-answering querying sources from a retriever.",
              "base_classes": [
                "Message"
              ],
              "display_name": "Retrieval QA",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "invoke_chain",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "chain_type",
                "llm",
                "retriever",
                "memory",
                "return_source_documents"
              ],
              "beta": false,
              "edited": false
            },
            "id": "RetrievalQA-H6j3r"
          },
          "selected": false,
          "width": 384,
          "height": 584,
          "positionAbsolute": {
            "x": 5878.690988614894,
            "y": 2058.233610859458
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-TEskx",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-ouWi2",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Prompt-TEskx{dataType:Prompt,id:Prompt-TEskx,name:prompt,output_types:[Message]}-OpenAIModel-ouWi2{fieldName:input_value,id:OpenAIModel-ouWi2,inputTypes:[Message],type:str}",
          "source": "Prompt-TEskx",
          "sourceHandle": "{dataType:Prompt,id:Prompt-TEskx,name:prompt,output_types:[Message]}",
          "target": "OpenAIModel-ouWi2",
          "targetHandle": "{fieldName:input_value,id:OpenAIModel-ouWi2,inputTypes:[Message],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-mdaMN",
              "name": "messages_text",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-TEskx",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}-Prompt-TEskx{fieldName:context,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
          "source": "Memory-mdaMN",
          "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}",
          "target": "Prompt-TEskx",
          "targetHandle": "{fieldName:context,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
          "selected": false
        },
        {
          "source": "ChatInput-m93BG",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}",
          "target": "Prompt-TEskx",
          "targetHandle": "{fieldName:user_message,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "user_message",
              "id": "Prompt-TEskx",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-m93BG",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-m93BG{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}-Prompt-TEskx{fieldName:user_message,id:Prompt-TEskx,inputTypes:[Message,Text],type:str}",
          "selected": false,
          "className": ""
        },
        {
          "source": "Memory-mdaMN",
          "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages,output_types:[Data]}",
          "target": "MongoDBAtlasVector-s3hCe",
          "targetHandle": "{fieldName:ingest_data,id:MongoDBAtlasVector-s3hCe,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "MongoDBAtlasVector-s3hCe",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-mdaMN",
              "name": "messages",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages,output_types:[Data]}-MongoDBAtlasVector-s3hCe{fieldName:ingest_data,id:MongoDBAtlasVector-s3hCe,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "APIRequest-cRGHI",
          "sourceHandle": "{dataType:APIRequest,id:APIRequest-cRGHI,name:data,output_types:[Data]}",
          "target": "ParseData-VJq1Z",
          "targetHandle": "{fieldName:data,id:ParseData-VJq1Z,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ParseData-VJq1Z",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "APIRequest",
              "id": "APIRequest-cRGHI",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-APIRequest-cRGHI{dataType:APIRequest,id:APIRequest-cRGHI,name:data,output_types:[Data]}-ParseData-VJq1Z{fieldName:data,id:ParseData-VJq1Z,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "ChatInput-m93BG",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-m93BG,name:email,output_types:[Message]}",
          "target": "CombineText-wvPwC",
          "targetHandle": "{fieldName:text2,id:CombineText-wvPwC,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "text2",
              "id": "CombineText-wvPwC",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-m93BG",
              "name": "email",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-m93BG{dataType:ChatInput,id:ChatInput-m93BG,name:email,output_types:[Message]}-CombineText-wvPwC{fieldName:text2,id:CombineText-wvPwC,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "CombineText-wvPwC",
          "sourceHandle": "{dataType:CombineText,id:CombineText-wvPwC,name:combined_text,output_types:[Message]}",
          "target": "APIRequest-cRGHI",
          "targetHandle": "{fieldName:curl,id:APIRequest-cRGHI,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "curl",
              "id": "APIRequest-cRGHI",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CombineText",
              "id": "CombineText-wvPwC",
              "name": "combined_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CombineText-wvPwC{dataType:CombineText,id:CombineText-wvPwC,name:combined_text,output_types:[Message]}-APIRequest-cRGHI{fieldName:curl,id:APIRequest-cRGHI,inputTypes:[Message],type:str}",
          "selected": false,
          "className": ""
        },
        {
          "source": "OpenAIModel-ouWi2",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-ouWi2,name:text_output,output_types:[Message]}",
          "target": "ConditionalRouter-jxc96",
          "targetHandle": "{fieldName:input_text,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_text",
              "id": "ConditionalRouter-jxc96",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-ouWi2",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-ouWi2{dataType:OpenAIModel,id:OpenAIModel-ouWi2,name:text_output,output_types:[Message]}-ConditionalRouter-jxc96{fieldName:input_text,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "ChatInput-m93BG",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}",
          "target": "ConditionalRouter-jxc96",
          "targetHandle": "{fieldName:message,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "message",
              "id": "ConditionalRouter-jxc96",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-m93BG",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-m93BG{dataType:ChatInput,id:ChatInput-m93BG,name:message,output_types:[Message]}-ConditionalRouter-jxc96{fieldName:message,id:ConditionalRouter-jxc96,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "Memory-mdaMN",
          "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}",
          "target": "Prompt-6wy0q",
          "targetHandle": "{fieldName:context,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-6wy0q",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-mdaMN",
              "name": "messages_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}-Prompt-6wy0q{fieldName:context,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "ConditionalRouter-jxc96",
          "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task1_result,output_types:[Message]}",
          "target": "Prompt-6wy0q",
          "targetHandle": "{fieldName:user_message,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "user_message",
              "id": "Prompt-6wy0q",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConditionalRouter",
              "id": "ConditionalRouter-jxc96",
              "name": "task1_result",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConditionalRouter-jxc96{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task1_result,output_types:[Message]}-Prompt-6wy0q{fieldName:user_message,id:Prompt-6wy0q,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "ConditionalRouter-jxc96",
          "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task2_result,output_types:[Message]}",
          "target": "Prompt-TF4GE",
          "targetHandle": "{fieldName:user_message,id:Prompt-TF4GE,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "user_message",
              "id": "Prompt-TF4GE",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConditionalRouter",
              "id": "ConditionalRouter-jxc96",
              "name": "task2_result",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConditionalRouter-jxc96{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task2_result,output_types:[Message]}-Prompt-TF4GE{fieldName:user_message,id:Prompt-TF4GE,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "Memory-mdaMN",
          "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}",
          "target": "Prompt-ZXUU6",
          "targetHandle": "{fieldName:context,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-ZXUU6",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-mdaMN",
              "name": "messages_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:messages_text,output_types:[Message]}-Prompt-ZXUU6{fieldName:context,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "ConditionalRouter-jxc96",
          "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task3_result,output_types:[Message]}",
          "target": "Prompt-ZXUU6",
          "targetHandle": "{fieldName:user_message,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "user_message",
              "id": "Prompt-ZXUU6",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConditionalRouter",
              "id": "ConditionalRouter-jxc96",
              "name": "task3_result",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConditionalRouter-jxc96{dataType:ConditionalRouter,id:ConditionalRouter-jxc96,name:task3_result,output_types:[Message]}-Prompt-ZXUU6{fieldName:user_message,id:Prompt-ZXUU6,inputTypes:[Message,Text],type:str}",
          "className": ""
        },
        {
          "source": "HuggingFaceEmbeddings-s3Dgs",
          "sourceHandle": "{dataType:HuggingFaceEmbeddings,id:HuggingFaceEmbeddings-s3Dgs,name:embeddings,output_types:[Embeddings]}",
          "target": "FAISS-bMOmL",
          "targetHandle": "{fieldName:embedding,id:FAISS-bMOmL,inputTypes:[Embeddings],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "FAISS-bMOmL",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "HuggingFaceEmbeddings",
              "id": "HuggingFaceEmbeddings-s3Dgs",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-HuggingFaceEmbeddings-s3Dgs{dataType:HuggingFaceEmbeddings,id:HuggingFaceEmbeddings-s3Dgs,name:embeddings,output_types:[Embeddings]}-FAISS-bMOmL{fieldName:embedding,id:FAISS-bMOmL,inputTypes:[Embeddings],type:other}",
          "className": ""
        },
        {
          "source": "FAISS-bMOmL",
          "sourceHandle": "{dataType:FAISS,id:FAISS-bMOmL,name:base_retriever,output_types:[Retriever]}",
          "target": "RetrievalQA-H6j3r",
          "targetHandle": "{fieldName:retriever,id:RetrievalQA-H6j3r,inputTypes:[Retriever],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "retriever",
              "id": "RetrievalQA-H6j3r",
              "inputTypes": [
                "Retriever"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "FAISS",
              "id": "FAISS-bMOmL",
              "name": "base_retriever",
              "output_types": [
                "Retriever"
              ]
            }
          },
          "id": "reactflow__edge-FAISS-bMOmL{dataType:FAISS,id:FAISS-bMOmL,name:base_retriever,output_types:[Retriever]}-RetrievalQA-H6j3r{fieldName:retriever,id:RetrievalQA-H6j3r,inputTypes:[Retriever],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIModel-qbv4K",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-qbv4K,name:model_output,output_types:[LanguageModel]}",
          "target": "RetrievalQA-H6j3r",
          "targetHandle": "{fieldName:llm,id:RetrievalQA-H6j3r,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "RetrievalQA-H6j3r",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-qbv4K",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-qbv4K{dataType:OpenAIModel,id:OpenAIModel-qbv4K,name:model_output,output_types:[LanguageModel]}-RetrievalQA-H6j3r{fieldName:llm,id:RetrievalQA-H6j3r,inputTypes:[LanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "Memory-mdaMN",
          "sourceHandle": "{dataType:Memory,id:Memory-mdaMN,name:lc_memory,output_types:[BaseChatMemory]}",
          "target": "RetrievalQA-H6j3r",
          "targetHandle": "{fieldName:memory,id:RetrievalQA-H6j3r,inputTypes:[BaseChatMemory],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "RetrievalQA-H6j3r",
              "inputTypes": [
                "BaseChatMemory"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-mdaMN",
              "name": "lc_memory",
              "output_types": [
                "BaseChatMemory"
              ]
            }
          },
          "id": "reactflow__edge-Memory-mdaMN{dataType:Memory,id:Memory-mdaMN,name:lc_memory,output_types:[BaseChatMemory]}-RetrievalQA-H6j3r{fieldName:memory,id:RetrievalQA-H6j3r,inputTypes:[BaseChatMemory],type:other}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 115.14079235477533,
        "y": 53.072975125132984,
        "zoom": 0.12266007341946632
      }
    },
    "date_created": "2024-08-06T07:59:12.293Z",
    "date_updated": "2024-08-06T07:59:12.524Z",
    "status": "Public",
    "sort": null,
    "user_updated": "6c2b8ddb-0368-495e-8398-58e6adca98ba",
    "user_created": {
      "username": "SkylerZeng",
      "first_name": "Skyler",
      "last_name": "zeng",
      "id": "6c2b8ddb-0368-495e-8398-58e6adca98ba"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:57.047Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 162,
    "converter_version": "1.0.0"
  }
}