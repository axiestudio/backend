{
  "id": "467cccd8-d68b-4ed8-af7f-fda9b5e74045",
  "name": "OrpheoMain",
  "description": "This project can be used as a starting point for building a Chat experience with user specific memory. You can set a different Session ID to start a new message history. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "fmanto",
    "first_name": "Francesco",
    "last_name": "Mantovani",
    "id": "10d3653a-d667-4b0e-b3bd-a3f507bf0f47",
    "full_name": "Francesco Mantovani"
  },
  "store_url": "https://www.langflow.store/store/component/467cccd8-d68b-4ed8-af7f-fda9b5e74045",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-11T18:08:00.365Z",
    "updated": "2024-10-11T18:08:00.479Z",
    "downloaded": "2025-08-19T17:50:07.594Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.18",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-jWyal",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{context}\n\nUser: {user_message}\nAI: ",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "user_message": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_message",
                "display_name": "user_message",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "user_message"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 502,
        "id": "Prompt-jWyal",
        "position": {
          "x": 1880.8227904110583,
          "y": 625.8049209882275
        },
        "positionAbsolute": {
          "x": 1880.8227904110583,
          "y": 625.8049209882275
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-8tP8C",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "can you cover the smell?",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "123",
                "display_name": "Session ID",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 388,
        "id": "ChatInput-8tP8C",
        "position": {
          "x": 1307.820177917901,
          "y": 846.754125206539
        },
        "positionAbsolute": {
          "x": 1307.820177917901,
          "y": 846.754125206539
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI",
          "id": "OpenAIModel-vhY8r",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": true,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 605,
        "id": "OpenAIModel-vhY8r",
        "position": {
          "x": 2468.968379487559,
          "y": 560.0689522326683
        },
        "positionAbsolute": {
          "x": 2468.968379487559,
          "y": 560.0689522326683
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-0Si2J",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "ChatOutput"
        },
        "height": 302,
        "id": "ChatOutput-0Si2J",
        "position": {
          "x": 4291.105107933034,
          "y": 1517.7631428808918
        },
        "selected": false,
        "type": "genericNode",
        "width": 384,
        "positionAbsolute": {
          "x": 4291.105107933034,
          "y": 1517.7631428808918
        },
        "dragging": false
      },
      {
        "data": {
          "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
          "display_name": "Chat Memory",
          "id": "Memory-CbogB",
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "order": {
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "icon": "message-square-more",
            "base_classes": [
              "BaseChatMemory",
              "Data",
              "Message"
            ],
            "display_name": "Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Messages (Data)",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "BaseChatMemory"
                ],
                "selected": "BaseChatMemory",
                "name": "lc_memory",
                "display_name": "Memory",
                "method": "build_lc_memory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "type": "Memory"
        },
        "dragging": false,
        "height": 382,
        "id": "Memory-CbogB",
        "position": {
          "x": 1301.98330242754,
          "y": 422.33865605652574
        },
        "positionAbsolute": {
          "x": 1301.98330242754,
          "y": 422.33865605652574
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "OpenAIToolsAgent-iTroj",
        "type": "genericNode",
        "position": {
          "x": 3038.841010223995,
          "y": 1525.5865078250145
        },
        "data": {
          "type": "OpenAIToolsAgent",
          "node": {
            "template": {
              "_type": "Component",
              "chat_history": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_history",
                "value": "",
                "display_name": "Chat History",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel",
                  "ToolEnabledLanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, List\n\nfrom langchain.agents import create_openai_tools_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.inputs import MultilineInput\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\nfrom axiestudio.schema import Data\n\n\nclass OpenAIToolsAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"OpenAI Tools Agent\"\n    description: str = \"Agent that uses tools via openai-tools.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"OpenAIToolsAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\", \"ToolEnabledLanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_openai_tools_agent(self.llm, self.tools, prompt)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "system_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant of a BMW Car. Your name is Orpheo. You reply to the requests that the user makes via voice interaction. The request contains information on who's interacting (i.e. driver or passenger) and their name. Your replies always start mentioning who made the request by name (e.g. \"Francesco, ...\", \"Stefan, ...\"). Always use the tools to get more information about the person who you are interacting with.\nYou also have the scent diffuser tool to release scents in the cabin. Use it as appropriate.\nYour current location is Mountain View, CA.\nYour replies have to be short and concise, only include the relevant context.\nYou will also have to decide if further input is needed from the user.\nThe output must be a a json a json like this:\n \"text\": \"your reply here\",\n\"need_user_input\": true|false.\n",
                "display_name": "System Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System prompt for the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "user_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_prompt",
                "value": "{input}",
                "display_name": "Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "This prompt must contain 'input' key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Agent that uses tools via openai-tools.",
            "icon": "LangChain",
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "display_name": "OpenAI Tools Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "AgentExecutor"
                ],
                "selected": "AgentExecutor",
                "name": "agent",
                "display_name": "Agent",
                "method": "build_agent",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "tools",
              "llm",
              "system_prompt",
              "user_prompt",
              "chat_history"
            ],
            "beta": true,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "OpenAIToolsAgent-iTroj"
        },
        "selected": false,
        "width": 384,
        "height": 615,
        "positionAbsolute": {
          "x": 3038.841010223995,
          "y": 1525.5865078250145
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-eXRyc",
        "type": "genericNode",
        "position": {
          "x": 1645.5035647247819,
          "y": 1755.0100903852804
        },
        "data": {
          "type": "FaceRecognizer",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import paho.mqtt.client as mqtt\nimport paho.mqtt.subscribe as subscribe\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass FaceRecognizer(Component):\n    icon = \"cctv\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"face_rec_tool\", method=\"build_tool\"),\n    ]\n\n\n\n\n    def face_rec(self) -> str:\n        msg = subscribe.simple(\"orpheo/ai/face_id/driver\", hostname=\"192.168.50.10\")\n        print(\"returning faces: \" + str(msg.payload))\n        return str(msg.payload)\n\n    def build_tool(self) -> Tool:\n        face_recognizer_tool = StructuredTool.from_function(\n        func=self.face_rec,\n        name=\"FaceRecognizer_driver\",\n        description=\"Returns the name and facial features (age, emotion, gender) of the person in the driver seat\",\n        #args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        return face_recognizer_tool\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "icon": "cctv",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Face Recognizer Driver",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "face_rec_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "CustomComponent-eXRyc"
        },
        "selected": false,
        "width": 384,
        "height": 208,
        "dragging": false,
        "positionAbsolute": {
          "x": 1645.5035647247819,
          "y": 1755.0100903852804
        }
      },
      {
        "id": "CustomComponent-cs25Q",
        "type": "genericNode",
        "position": {
          "x": 1649.676205521081,
          "y": 1497.595592257298
        },
        "data": {
          "type": "FaceRecognizer",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import paho.mqtt.client as mqtt\nimport paho.mqtt.subscribe as subscribe\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass FaceRecognizer(Component):\n    icon = \"cctv\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"face_rec_tool\", method=\"build_tool\"),\n    ]\n\n\n\n\n    def face_rec(self) -> str:\n        msg = subscribe.simple(\"orpheo/ai/face_id/passenger\", hostname=\"192.168.50.10\")\n        print(\"returning faces: \" + str(msg.payload))\n        return str(msg.payload)\n\n    def build_tool(self) -> Tool:\n        face_recognizer_tool = StructuredTool.from_function(\n        func=self.face_rec,\n        name=\"FaceRecognizer_Passenger\",\n        description=\"Returns the name and facial features (age, emotion, gender) of the person in the passenger seat\",\n        #args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        return face_recognizer_tool\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "icon": "cctv",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Face Recognizer Passenger",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "face_rec_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "CustomComponent-cs25Q"
        },
        "selected": false,
        "width": 384,
        "height": 208,
        "dragging": false,
        "positionAbsolute": {
          "x": 1649.676205521081,
          "y": 1497.595592257298
        }
      },
      {
        "id": "CustomComponent-vuTAo",
        "type": "genericNode",
        "position": {
          "x": 1651.328051192944,
          "y": 2010.773760567024
        },
        "data": {
          "type": "SeatMover",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import paho.mqtt.client as mqtt\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass SeatMover(Component):\n    icon = \"rocking-chair\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def on_connect(client, userdata, flags, reason_code, properties):\n        print(f\"Connected with result code {reason_code}\")\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n\n    class SeatMoverInput(BaseModel):\n        seat: str = Field(description=\"Seat: driver or passenger\")\n        direction: int = Field(description=\"Direction of movement: 1 = forward, -1 = backwards\")\n\n\n    def move_seat(self, seat: int, direction :int) -> str:\n        print(\"Moving Seat: \" + seat + \" Direction: \" + str(direction))\n        seat_topic = \"SeatControl/Driver/SLV/\" if seat == \"driver\" else \"SeatControl/Passenger/SLV/\"\n        seat_motion = \"Forward\" if direction == 1 else \"Back\"\n        seat_topic = seat_topic+seat_motion\n        print(\"Moving Seat\")\n        self.mqttc.publish(seat_topic, \"1\")\n        time.sleep(2)\n        self.mqttc.publish(\"SeatControl/Stop\", \"1\")\n        print(\"Stopping Seat\")\n\n        return \"Moving Seat: \" + seat + \" Direction: \" + str(direction)\n\n    def build_tool(self) -> Tool:\n        seat_mover_tool = StructuredTool.from_function(\n        func=self.move_seat,\n        name=\"SeatMover\",\n        description=\"Move a car seat horizontally given the seat (driver or passenger) and the direction of movement (forward or backwards)\",\n        args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        print(seat_mover_tool.args)\n        return seat_mover_tool\n\n\n\n\n\n\n\"\"\" # The callback for when the client receives a CONNACK response from the server.\ndef on_connect(client, userdata, flags, reason_code, properties):\n    print(f\"Connected with result code {reason_code}\")\n\ndef move_seat(seat: str, direction: int):\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n    mqttc.publish(\"axiestudio/test\", \"test\")\n    mqttc.publish(\"axiestudio/test\", \"seat: \" + seat + str(direction))\n    return \"OK\" \"\"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "icon": "rocking-chair",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Seat Mover FORWARD/BACK",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "CustomComponent-vuTAo"
        },
        "selected": true,
        "width": 384,
        "height": 208,
        "dragging": false,
        "positionAbsolute": {
          "x": 1651.328051192944,
          "y": 2010.773760567024
        }
      },
      {
        "id": "PythonCodeStructuredTool-xPU8j",
        "type": "genericNode",
        "position": {
          "x": 1186.8036384107688,
          "y": 1479.324335938785
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "Component",
              "_classes": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_classes",
                "value": "[]",
                "display_name": "Classes",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "_functions": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_functions",
                "value": "{\"get_current_pacific_time\": {\"name\": \"get_current_pacific_time\", \"args\": []}}",
                "display_name": "Functions",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "global_variables": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "global_variables",
                "value": "",
                "display_name": "Global Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Enter the global variables or Create Data Component.",
                "title_case": false,
                "type": "dict",
                "_input_type": "HandleInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": false,
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tool_code": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "show": true,
                "name": "tool_code",
                "value": "from datetime import datetime\nimport pytz\n\ndef get_current_pacific_time():\n    # Define the timezone for US West Coast\n    pacific_timezone = pytz.timezone('America/Los_Angeles')\n    \n    # Get current time in UTC\n    utc_now = datetime.utcnow()\n    \n    # Localize the UTC time to the Pacific Time Zone\n    pacific_time = pytz.utc.localize(utc_now).astimezone(pacific_timezone)\n    \n    return pacific_time",
                "display_name": "Tool Code",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "tool_description": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "Returns the date and the time in the current timezone",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tool_function": {
                "trace_as_metadata": true,
                "options": [
                  "get_current_pacific_time"
                ],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_function",
                "value": "get_current_pacific_time",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "tool_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "date_time",
                "display_name": "Tool Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "structuredtool dataclass code to tool",
            "icon": "",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Current Date Time",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "tool_code",
              "tool_name",
              "tool_description",
              "return_direct",
              "tool_function",
              "global_variables",
              "_classes",
              "_functions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PythonCodeStructuredTool-xPU8j"
        },
        "selected": false,
        "width": 384,
        "height": 714,
        "positionAbsolute": {
          "x": 1186.8036384107688,
          "y": 1479.324335938785
        },
        "dragging": false
      },
      {
        "id": "PythonCodeStructuredTool-xF4JR",
        "type": "genericNode",
        "position": {
          "x": 762.0986362867036,
          "y": 1472.3955483240736
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "Component",
              "_classes": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_classes",
                "value": "[]",
                "display_name": "Classes",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "_functions": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_functions",
                "value": "{\"get_weather_info\": {\"name\": \"get_weather_info\", \"args\": [{\"name\": \"location\", \"annotation\": null}]}}",
                "display_name": "Functions",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "global_variables": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "global_variables",
                "value": "",
                "display_name": "Global Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Enter the global variables or Create Data Component.",
                "title_case": false,
                "type": "dict",
                "_input_type": "HandleInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": false,
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tool_code": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "show": true,
                "name": "tool_code",
                "value": "def get_weather_info(location):\n    api_key = 'fb44c460b7104fe5b69180737240409'\n    base_url = \"http://api.weatherapi.com/v1/current.json\"\n    params = {\n        'key': api_key,\n        'q': location\n    }\n    \n    response = requests.get(base_url, params=params)\n    \n    if response.status_code == 200:\n        data = response.json()\n        weather_info = {\n            \"location\": data.get(\"location\", {}).get(\"name\"),\n            \"temperature\": data.get(\"current\", {}).get(\"temp_c\"),\n            \"description\": data.get(\"current\", {}).get(\"condition\", {}).get(\"text\"),\n            \"humidity\": data.get(\"current\", {}).get(\"humidity\"),\n            \"pressure\": data.get(\"current\", {}).get(\"pressure_mb\"),\n            \"wind_speed\": data.get(\"current\", {}).get(\"wind_kph\")\n        }\n        return weather_info\n    else:\n        return f\"Error: Unable to get weather information for {location}. Status code: {response.status_code}\"",
                "display_name": "Tool Code",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "tool_description": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "This function returns the current weather information (temperature, description, humidity, pressure and wind) of a given location)",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tool_function": {
                "trace_as_metadata": true,
                "options": [
                  "get_weather_info"
                ],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_function",
                "value": "get_weather_info",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "tool_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "current_weather",
                "display_name": "Tool Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "get_weather_info|location": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "get_weather_info|location",
                "value": "The name of the location",
                "display_name": "location: Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description for location",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "structuredtool dataclass code to tool",
            "icon": "",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Current Weather",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "tool_code",
              "tool_name",
              "tool_description",
              "return_direct",
              "tool_function",
              "global_variables",
              "_classes",
              "_functions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PythonCodeStructuredTool-xF4JR"
        },
        "selected": false,
        "width": 384,
        "height": 800,
        "positionAbsolute": {
          "x": 762.0986362867036,
          "y": 1472.3955483240736
        },
        "dragging": false
      },
      {
        "id": "PythonCodeStructuredTool-Lmmfb",
        "type": "genericNode",
        "position": {
          "x": 312.452678312957,
          "y": 1466.7133219374352
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "Component",
              "_classes": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_classes",
                "value": "[]",
                "display_name": "Classes",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "_functions": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_functions",
                "value": "{\"get_weather_forecast\": {\"name\": \"get_weather_forecast\", \"args\": [{\"name\": \"location\", \"annotation\": null}, {\"name\": \"days\", \"annotation\": null}]}}",
                "display_name": "Functions",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "global_variables": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "global_variables",
                "value": "",
                "display_name": "Global Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Enter the global variables or Create Data Component.",
                "title_case": false,
                "type": "dict",
                "_input_type": "HandleInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": false,
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tool_code": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "show": true,
                "name": "tool_code",
                "value": "def get_weather_forecast(location, days=1):\n    api_key = 'fb44c460b7104fe5b69180737240409'\n    base_url = \"http://api.weatherapi.com/v1/forecast.json\"\n    params = {\n        'key': api_key,\n        'q': location,\n        'days': days  # Number of days to forecast (1-10)\n    }\n    \n    response = requests.get(base_url, params=params)\n    \n    if response.status_code == 200:\n        data = response.json()\n        forecast_days = data.get(\"forecast\", {}).get(\"forecastday\", [])\n        \n        forecast_info = []\n        for day in forecast_days:\n            day_info = {\n                \"date\": day.get(\"date\"),\n                \"avg_temp_c\": day.get(\"day\", {}).get(\"avgtemp_c\"),\n                \"condition\": day.get(\"day\", {}).get(\"condition\", {}).get(\"text\"),\n                \"max_temp_c\": day.get(\"day\", {}).get(\"maxtemp_c\"),\n                \"min_temp_c\": day.get(\"day\", {}).get(\"mintemp_c\"),\n                \"max_wind_kph\": day.get(\"day\", {}).get(\"maxwind_kph\"),\n                \"total_precip_mm\": day.get(\"day\", {}).get(\"totalprecip_mm\"),\n                \"uv_index\": day.get(\"day\", {}).get(\"uv\"),\n            }\n            forecast_info.append(day_info)\n            \n        return forecast_info\n    else:\n        return f\"Error: Unable to get the weather forecast for {location}. Status code:{response.status_code}\"",
                "display_name": "Tool Code",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "tool_description": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "This function returns the weather forecast information of a given location, given the number of days in the future",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tool_function": {
                "trace_as_metadata": true,
                "options": [
                  "get_weather_forecast"
                ],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_function",
                "value": "get_weather_forecast",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "tool_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "current_weather",
                "display_name": "Tool Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "get_weather_forecast|location": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "get_weather_forecast|location",
                "value": "The name of the location to be forecasted",
                "display_name": "location: Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description for location",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "get_weather_forecast|days": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "get_weather_forecast|days",
                "value": "Days in the future for which you what to know the weather forecast (1-10))",
                "display_name": "days: Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description for days",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "structuredtool dataclass code to tool",
            "icon": "",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Weather Forecast",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "tool_code",
              "tool_name",
              "tool_description",
              "return_direct",
              "tool_function",
              "global_variables",
              "_classes",
              "_functions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PythonCodeStructuredTool-Lmmfb"
        },
        "selected": false,
        "width": 384,
        "height": 886,
        "positionAbsolute": {
          "x": 312.452678312957,
          "y": 1466.7133219374352
        },
        "dragging": false
      },
      {
        "id": "PythonCodeStructuredTool-slJhZ",
        "type": "genericNode",
        "position": {
          "x": -148.05623953363335,
          "y": 1475.5547388050638
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "Component",
              "_classes": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_classes",
                "value": "[]",
                "display_name": "Classes",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "_functions": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "_functions",
                "value": "{\"get_user_data\": {\"name\": \"get_user_data\", \"args\": [{\"name\": \"user_id\", \"annotation\": null}]}}",
                "display_name": "Functions",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "global_variables": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "global_variables",
                "value": "",
                "display_name": "Global Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Enter the global variables or Create Data Component.",
                "title_case": false,
                "type": "dict",
                "_input_type": "HandleInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": false,
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tool_code": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "show": true,
                "name": "tool_code",
                "value": "import os\nimport json\n\ndef get_user_data(user_id):\n    base_dir = \"/home/bmw/src/context_manager_UI/backend/data\"\n    user_folder = os.path.join(base_dir, user_id)\n    \n    # Return an empty string if user folder doesn't exist\n    if not os.path.exists(user_folder):\n        return \"\"\n\n    result = {\n        'person': user_id,\n        'context': []\n    }\n\n    # Loop through all files in the user's folder\n    try:\n        for filename in os.listdir(user_folder):\n            if filename.endswith('.txt'):\n                file_path = os.path.join(user_folder, filename)\n                description = os.path.splitext(filename)[0]  # Remove the \".txt\" extension\n                \n                with open(file_path, 'r') as file:\n                    file_content = file.read()\n\n                # Append the file content and description to the context list\n                result['context'].append({\n                    'description': description,\n                    'content': file_content\n                })\n        \n        return json.dumps(result, indent=4)  # Convert the result to a pretty JSON structure\n\n    except Exception as e:\n        return f\"An error occurred while reading files: {e}\"",
                "display_name": "Tool Code",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "tool_description": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_description",
                "value": "This tools provides some context information about a person, given their name. The information could include some general infromation, car setting preferences, music preferences, trips preferences and more (this list is not complete). It returns a object with the context area and the context information.",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tool_function": {
                "trace_as_metadata": true,
                "options": [
                  "get_user_data"
                ],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_function",
                "value": "get_user_data",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "tool_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tool_name",
                "value": "PersonContextRetriever",
                "display_name": "Tool Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "get_user_data|user_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "get_user_data|user_id",
                "value": "",
                "display_name": "user_id: Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the description for user_id",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Tools to retrieve person context data",
            "icon": "",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Context retriever",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "tool_code",
              "tool_name",
              "tool_description",
              "return_direct",
              "tool_function",
              "global_variables",
              "_classes",
              "_functions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PythonCodeStructuredTool-slJhZ"
        },
        "selected": false,
        "width": 384,
        "height": 800,
        "positionAbsolute": {
          "x": -148.05623953363335,
          "y": 1475.5547388050638
        },
        "dragging": false
      },
      {
        "id": "SeatMover-iFnNh",
        "type": "genericNode",
        "position": {
          "x": 1651.780645060777,
          "y": 2239.9132290207253
        },
        "data": {
          "type": "SeatMover",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import paho.mqtt.client as mqtt\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass SeatMover(Component):\n    icon = \"rocking-chair\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def on_connect(client, userdata, flags, reason_code, properties):\n        print(f\"Connected with result code {reason_code}\")\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n\n    class SeatMoverInput(BaseModel):\n        seat: str = Field(description=\"Seat: driver or passenger\")\n        direction: int = Field(description=\"Direction of movement: 1 = up, -1 = down\")\n\n\n    def move_seat(self, seat: int, direction :int) -> str:\n        print(\"Moving Seat: \" + seat + \" Direction: \" + str(direction))\n        seat_topic = \"SeatControl/Driver/SHV/\" if seat == \"driver\" else \"SeatControl/Passenger/SHV/\"\n        seat_motion = \"Up\" if direction == 1 else \"Down\"\n        seat_topic = seat_topic+seat_motion\n        print(\"Moving Seat\")\n        self.mqttc.publish(seat_topic, \"1\")\n        time.sleep(2)\n        self.mqttc.publish(\"SeatControl/Stop\", \"1\")\n        print(\"Stopping Seat\")\n\n        return \"Moving Seat: \" + seat + \" Direction: \" + str(direction)\n\n    def build_tool(self) -> Tool:\n        seat_mover_tool = StructuredTool.from_function(\n        func=self.move_seat,\n        name=\"SeatMoverV\",\n        description=\"Move a car seat given the seat on the vertical axis up or down (driver or passenger) and the direction of movement (up or down). Short people should be moved up, tall people should be moved down\",\n        args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        print(seat_mover_tool.args)\n        return seat_mover_tool\n\n\n\n\n\n\n\"\"\" # The callback for when the client receives a CONNACK response from the server.\ndef on_connect(client, userdata, flags, reason_code, properties):\n    print(f\"Connected with result code {reason_code}\")\n\ndef move_seat(seat: str, direction: int):\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n    mqttc.publish(\"axiestudio/test\", \"test\")\n    mqttc.publish(\"axiestudio/test\", \"seat: \" + seat + str(direction))\n    return \"OK\" \"\"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "icon": "rocking-chair",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Seat Mover UP/DOWN",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "SeatMover-iFnNh"
        },
        "selected": false,
        "width": 384,
        "height": 208,
        "positionAbsolute": {
          "x": 1651.780645060777,
          "y": 2239.9132290207253
        },
        "dragging": false
      },
      {
        "id": "SeatMover-7SQOy",
        "type": "genericNode",
        "position": {
          "x": 1649.2961403892484,
          "y": 2463.518649458326
        },
        "data": {
          "type": "SeatMover",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import paho.mqtt.client as mqtt\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass SeatMover(Component):\n    icon = \"rocking-chair\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def on_connect(client, userdata, flags, reason_code, properties):\n        print(f\"Connected with result code {reason_code}\")\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n\n    class SeatMoverInput(BaseModel):\n        seat: str = Field(description=\"Seat: driver or passenger\")\n        direction: int = Field(description=\"Direction of movement: 1 = forward, -1 = back\")\n\n\n    def move_seat(self, seat: int, direction :int) -> str:\n        print(\"Moving Seat: \" + seat + \" Direction: \" + str(direction))\n        seat_topic = \"SeatControl/Driver/LNV/\" if seat == \"driver\" else \"SeatControl/Passenger/LNV/\"\n        seat_motion = \"Forward\" if direction == 1 else \"Back\"\n        seat_topic = seat_topic+seat_motion\n        print(\"Moving Seat\")\n        self.mqttc.publish(seat_topic, \"1\")\n        time.sleep(2)\n        self.mqttc.publish(\"SeatControl/Stop\", \"1\")\n        print(\"Stopping Seat\")\n\n        return \"Moving Seat: \" + seat + \" Direction: \" + str(direction)\n\n    def build_tool(self) -> Tool:\n        seat_mover_tool = StructuredTool.from_function(\n        func=self.move_seat,\n        name=\"SeatMoverR\",\n        description=\"Recline a car seat backrest given the seat (driver or passenger) and the direction of movement (forward or backwards)\",\n        args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        print(seat_mover_tool.args)\n        return seat_mover_tool\n\n\n\n\n\n\n\"\"\" # The callback for when the client receives a CONNACK response from the server.\ndef on_connect(client, userdata, flags, reason_code, properties):\n    print(f\"Connected with result code {reason_code}\")\n\ndef move_seat(seat: str, direction: int):\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n    mqttc.publish(\"axiestudio/test\", \"test\")\n    mqttc.publish(\"axiestudio/test\", \"seat: \" + seat + str(direction))\n    return \"OK\" \"\"\"",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "icon": "rocking-chair",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Seat Mover Recline",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "result_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "SeatMover-7SQOy"
        },
        "selected": false,
        "width": 384,
        "height": 208,
        "positionAbsolute": {
          "x": 1649.2961403892484,
          "y": 2463.518649458326
        },
        "dragging": false
      },
      {
        "id": "JSONCleaner-GCEXx",
        "type": "genericNode",
        "position": {
          "x": 3572.5094468047073,
          "y": 1807.9865935758532
        },
        "data": {
          "type": "JSONCleaner",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\nimport re\nimport unicodedata\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, BoolInput\nfrom axiestudio.template import Output\nfrom axiestudio.schema.message import Message\n\n\nclass JSONCleaner(Component):\n    display_name = \"JSON Cleaner\"\n    description = \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.\"\n    icon = \"custom_components\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import the json_repair package.\" \"Please install it with `pip install json_repair`.\"\n            )\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        try:\n            start = json_str.find(\"{\")\n            end = json_str.rfind(\"}\")\n            if start == -1 or end == -1:\n                raise ValueError(\"Invalid JSON string: Missing '{' or '}'\")\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            raise ValueError(f\"Error cleaning JSON string: {str(e)}\")\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", s)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n            return s\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON string: {str(e)}\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "json_str": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "json_str",
                "value": "",
                "display_name": "JSON String",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The JSON string to be cleaned.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "normalize_unicode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "normalize_unicode",
                "value": false,
                "display_name": "Normalize Unicode",
                "advanced": false,
                "dynamic": false,
                "info": "Normalize Unicode characters in the JSON string.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "remove_control_chars": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "remove_control_chars",
                "value": false,
                "display_name": "Remove Control Characters",
                "advanced": false,
                "dynamic": false,
                "info": "Remove control characters from the JSON string.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "validate_json": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "validate_json",
                "value": true,
                "display_name": "Validate JSON",
                "advanced": false,
                "dynamic": false,
                "info": "Validate the JSON string to ensure it is well-formed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "JSON Cleaner",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Cleaned JSON String",
                "method": "clean_json",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "json_str",
              "remove_control_chars",
              "normalize_unicode",
              "validate_json"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "JSONCleaner-GCEXx"
        },
        "selected": false,
        "width": 384,
        "height": 574,
        "positionAbsolute": {
          "x": 3572.5094468047073,
          "y": 1807.9865935758532
        },
        "dragging": false
      },
      {
        "id": "FlowTool-ln4do",
        "type": "genericNode",
        "position": {
          "x": 1679.9139476903108,
          "y": 2820.9070853180165
        },
        "data": {
          "type": "FlowTool",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any, List, Optional\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.base.tools.flow_tool import FlowTool\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.graph.graph.base import Graph\nfrom axiestudio.helpers.flow import get_flow_inputs\nfrom axiestudio.io import BoolInput, DropdownInput, Output, StrInput\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass FlowToolComponent(LCToolComponent):\n    display_name = \"Flow as Tool\"\n    description = \"Construct a Tool from a function that runs the loaded Flow.\"\n    field_order = [\"flow_name\", \"name\", \"description\", \"return_direct\"]\n    trace_type = \"tool\"\n    name = \"FlowTool\"\n    beta = True\n\n    def get_flow_names(self) -> List[str]:\n        flow_datas = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    def get_flow(self, flow_name: str) -> Optional[Data]:\n        \"\"\"\n        Retrieves a flow by its name.\n\n        Args:\n            flow_name (str): The name of the flow to retrieve.\n\n        Returns:\n            Optional[Text]: The flow record if found, None otherwise.\n        \"\"\"\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\", display_name=\"Flow Name\", info=\"The name of the flow to run.\", refresh_button=True\n        ),\n        StrInput(\n            name=\"name\",\n            display_name=\"Name\",\n            info=\"The name of the tool.\",\n        ),\n        StrInput(\n            name=\"description\",\n            display_name=\"Description\",\n            info=\"The description of the tool.\",\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Direct\",\n            info=\"Return the result directly from the Tool.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"api_build_tool\", display_name=\"Tool\", method=\"build_tool\"),\n    ]\n\n    def build_tool(self) -> Tool:\n        FlowTool.update_forward_refs()\n        if \"flow_name\" not in self._attributes or not self._attributes[\"flow_name\"]:\n            raise ValueError(\"Flow name is required\")\n        flow_name = self._attributes[\"flow_name\"]\n        flow_data = self.get_flow(flow_name)\n        if not flow_data:\n            raise ValueError(\"Flow not found.\")\n        graph = Graph.from_payload(flow_data.data[\"data\"])\n        inputs = get_flow_inputs(graph)\n        tool = FlowTool(\n            name=self.name,\n            description=self.description,\n            graph=graph,\n            return_direct=self.return_direct,\n            inputs=inputs,\n            flow_id=str(flow_data.id),\n            user_id=str(self.user_id),\n        )\n        description_repr = repr(tool.description).strip(\"'\")\n        args_str = \"\\n\".join([f\"- {arg_name}: {arg_data['description']}\" for arg_name, arg_data in tool.args.items()])\n        self.status = f\"{description_repr}\\nArguments:\\n{args_str}\"\n        return tool  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "description": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "description",
                "value": "This tool releases scents inside the car. It has knowledge of the scents it can release and and their notes. Base on  the user input it can release the right scent for that specific situation. Always call this tool when a scent release is needed.",
                "display_name": "Description",
                "advanced": false,
                "dynamic": false,
                "info": "The description of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "flow_name": {
                "trace_as_metadata": true,
                "options": [
                  "Memory Chatbot",
                  "Basic Prompting (Hello, World) (2)",
                  "Memory Chatbot (1)",
                  "OrpheoMain",
                  "Orpheo Continous",
                  "Basic Prompting (Hello, World)",
                  "Memory Chatbot (2)",
                  "Basic Prompting (Hello, World) (1)",
                  "Untitled document",
                  "Interviewer",
                  "Untitled document (2)",
                  "ScentDiffuser-ATMOS",
                  "Simple Agent"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "flow_name",
                "value": "ScentDiffuser-ATMOS",
                "display_name": "Flow Name",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the flow to run.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "name",
                "value": "scent_diffuser",
                "display_name": "Name",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the tool.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "return_direct": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "return_direct",
                "value": false,
                "display_name": "Return Direct",
                "advanced": true,
                "dynamic": false,
                "info": "Return the result directly from the Tool.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Construct a Tool from a function that runs the loaded Flow.",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Flow as Tool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "flow_name",
              "name",
              "description",
              "return_direct"
            ],
            "beta": true,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "FlowTool-ln4do"
        },
        "selected": false,
        "width": 384,
        "height": 502,
        "positionAbsolute": {
          "x": 1679.9139476903108,
          "y": 2820.9070853180165
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-8tP8C",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_message",
            "id": "Prompt-jWyal",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-8tP8C{dataType:ChatInput,id:ChatInput-8tP8C,name:message,output_types:[Message]}-Prompt-jWyal{fieldName:user_message,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}",
        "source": "ChatInput-8tP8C",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-8tP8C,name:message,output_types:[Message]}",
        "target": "Prompt-jWyal",
        "targetHandle": "{fieldName:user_message,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-CbogB",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-jWyal",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Memory-CbogB{dataType:Memory,id:Memory-CbogB,name:messages_text,output_types:[Message]}-Prompt-jWyal{fieldName:context,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}",
        "source": "Memory-CbogB",
        "sourceHandle": "{dataType:Memory,id:Memory-CbogB,name:messages_text,output_types:[Message]}",
        "target": "Prompt-jWyal",
        "targetHandle": "{fieldName:context,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}"
      },
      {
        "source": "PythonCodeStructuredTool-Lmmfb",
        "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-Lmmfb,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "PythonCodeStructuredTool",
            "id": "PythonCodeStructuredTool-Lmmfb",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-PythonCodeStructuredTool-Lmmfb{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-Lmmfb,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "PythonCodeStructuredTool-xF4JR",
        "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xF4JR,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "PythonCodeStructuredTool",
            "id": "PythonCodeStructuredTool-xF4JR",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-PythonCodeStructuredTool-xF4JR{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xF4JR,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "PythonCodeStructuredTool-xPU8j",
        "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xPU8j,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "PythonCodeStructuredTool",
            "id": "PythonCodeStructuredTool-xPU8j",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-PythonCodeStructuredTool-xPU8j{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xPU8j,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": "",
        "selected": false
      },
      {
        "source": "PythonCodeStructuredTool-slJhZ",
        "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-slJhZ,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "PythonCodeStructuredTool",
            "id": "PythonCodeStructuredTool-slJhZ",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-PythonCodeStructuredTool-slJhZ{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-slJhZ,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "CustomComponent-vuTAo",
        "sourceHandle": "{dataType:SeatMover,id:CustomComponent-vuTAo,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SeatMover",
            "id": "CustomComponent-vuTAo",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-vuTAo{dataType:SeatMover,id:CustomComponent-vuTAo,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "SeatMover-iFnNh",
        "sourceHandle": "{dataType:SeatMover,id:SeatMover-iFnNh,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SeatMover",
            "id": "SeatMover-iFnNh",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-SeatMover-iFnNh{dataType:SeatMover,id:SeatMover-iFnNh,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "SeatMover-7SQOy",
        "sourceHandle": "{dataType:SeatMover,id:SeatMover-7SQOy,name:result_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SeatMover",
            "id": "SeatMover-7SQOy",
            "name": "result_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-SeatMover-7SQOy{dataType:SeatMover,id:SeatMover-7SQOy,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "Prompt-jWyal",
        "sourceHandle": "{dataType:Prompt,id:Prompt-jWyal,name:prompt,output_types:[Message]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:input_value,id:OpenAIToolsAgent-iTroj,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-jWyal",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-jWyal{dataType:Prompt,id:Prompt-jWyal,name:prompt,output_types:[Message]}-OpenAIToolsAgent-iTroj{fieldName:input_value,id:OpenAIToolsAgent-iTroj,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "OpenAIModel-vhY8r",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-vhY8r,name:model_output,output_types:[LanguageModel]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:llm,id:OpenAIToolsAgent-iTroj,inputTypes:[LanguageModel,ToolEnabledLanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "LanguageModel",
              "ToolEnabledLanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-vhY8r",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-vhY8r{dataType:OpenAIModel,id:OpenAIModel-vhY8r,name:model_output,output_types:[LanguageModel]}-OpenAIToolsAgent-iTroj{fieldName:llm,id:OpenAIToolsAgent-iTroj,inputTypes:[LanguageModel,ToolEnabledLanguageModel],type:other}",
        "className": ""
      },
      {
        "source": "OpenAIToolsAgent-iTroj",
        "sourceHandle": "{dataType:OpenAIToolsAgent,id:OpenAIToolsAgent-iTroj,name:response,output_types:[Message]}",
        "target": "JSONCleaner-GCEXx",
        "targetHandle": "{fieldName:json_str,id:JSONCleaner-GCEXx,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "json_str",
            "id": "JSONCleaner-GCEXx",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIToolsAgent",
            "id": "OpenAIToolsAgent-iTroj",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIToolsAgent-iTroj{dataType:OpenAIToolsAgent,id:OpenAIToolsAgent-iTroj,name:response,output_types:[Message]}-JSONCleaner-GCEXx{fieldName:json_str,id:JSONCleaner-GCEXx,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "JSONCleaner-GCEXx",
        "sourceHandle": "{dataType:JSONCleaner,id:JSONCleaner-GCEXx,name:output,output_types:[Message]}",
        "target": "ChatOutput-0Si2J",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-0Si2J,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-0Si2J",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-GCEXx",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-JSONCleaner-GCEXx{dataType:JSONCleaner,id:JSONCleaner-GCEXx,name:output,output_types:[Message]}-ChatOutput-0Si2J{fieldName:input_value,id:ChatOutput-0Si2J,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "CustomComponent-eXRyc",
        "sourceHandle": "{dataType:FaceRecognizer,id:CustomComponent-eXRyc,name:face_rec_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FaceRecognizer",
            "id": "CustomComponent-eXRyc",
            "name": "face_rec_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-eXRyc{dataType:FaceRecognizer,id:CustomComponent-eXRyc,name:face_rec_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "CustomComponent-cs25Q",
        "sourceHandle": "{dataType:FaceRecognizer,id:CustomComponent-cs25Q,name:face_rec_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FaceRecognizer",
            "id": "CustomComponent-cs25Q",
            "name": "face_rec_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-cs25Q{dataType:FaceRecognizer,id:CustomComponent-cs25Q,name:face_rec_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      },
      {
        "source": "FlowTool-ln4do",
        "sourceHandle": "{dataType:FlowTool,id:FlowTool-ln4do,name:api_build_tool,output_types:[Tool]}",
        "target": "OpenAIToolsAgent-iTroj",
        "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "OpenAIToolsAgent-iTroj",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FlowTool",
            "id": "FlowTool-ln4do",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-FlowTool-ln4do{dataType:FlowTool,id:FlowTool-ln4do,name:api_build_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 117.52407238657077,
      "y": 262.35956751433366,
      "zoom": 0.3019520873230959
    }
  },
  "metadata": {
    "Prompt": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "OpenAIToolsAgent": {
      "count": 1
    },
    "CustomComponent": {
      "count": 3
    },
    "PythonCodeStructuredTool": {
      "count": 4
    },
    "SeatMover": {
      "count": 2
    },
    "JSONCleaner": {
      "count": 1
    },
    "FlowTool": {
      "count": 1
    },
    "total": 17
  },
  "original": {
    "id": "467cccd8-d68b-4ed8-af7f-fda9b5e74045",
    "name": "OrpheoMain",
    "description": "This project can be used as a starting point for building a Chat experience with user specific memory. You can set a different Session ID to start a new message history.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "Prompt": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "OpenAIToolsAgent": {
        "count": 1
      },
      "CustomComponent": {
        "count": 3
      },
      "PythonCodeStructuredTool": {
        "count": 4
      },
      "SeatMover": {
        "count": 2
      },
      "JSONCleaner": {
        "count": 1
      },
      "FlowTool": {
        "count": 1
      },
      "total": 17
    },
    "last_tested_version": "1.0.18",
    "private": true,
    "data": {
      "nodes": [
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-jWyal",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{context}\n\nUser: {user_message}\nAI: ",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput",
                  "load_from_db": false
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "user_message": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_message",
                  "display_name": "user_message",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "base_classes": [
                "Message"
              ],
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "user_message"
                ]
              },
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 502,
          "id": "Prompt-jWyal",
          "position": {
            "x": 1880.8227904110583,
            "y": 625.8049209882275
          },
          "positionAbsolute": {
            "x": 1880.8227904110583,
            "y": 625.8049209882275
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "id": "ChatInput-8tP8C",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "can you cover the smell?",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "123",
                  "display_name": "Session ID",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "ChatInput"
          },
          "dragging": false,
          "height": 388,
          "id": "ChatInput-8tP8C",
          "position": {
            "x": 1307.820177917901,
            "y": 846.754125206539
          },
          "positionAbsolute": {
            "x": 1307.820177917901,
            "y": 846.754125206539
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "id": "OpenAIModel-vhY8r",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": true,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput",
                  "load_from_db": false
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 605,
          "id": "OpenAIModel-vhY8r",
          "position": {
            "x": 2468.968379487559,
            "y": 560.0689522326683
          },
          "positionAbsolute": {
            "x": 2468.968379487559,
            "y": 560.0689522326683
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "id": "ChatOutput-0Si2J",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "ChatOutput"
          },
          "height": 302,
          "id": "ChatOutput-0Si2J",
          "position": {
            "x": 4291.105107933034,
            "y": 1517.7631428808918
          },
          "selected": false,
          "type": "genericNode",
          "width": 384,
          "positionAbsolute": {
            "x": 4291.105107933034,
            "y": 1517.7631428808918
          },
          "dragging": false
        },
        {
          "data": {
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Chat Memory",
            "id": "Memory-CbogB",
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n_messages",
                  "value": 100,
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "order": {
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "order",
                  "value": "Ascending",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine and User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Filter by sender type.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Filter by sender name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{sender_name}: {text}",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
              "icon": "message-square-more",
              "base_classes": [
                "BaseChatMemory",
                "Data",
                "Message"
              ],
              "display_name": "Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "messages",
                  "display_name": "Messages (Data)",
                  "method": "retrieve_messages",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "messages_text",
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "BaseChatMemory"
                  ],
                  "selected": "BaseChatMemory",
                  "name": "lc_memory",
                  "display_name": "Memory",
                  "method": "build_lc_memory",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "type": "Memory"
          },
          "dragging": false,
          "height": 382,
          "id": "Memory-CbogB",
          "position": {
            "x": 1301.98330242754,
            "y": 422.33865605652574
          },
          "positionAbsolute": {
            "x": 1301.98330242754,
            "y": 422.33865605652574
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "OpenAIToolsAgent-iTroj",
          "type": "genericNode",
          "position": {
            "x": 3038.841010223995,
            "y": 1525.5865078250145
          },
          "data": {
            "type": "OpenAIToolsAgent",
            "node": {
              "template": {
                "_type": "Component",
                "chat_history": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_history",
                  "value": "",
                  "display_name": "Chat History",
                  "advanced": true,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel",
                    "ToolEnabledLanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool",
                    "BaseTool"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, List\n\nfrom langchain.agents import create_openai_tools_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.inputs import MultilineInput\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\nfrom axiestudio.schema import Data\n\n\nclass OpenAIToolsAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"OpenAI Tools Agent\"\n    description: str = \"Agent that uses tools via openai-tools.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"OpenAIToolsAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\", \"ToolEnabledLanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_openai_tools_agent(self.llm, self.tools, prompt)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "handle_parsing_errors",
                  "value": true,
                  "display_name": "Handle Parse Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "max_iterations": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_iterations",
                  "value": 15,
                  "display_name": "Max Iterations",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "system_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_prompt",
                  "value": "You are a helpful assistant of a BMW Car. Your name is Orpheo. You reply to the requests that the user makes via voice interaction. The request contains information on who's interacting (i.e. driver or passenger) and their name. Your replies always start mentioning who made the request by name (e.g. \"Francesco, ...\", \"Stefan, ...\"). Always use the tools to get more information about the person who you are interacting with.\nYou also have the scent diffuser tool to release scents in the cabin. Use it as appropriate.\nYour current location is Mountain View, CA.\nYour replies have to be short and concise, only include the relevant context.\nYou will also have to decide if further input is needed from the user.\nThe output must be a a json a json like this:\n \"text\": \"your reply here\",\n\"need_user_input\": true|false.\n",
                  "display_name": "System Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System prompt for the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "user_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_prompt",
                  "value": "{input}",
                  "display_name": "Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "This prompt must contain 'input' key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": true,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Agent that uses tools via openai-tools.",
              "icon": "LangChain",
              "base_classes": [
                "AgentExecutor",
                "Message"
              ],
              "display_name": "OpenAI Tools Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "AgentExecutor"
                  ],
                  "selected": "AgentExecutor",
                  "name": "agent",
                  "display_name": "Agent",
                  "method": "build_agent",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "response",
                  "display_name": "Response",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "handle_parsing_errors",
                "verbose",
                "max_iterations",
                "tools",
                "llm",
                "system_prompt",
                "user_prompt",
                "chat_history"
              ],
              "beta": true,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "OpenAIToolsAgent-iTroj"
          },
          "selected": false,
          "width": 384,
          "height": 615,
          "positionAbsolute": {
            "x": 3038.841010223995,
            "y": 1525.5865078250145
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-eXRyc",
          "type": "genericNode",
          "position": {
            "x": 1645.5035647247819,
            "y": 1755.0100903852804
          },
          "data": {
            "type": "FaceRecognizer",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import paho.mqtt.client as mqtt\nimport paho.mqtt.subscribe as subscribe\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass FaceRecognizer(Component):\n    icon = \"cctv\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"face_rec_tool\", method=\"build_tool\"),\n    ]\n\n\n\n\n    def face_rec(self) -> str:\n        msg = subscribe.simple(\"orpheo/ai/face_id/driver\", hostname=\"192.168.50.10\")\n        print(\"returning faces: \" + str(msg.payload))\n        return str(msg.payload)\n\n    def build_tool(self) -> Tool:\n        face_recognizer_tool = StructuredTool.from_function(\n        func=self.face_rec,\n        name=\"FaceRecognizer_driver\",\n        description=\"Returns the name and facial features (age, emotion, gender) of the person in the driver seat\",\n        #args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        return face_recognizer_tool\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "icon": "cctv",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Face Recognizer Driver",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "face_rec_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "CustomComponent-eXRyc"
          },
          "selected": false,
          "width": 384,
          "height": 208,
          "dragging": false,
          "positionAbsolute": {
            "x": 1645.5035647247819,
            "y": 1755.0100903852804
          }
        },
        {
          "id": "CustomComponent-cs25Q",
          "type": "genericNode",
          "position": {
            "x": 1649.676205521081,
            "y": 1497.595592257298
          },
          "data": {
            "type": "FaceRecognizer",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import paho.mqtt.client as mqtt\nimport paho.mqtt.subscribe as subscribe\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass FaceRecognizer(Component):\n    icon = \"cctv\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"face_rec_tool\", method=\"build_tool\"),\n    ]\n\n\n\n\n    def face_rec(self) -> str:\n        msg = subscribe.simple(\"orpheo/ai/face_id/passenger\", hostname=\"192.168.50.10\")\n        print(\"returning faces: \" + str(msg.payload))\n        return str(msg.payload)\n\n    def build_tool(self) -> Tool:\n        face_recognizer_tool = StructuredTool.from_function(\n        func=self.face_rec,\n        name=\"FaceRecognizer_Passenger\",\n        description=\"Returns the name and facial features (age, emotion, gender) of the person in the passenger seat\",\n        #args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        return face_recognizer_tool\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "icon": "cctv",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Face Recognizer Passenger",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "face_rec_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "CustomComponent-cs25Q"
          },
          "selected": false,
          "width": 384,
          "height": 208,
          "dragging": false,
          "positionAbsolute": {
            "x": 1649.676205521081,
            "y": 1497.595592257298
          }
        },
        {
          "id": "CustomComponent-vuTAo",
          "type": "genericNode",
          "position": {
            "x": 1651.328051192944,
            "y": 2010.773760567024
          },
          "data": {
            "type": "SeatMover",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import paho.mqtt.client as mqtt\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass SeatMover(Component):\n    icon = \"rocking-chair\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def on_connect(client, userdata, flags, reason_code, properties):\n        print(f\"Connected with result code {reason_code}\")\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n\n    class SeatMoverInput(BaseModel):\n        seat: str = Field(description=\"Seat: driver or passenger\")\n        direction: int = Field(description=\"Direction of movement: 1 = forward, -1 = backwards\")\n\n\n    def move_seat(self, seat: int, direction :int) -> str:\n        print(\"Moving Seat: \" + seat + \" Direction: \" + str(direction))\n        seat_topic = \"SeatControl/Driver/SLV/\" if seat == \"driver\" else \"SeatControl/Passenger/SLV/\"\n        seat_motion = \"Forward\" if direction == 1 else \"Back\"\n        seat_topic = seat_topic+seat_motion\n        print(\"Moving Seat\")\n        self.mqttc.publish(seat_topic, \"1\")\n        time.sleep(2)\n        self.mqttc.publish(\"SeatControl/Stop\", \"1\")\n        print(\"Stopping Seat\")\n\n        return \"Moving Seat: \" + seat + \" Direction: \" + str(direction)\n\n    def build_tool(self) -> Tool:\n        seat_mover_tool = StructuredTool.from_function(\n        func=self.move_seat,\n        name=\"SeatMover\",\n        description=\"Move a car seat horizontally given the seat (driver or passenger) and the direction of movement (forward or backwards)\",\n        args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        print(seat_mover_tool.args)\n        return seat_mover_tool\n\n\n\n\n\n\n\"\"\" # The callback for when the client receives a CONNACK response from the server.\ndef on_connect(client, userdata, flags, reason_code, properties):\n    print(f\"Connected with result code {reason_code}\")\n\ndef move_seat(seat: str, direction: int):\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n    mqttc.publish(\"axiestudio/test\", \"test\")\n    mqttc.publish(\"axiestudio/test\", \"seat: \" + seat + str(direction))\n    return \"OK\" \"\"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "icon": "rocking-chair",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Seat Mover FORWARD/BACK",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "CustomComponent-vuTAo"
          },
          "selected": true,
          "width": 384,
          "height": 208,
          "dragging": false,
          "positionAbsolute": {
            "x": 1651.328051192944,
            "y": 2010.773760567024
          }
        },
        {
          "id": "PythonCodeStructuredTool-xPU8j",
          "type": "genericNode",
          "position": {
            "x": 1186.8036384107688,
            "y": 1479.324335938785
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "Component",
                "_classes": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_classes",
                  "value": "[]",
                  "display_name": "Classes",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "_functions": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_functions",
                  "value": "{\"get_current_pacific_time\": {\"name\": \"get_current_pacific_time\", \"args\": []}}",
                  "display_name": "Functions",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "global_variables": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "global_variables",
                  "value": "",
                  "display_name": "Global Variables",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Enter the global variables or Create Data Component.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "HandleInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": false,
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tool_code": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "show": true,
                  "name": "tool_code",
                  "value": "from datetime import datetime\nimport pytz\n\ndef get_current_pacific_time():\n    # Define the timezone for US West Coast\n    pacific_timezone = pytz.timezone('America/Los_Angeles')\n    \n    # Get current time in UTC\n    utc_now = datetime.utcnow()\n    \n    # Localize the UTC time to the Pacific Time Zone\n    pacific_time = pytz.utc.localize(utc_now).astimezone(pacific_timezone)\n    \n    return pacific_time",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "tool_description": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_description",
                  "value": "Returns the date and the time in the current timezone",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "tool_function": {
                  "trace_as_metadata": true,
                  "options": [
                    "get_current_pacific_time"
                  ],
                  "combobox": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_function",
                  "value": "get_current_pacific_time",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "tool_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_name",
                  "value": "date_time",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "structuredtool dataclass code to tool",
              "icon": "",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Current Date Time",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "tool_code",
                "tool_name",
                "tool_description",
                "return_direct",
                "tool_function",
                "global_variables",
                "_classes",
                "_functions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PythonCodeStructuredTool-xPU8j"
          },
          "selected": false,
          "width": 384,
          "height": 714,
          "positionAbsolute": {
            "x": 1186.8036384107688,
            "y": 1479.324335938785
          },
          "dragging": false
        },
        {
          "id": "PythonCodeStructuredTool-xF4JR",
          "type": "genericNode",
          "position": {
            "x": 762.0986362867036,
            "y": 1472.3955483240736
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "Component",
                "_classes": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_classes",
                  "value": "[]",
                  "display_name": "Classes",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "_functions": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_functions",
                  "value": "{\"get_weather_info\": {\"name\": \"get_weather_info\", \"args\": [{\"name\": \"location\", \"annotation\": null}]}}",
                  "display_name": "Functions",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "global_variables": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "global_variables",
                  "value": "",
                  "display_name": "Global Variables",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Enter the global variables or Create Data Component.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "HandleInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": false,
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tool_code": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "show": true,
                  "name": "tool_code",
                  "value": "def get_weather_info(location):\n    api_key = 'fb44c460b7104fe5b69180737240409'\n    base_url = \"http://api.weatherapi.com/v1/current.json\"\n    params = {\n        'key': api_key,\n        'q': location\n    }\n    \n    response = requests.get(base_url, params=params)\n    \n    if response.status_code == 200:\n        data = response.json()\n        weather_info = {\n            \"location\": data.get(\"location\", {}).get(\"name\"),\n            \"temperature\": data.get(\"current\", {}).get(\"temp_c\"),\n            \"description\": data.get(\"current\", {}).get(\"condition\", {}).get(\"text\"),\n            \"humidity\": data.get(\"current\", {}).get(\"humidity\"),\n            \"pressure\": data.get(\"current\", {}).get(\"pressure_mb\"),\n            \"wind_speed\": data.get(\"current\", {}).get(\"wind_kph\")\n        }\n        return weather_info\n    else:\n        return f\"Error: Unable to get weather information for {location}. Status code: {response.status_code}\"",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "tool_description": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_description",
                  "value": "This function returns the current weather information (temperature, description, humidity, pressure and wind) of a given location)",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "tool_function": {
                  "trace_as_metadata": true,
                  "options": [
                    "get_weather_info"
                  ],
                  "combobox": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_function",
                  "value": "get_weather_info",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "tool_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_name",
                  "value": "current_weather",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "get_weather_info|location": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "get_weather_info|location",
                  "value": "The name of the location",
                  "display_name": "location: Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description for location",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "structuredtool dataclass code to tool",
              "icon": "",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Current Weather",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "tool_code",
                "tool_name",
                "tool_description",
                "return_direct",
                "tool_function",
                "global_variables",
                "_classes",
                "_functions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PythonCodeStructuredTool-xF4JR"
          },
          "selected": false,
          "width": 384,
          "height": 800,
          "positionAbsolute": {
            "x": 762.0986362867036,
            "y": 1472.3955483240736
          },
          "dragging": false
        },
        {
          "id": "PythonCodeStructuredTool-Lmmfb",
          "type": "genericNode",
          "position": {
            "x": 312.452678312957,
            "y": 1466.7133219374352
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "Component",
                "_classes": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_classes",
                  "value": "[]",
                  "display_name": "Classes",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "_functions": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_functions",
                  "value": "{\"get_weather_forecast\": {\"name\": \"get_weather_forecast\", \"args\": [{\"name\": \"location\", \"annotation\": null}, {\"name\": \"days\", \"annotation\": null}]}}",
                  "display_name": "Functions",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "global_variables": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "global_variables",
                  "value": "",
                  "display_name": "Global Variables",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Enter the global variables or Create Data Component.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "HandleInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": false,
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tool_code": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "show": true,
                  "name": "tool_code",
                  "value": "def get_weather_forecast(location, days=1):\n    api_key = 'fb44c460b7104fe5b69180737240409'\n    base_url = \"http://api.weatherapi.com/v1/forecast.json\"\n    params = {\n        'key': api_key,\n        'q': location,\n        'days': days  # Number of days to forecast (1-10)\n    }\n    \n    response = requests.get(base_url, params=params)\n    \n    if response.status_code == 200:\n        data = response.json()\n        forecast_days = data.get(\"forecast\", {}).get(\"forecastday\", [])\n        \n        forecast_info = []\n        for day in forecast_days:\n            day_info = {\n                \"date\": day.get(\"date\"),\n                \"avg_temp_c\": day.get(\"day\", {}).get(\"avgtemp_c\"),\n                \"condition\": day.get(\"day\", {}).get(\"condition\", {}).get(\"text\"),\n                \"max_temp_c\": day.get(\"day\", {}).get(\"maxtemp_c\"),\n                \"min_temp_c\": day.get(\"day\", {}).get(\"mintemp_c\"),\n                \"max_wind_kph\": day.get(\"day\", {}).get(\"maxwind_kph\"),\n                \"total_precip_mm\": day.get(\"day\", {}).get(\"totalprecip_mm\"),\n                \"uv_index\": day.get(\"day\", {}).get(\"uv\"),\n            }\n            forecast_info.append(day_info)\n            \n        return forecast_info\n    else:\n        return f\"Error: Unable to get the weather forecast for {location}. Status code:{response.status_code}\"",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "tool_description": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_description",
                  "value": "This function returns the weather forecast information of a given location, given the number of days in the future",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "tool_function": {
                  "trace_as_metadata": true,
                  "options": [
                    "get_weather_forecast"
                  ],
                  "combobox": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_function",
                  "value": "get_weather_forecast",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "tool_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_name",
                  "value": "current_weather",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "get_weather_forecast|location": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "get_weather_forecast|location",
                  "value": "The name of the location to be forecasted",
                  "display_name": "location: Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description for location",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "get_weather_forecast|days": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "get_weather_forecast|days",
                  "value": "Days in the future for which you what to know the weather forecast (1-10))",
                  "display_name": "days: Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description for days",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "structuredtool dataclass code to tool",
              "icon": "",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Weather Forecast",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "tool_code",
                "tool_name",
                "tool_description",
                "return_direct",
                "tool_function",
                "global_variables",
                "_classes",
                "_functions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PythonCodeStructuredTool-Lmmfb"
          },
          "selected": false,
          "width": 384,
          "height": 886,
          "positionAbsolute": {
            "x": 312.452678312957,
            "y": 1466.7133219374352
          },
          "dragging": false
        },
        {
          "id": "PythonCodeStructuredTool-slJhZ",
          "type": "genericNode",
          "position": {
            "x": -148.05623953363335,
            "y": 1475.5547388050638
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "Component",
                "_classes": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_classes",
                  "value": "[]",
                  "display_name": "Classes",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "_functions": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "_functions",
                  "value": "{\"get_user_data\": {\"name\": \"get_user_data\", \"args\": [{\"name\": \"user_id\", \"annotation\": null}]}}",
                  "display_name": "Functions",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs.inputs import MultilineInput, MessageTextInput, BoolInput, DropdownInput, HandleInput, FieldTypes\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\n\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured Tool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"Enter the name of the tool.\", required=True),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"tool_code\" and field_name != \"tool_function\":\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:\n            self.status = f\"Failed to extract names: {str(e)}\"\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        _local_namespace = {}  # type: ignore\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), _local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key in kwargs:\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = kwargs[key]\n                return _local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        _globals = globals()\n        _local = {}  # type: ignore\n        _local[self.tool_function] = PythonCodeToolFunc\n        _globals.update(_local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    _globals.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            _globals.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), _globals)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                raise Exception(f\"Failed to find arg: {field_name}\")\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", _globals)\n                schema_annotation = _globals[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg[\"default\"] if \"default\" in func_arg else Undefined, description=field_description\n                ),\n            )\n\n        if \"temp_annotation_type\" in _globals:\n            _globals.pop(\"temp_annotation_type\")\n\n        PythonCodeToolSchema = None\n        if schema_fields:\n            PythonCodeToolSchema = create_model(\"PythonCodeToolSchema\", **schema_fields)  # type: ignore\n\n        tool = StructuredTool.from_function(\n            func=_local[self.tool_function].run,\n            args_schema=PythonCodeToolSchema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n        return tool  # type: ignore\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = self.update_build_config(\n            frontend_node[\"template\"], frontend_node[\"template\"][\"tool_code\"][\"value\"], \"tool_code\"\n        )\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    raise Exception(\"Multiline arguments are not supported\")\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = default.value\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "global_variables": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "global_variables",
                  "value": "",
                  "display_name": "Global Variables",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Enter the global variables or Create Data Component.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "HandleInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": false,
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tool_code": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "show": true,
                  "name": "tool_code",
                  "value": "import os\nimport json\n\ndef get_user_data(user_id):\n    base_dir = \"/home/bmw/src/context_manager_UI/backend/data\"\n    user_folder = os.path.join(base_dir, user_id)\n    \n    # Return an empty string if user folder doesn't exist\n    if not os.path.exists(user_folder):\n        return \"\"\n\n    result = {\n        'person': user_id,\n        'context': []\n    }\n\n    # Loop through all files in the user's folder\n    try:\n        for filename in os.listdir(user_folder):\n            if filename.endswith('.txt'):\n                file_path = os.path.join(user_folder, filename)\n                description = os.path.splitext(filename)[0]  # Remove the \".txt\" extension\n                \n                with open(file_path, 'r') as file:\n                    file_content = file.read()\n\n                # Append the file content and description to the context list\n                result['context'].append({\n                    'description': description,\n                    'content': file_content\n                })\n        \n        return json.dumps(result, indent=4)  # Convert the result to a pretty JSON structure\n\n    except Exception as e:\n        return f\"An error occurred while reading files: {e}\"",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "tool_description": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_description",
                  "value": "This tools provides some context information about a person, given their name. The information could include some general infromation, car setting preferences, music preferences, trips preferences and more (this list is not complete). It returns a object with the context area and the context information.",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "tool_function": {
                  "trace_as_metadata": true,
                  "options": [
                    "get_user_data"
                  ],
                  "combobox": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_function",
                  "value": "get_user_data",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "tool_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_name",
                  "value": "PersonContextRetriever",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "get_user_data|user_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "get_user_data|user_id",
                  "value": "",
                  "display_name": "user_id: Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter the description for user_id",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Tools to retrieve person context data",
              "icon": "",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Context retriever",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "tool_code",
                "tool_name",
                "tool_description",
                "return_direct",
                "tool_function",
                "global_variables",
                "_classes",
                "_functions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PythonCodeStructuredTool-slJhZ"
          },
          "selected": false,
          "width": 384,
          "height": 800,
          "positionAbsolute": {
            "x": -148.05623953363335,
            "y": 1475.5547388050638
          },
          "dragging": false
        },
        {
          "id": "SeatMover-iFnNh",
          "type": "genericNode",
          "position": {
            "x": 1651.780645060777,
            "y": 2239.9132290207253
          },
          "data": {
            "type": "SeatMover",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import paho.mqtt.client as mqtt\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass SeatMover(Component):\n    icon = \"rocking-chair\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def on_connect(client, userdata, flags, reason_code, properties):\n        print(f\"Connected with result code {reason_code}\")\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n\n    class SeatMoverInput(BaseModel):\n        seat: str = Field(description=\"Seat: driver or passenger\")\n        direction: int = Field(description=\"Direction of movement: 1 = up, -1 = down\")\n\n\n    def move_seat(self, seat: int, direction :int) -> str:\n        print(\"Moving Seat: \" + seat + \" Direction: \" + str(direction))\n        seat_topic = \"SeatControl/Driver/SHV/\" if seat == \"driver\" else \"SeatControl/Passenger/SHV/\"\n        seat_motion = \"Up\" if direction == 1 else \"Down\"\n        seat_topic = seat_topic+seat_motion\n        print(\"Moving Seat\")\n        self.mqttc.publish(seat_topic, \"1\")\n        time.sleep(2)\n        self.mqttc.publish(\"SeatControl/Stop\", \"1\")\n        print(\"Stopping Seat\")\n\n        return \"Moving Seat: \" + seat + \" Direction: \" + str(direction)\n\n    def build_tool(self) -> Tool:\n        seat_mover_tool = StructuredTool.from_function(\n        func=self.move_seat,\n        name=\"SeatMoverV\",\n        description=\"Move a car seat given the seat on the vertical axis up or down (driver or passenger) and the direction of movement (up or down). Short people should be moved up, tall people should be moved down\",\n        args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        print(seat_mover_tool.args)\n        return seat_mover_tool\n\n\n\n\n\n\n\"\"\" # The callback for when the client receives a CONNACK response from the server.\ndef on_connect(client, userdata, flags, reason_code, properties):\n    print(f\"Connected with result code {reason_code}\")\n\ndef move_seat(seat: str, direction: int):\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n    mqttc.publish(\"axiestudio/test\", \"test\")\n    mqttc.publish(\"axiestudio/test\", \"seat: \" + seat + str(direction))\n    return \"OK\" \"\"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "icon": "rocking-chair",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Seat Mover UP/DOWN",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "SeatMover-iFnNh"
          },
          "selected": false,
          "width": 384,
          "height": 208,
          "positionAbsolute": {
            "x": 1651.780645060777,
            "y": 2239.9132290207253
          },
          "dragging": false
        },
        {
          "id": "SeatMover-7SQOy",
          "type": "genericNode",
          "position": {
            "x": 1649.2961403892484,
            "y": 2463.518649458326
          },
          "data": {
            "type": "SeatMover",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import paho.mqtt.client as mqtt\n# Import things that are needed generically\nfrom langchain.agents import Tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import Component\n\nfrom axiestudio.template import Output\n\nimport time\n\nclass SeatMover(Component):\n    icon = \"rocking-chair\" # check lucide.dev/icons or pass an emoji\n\n    inputs = [\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def on_connect(client, userdata, flags, reason_code, properties):\n        print(f\"Connected with result code {reason_code}\")\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n\n    class SeatMoverInput(BaseModel):\n        seat: str = Field(description=\"Seat: driver or passenger\")\n        direction: int = Field(description=\"Direction of movement: 1 = forward, -1 = back\")\n\n\n    def move_seat(self, seat: int, direction :int) -> str:\n        print(\"Moving Seat: \" + seat + \" Direction: \" + str(direction))\n        seat_topic = \"SeatControl/Driver/LNV/\" if seat == \"driver\" else \"SeatControl/Passenger/LNV/\"\n        seat_motion = \"Forward\" if direction == 1 else \"Back\"\n        seat_topic = seat_topic+seat_motion\n        print(\"Moving Seat\")\n        self.mqttc.publish(seat_topic, \"1\")\n        time.sleep(2)\n        self.mqttc.publish(\"SeatControl/Stop\", \"1\")\n        print(\"Stopping Seat\")\n\n        return \"Moving Seat: \" + seat + \" Direction: \" + str(direction)\n\n    def build_tool(self) -> Tool:\n        seat_mover_tool = StructuredTool.from_function(\n        func=self.move_seat,\n        name=\"SeatMoverR\",\n        description=\"Recline a car seat backrest given the seat (driver or passenger) and the direction of movement (forward or backwards)\",\n        args_schema=self.SeatMoverInput,\n        return_direct=False,\n        # coroutine= ... <- you can specify an async method if desired as well\n        )\n        print(seat_mover_tool.args)\n        return seat_mover_tool\n\n\n\n\n\n\n\"\"\" # The callback for when the client receives a CONNACK response from the server.\ndef on_connect(client, userdata, flags, reason_code, properties):\n    print(f\"Connected with result code {reason_code}\")\n\ndef move_seat(seat: str, direction: int):\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_connect = on_connect\n    mqttc.connect(\"192.168.50.10\", 1883, 60)\n    mqttc.publish(\"axiestudio/test\", \"test\")\n    mqttc.publish(\"axiestudio/test\", \"seat: \" + seat + str(direction))\n    return \"OK\" \"\"\"",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "icon": "rocking-chair",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Seat Mover Recline",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "result_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "SeatMover-7SQOy"
          },
          "selected": false,
          "width": 384,
          "height": 208,
          "positionAbsolute": {
            "x": 1649.2961403892484,
            "y": 2463.518649458326
          },
          "dragging": false
        },
        {
          "id": "JSONCleaner-GCEXx",
          "type": "genericNode",
          "position": {
            "x": 3572.5094468047073,
            "y": 1807.9865935758532
          },
          "data": {
            "type": "JSONCleaner",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import json\nimport re\nimport unicodedata\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, BoolInput\nfrom axiestudio.template import Output\nfrom axiestudio.schema.message import Message\n\n\nclass JSONCleaner(Component):\n    display_name = \"JSON Cleaner\"\n    description = \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.\"\n    icon = \"custom_components\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import the json_repair package.\" \"Please install it with `pip install json_repair`.\"\n            )\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        try:\n            start = json_str.find(\"{\")\n            end = json_str.rfind(\"}\")\n            if start == -1 or end == -1:\n                raise ValueError(\"Invalid JSON string: Missing '{' or '}'\")\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            raise ValueError(f\"Error cleaning JSON string: {str(e)}\")\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", s)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n            return s\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON string: {str(e)}\")\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "json_str": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "json_str",
                  "value": "",
                  "display_name": "JSON String",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The JSON string to be cleaned.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "normalize_unicode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "normalize_unicode",
                  "value": false,
                  "display_name": "Normalize Unicode",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Normalize Unicode characters in the JSON string.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "remove_control_chars": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "remove_control_chars",
                  "value": false,
                  "display_name": "Remove Control Characters",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Remove control characters from the JSON string.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "validate_json": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "validate_json",
                  "value": true,
                  "display_name": "Validate JSON",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Validate the JSON string to ensure it is well-formed.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "JSON Cleaner",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Cleaned JSON String",
                  "method": "clean_json",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "json_str",
                "remove_control_chars",
                "normalize_unicode",
                "validate_json"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "JSONCleaner-GCEXx"
          },
          "selected": false,
          "width": 384,
          "height": 574,
          "positionAbsolute": {
            "x": 3572.5094468047073,
            "y": 1807.9865935758532
          },
          "dragging": false
        },
        {
          "id": "FlowTool-ln4do",
          "type": "genericNode",
          "position": {
            "x": 1679.9139476903108,
            "y": 2820.9070853180165
          },
          "data": {
            "type": "FlowTool",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any, List, Optional\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.base.tools.flow_tool import FlowTool\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.graph.graph.base import Graph\nfrom axiestudio.helpers.flow import get_flow_inputs\nfrom axiestudio.io import BoolInput, DropdownInput, Output, StrInput\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass FlowToolComponent(LCToolComponent):\n    display_name = \"Flow as Tool\"\n    description = \"Construct a Tool from a function that runs the loaded Flow.\"\n    field_order = [\"flow_name\", \"name\", \"description\", \"return_direct\"]\n    trace_type = \"tool\"\n    name = \"FlowTool\"\n    beta = True\n\n    def get_flow_names(self) -> List[str]:\n        flow_datas = self.list_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    def get_flow(self, flow_name: str) -> Optional[Data]:\n        \"\"\"\n        Retrieves a flow by its name.\n\n        Args:\n            flow_name (str): The name of the flow to retrieve.\n\n        Returns:\n            Optional[Text]: The flow record if found, None otherwise.\n        \"\"\"\n        flow_datas = self.list_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\", display_name=\"Flow Name\", info=\"The name of the flow to run.\", refresh_button=True\n        ),\n        StrInput(\n            name=\"name\",\n            display_name=\"Name\",\n            info=\"The name of the tool.\",\n        ),\n        StrInput(\n            name=\"description\",\n            display_name=\"Description\",\n            info=\"The description of the tool.\",\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Direct\",\n            info=\"Return the result directly from the Tool.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"api_build_tool\", display_name=\"Tool\", method=\"build_tool\"),\n    ]\n\n    def build_tool(self) -> Tool:\n        FlowTool.update_forward_refs()\n        if \"flow_name\" not in self._attributes or not self._attributes[\"flow_name\"]:\n            raise ValueError(\"Flow name is required\")\n        flow_name = self._attributes[\"flow_name\"]\n        flow_data = self.get_flow(flow_name)\n        if not flow_data:\n            raise ValueError(\"Flow not found.\")\n        graph = Graph.from_payload(flow_data.data[\"data\"])\n        inputs = get_flow_inputs(graph)\n        tool = FlowTool(\n            name=self.name,\n            description=self.description,\n            graph=graph,\n            return_direct=self.return_direct,\n            inputs=inputs,\n            flow_id=str(flow_data.id),\n            user_id=str(self.user_id),\n        )\n        description_repr = repr(tool.description).strip(\"'\")\n        args_str = \"\\n\".join([f\"- {arg_name}: {arg_data['description']}\" for arg_name, arg_data in tool.args.items()])\n        self.status = f\"{description_repr}\\nArguments:\\n{args_str}\"\n        return tool  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "description": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "description",
                  "value": "This tool releases scents inside the car. It has knowledge of the scents it can release and and their notes. Base on  the user input it can release the right scent for that specific situation. Always call this tool when a scent release is needed.",
                  "display_name": "Description",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The description of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "flow_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "Memory Chatbot",
                    "Basic Prompting (Hello, World) (2)",
                    "Memory Chatbot (1)",
                    "OrpheoMain",
                    "Orpheo Continous",
                    "Basic Prompting (Hello, World)",
                    "Memory Chatbot (2)",
                    "Basic Prompting (Hello, World) (1)",
                    "Untitled document",
                    "Interviewer",
                    "Untitled document (2)",
                    "ScentDiffuser-ATMOS",
                    "Simple Agent"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "flow_name",
                  "value": "ScentDiffuser-ATMOS",
                  "display_name": "Flow Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The name of the flow to run.",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "name",
                  "value": "scent_diffuser",
                  "display_name": "Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The name of the tool.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "return_direct": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "return_direct",
                  "value": false,
                  "display_name": "Return Direct",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Return the result directly from the Tool.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Construct a Tool from a function that runs the loaded Flow.",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Flow as Tool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "flow_name",
                "name",
                "description",
                "return_direct"
              ],
              "beta": true,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "FlowTool-ln4do"
          },
          "selected": false,
          "width": 384,
          "height": 502,
          "positionAbsolute": {
            "x": 1679.9139476903108,
            "y": 2820.9070853180165
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-8tP8C",
              "name": "message",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "user_message",
              "id": "Prompt-jWyal",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-ChatInput-8tP8C{dataType:ChatInput,id:ChatInput-8tP8C,name:message,output_types:[Message]}-Prompt-jWyal{fieldName:user_message,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}",
          "source": "ChatInput-8tP8C",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-8tP8C,name:message,output_types:[Message]}",
          "target": "Prompt-jWyal",
          "targetHandle": "{fieldName:user_message,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-CbogB",
              "name": "messages_text",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-jWyal",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Memory-CbogB{dataType:Memory,id:Memory-CbogB,name:messages_text,output_types:[Message]}-Prompt-jWyal{fieldName:context,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}",
          "source": "Memory-CbogB",
          "sourceHandle": "{dataType:Memory,id:Memory-CbogB,name:messages_text,output_types:[Message]}",
          "target": "Prompt-jWyal",
          "targetHandle": "{fieldName:context,id:Prompt-jWyal,inputTypes:[Message,Text],type:str}"
        },
        {
          "source": "PythonCodeStructuredTool-Lmmfb",
          "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-Lmmfb,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "PythonCodeStructuredTool",
              "id": "PythonCodeStructuredTool-Lmmfb",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-PythonCodeStructuredTool-Lmmfb{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-Lmmfb,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "PythonCodeStructuredTool-xF4JR",
          "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xF4JR,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "PythonCodeStructuredTool",
              "id": "PythonCodeStructuredTool-xF4JR",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-PythonCodeStructuredTool-xF4JR{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xF4JR,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "PythonCodeStructuredTool-xPU8j",
          "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xPU8j,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "PythonCodeStructuredTool",
              "id": "PythonCodeStructuredTool-xPU8j",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-PythonCodeStructuredTool-xPU8j{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-xPU8j,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": "",
          "selected": false
        },
        {
          "source": "PythonCodeStructuredTool-slJhZ",
          "sourceHandle": "{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-slJhZ,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "PythonCodeStructuredTool",
              "id": "PythonCodeStructuredTool-slJhZ",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-PythonCodeStructuredTool-slJhZ{dataType:PythonCodeStructuredTool,id:PythonCodeStructuredTool-slJhZ,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "CustomComponent-vuTAo",
          "sourceHandle": "{dataType:SeatMover,id:CustomComponent-vuTAo,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "SeatMover",
              "id": "CustomComponent-vuTAo",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-vuTAo{dataType:SeatMover,id:CustomComponent-vuTAo,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "SeatMover-iFnNh",
          "sourceHandle": "{dataType:SeatMover,id:SeatMover-iFnNh,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "SeatMover",
              "id": "SeatMover-iFnNh",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-SeatMover-iFnNh{dataType:SeatMover,id:SeatMover-iFnNh,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "SeatMover-7SQOy",
          "sourceHandle": "{dataType:SeatMover,id:SeatMover-7SQOy,name:result_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "SeatMover",
              "id": "SeatMover-7SQOy",
              "name": "result_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-SeatMover-7SQOy{dataType:SeatMover,id:SeatMover-7SQOy,name:result_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "Prompt-jWyal",
          "sourceHandle": "{dataType:Prompt,id:Prompt-jWyal,name:prompt,output_types:[Message]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:input_value,id:OpenAIToolsAgent-iTroj,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-jWyal",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-jWyal{dataType:Prompt,id:Prompt-jWyal,name:prompt,output_types:[Message]}-OpenAIToolsAgent-iTroj{fieldName:input_value,id:OpenAIToolsAgent-iTroj,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "OpenAIModel-vhY8r",
          "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-vhY8r,name:model_output,output_types:[LanguageModel]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:llm,id:OpenAIToolsAgent-iTroj,inputTypes:[LanguageModel,ToolEnabledLanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "LanguageModel",
                "ToolEnabledLanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-vhY8r",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-vhY8r{dataType:OpenAIModel,id:OpenAIModel-vhY8r,name:model_output,output_types:[LanguageModel]}-OpenAIToolsAgent-iTroj{fieldName:llm,id:OpenAIToolsAgent-iTroj,inputTypes:[LanguageModel,ToolEnabledLanguageModel],type:other}",
          "className": ""
        },
        {
          "source": "OpenAIToolsAgent-iTroj",
          "sourceHandle": "{dataType:OpenAIToolsAgent,id:OpenAIToolsAgent-iTroj,name:response,output_types:[Message]}",
          "target": "JSONCleaner-GCEXx",
          "targetHandle": "{fieldName:json_str,id:JSONCleaner-GCEXx,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "json_str",
              "id": "JSONCleaner-GCEXx",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIToolsAgent",
              "id": "OpenAIToolsAgent-iTroj",
              "name": "response",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIToolsAgent-iTroj{dataType:OpenAIToolsAgent,id:OpenAIToolsAgent-iTroj,name:response,output_types:[Message]}-JSONCleaner-GCEXx{fieldName:json_str,id:JSONCleaner-GCEXx,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "JSONCleaner-GCEXx",
          "sourceHandle": "{dataType:JSONCleaner,id:JSONCleaner-GCEXx,name:output,output_types:[Message]}",
          "target": "ChatOutput-0Si2J",
          "targetHandle": "{fieldName:input_value,id:ChatOutput-0Si2J,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-0Si2J",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "JSONCleaner",
              "id": "JSONCleaner-GCEXx",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-JSONCleaner-GCEXx{dataType:JSONCleaner,id:JSONCleaner-GCEXx,name:output,output_types:[Message]}-ChatOutput-0Si2J{fieldName:input_value,id:ChatOutput-0Si2J,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "CustomComponent-eXRyc",
          "sourceHandle": "{dataType:FaceRecognizer,id:CustomComponent-eXRyc,name:face_rec_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "FaceRecognizer",
              "id": "CustomComponent-eXRyc",
              "name": "face_rec_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-eXRyc{dataType:FaceRecognizer,id:CustomComponent-eXRyc,name:face_rec_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "CustomComponent-cs25Q",
          "sourceHandle": "{dataType:FaceRecognizer,id:CustomComponent-cs25Q,name:face_rec_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "FaceRecognizer",
              "id": "CustomComponent-cs25Q",
              "name": "face_rec_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-cs25Q{dataType:FaceRecognizer,id:CustomComponent-cs25Q,name:face_rec_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        },
        {
          "source": "FlowTool-ln4do",
          "sourceHandle": "{dataType:FlowTool,id:FlowTool-ln4do,name:api_build_tool,output_types:[Tool]}",
          "target": "OpenAIToolsAgent-iTroj",
          "targetHandle": "{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "OpenAIToolsAgent-iTroj",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "FlowTool",
              "id": "FlowTool-ln4do",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-FlowTool-ln4do{dataType:FlowTool,id:FlowTool-ln4do,name:api_build_tool,output_types:[Tool]}-OpenAIToolsAgent-iTroj{fieldName:tools,id:OpenAIToolsAgent-iTroj,inputTypes:[Tool,BaseTool],type:other}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 117.52407238657077,
        "y": 262.35956751433366,
        "zoom": 0.3019520873230959
      }
    },
    "date_created": "2024-10-11T18:08:00.365Z",
    "date_updated": "2024-10-11T18:08:00.479Z",
    "status": "Public",
    "sort": null,
    "user_updated": "10d3653a-d667-4b0e-b3bd-a3f507bf0f47",
    "user_created": {
      "username": "fmanto",
      "first_name": "Francesco",
      "last_name": "Mantovani",
      "id": "10d3653a-d667-4b0e-b3bd-a3f507bf0f47"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:57.191Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 170,
    "converter_version": "1.0.0"
  }
}