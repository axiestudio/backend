{
  "id": "e5cb7021-cdd7-449c-ba20-b0ed31e4bbbf",
  "name": "Untitled document",
  "description": "Generate, Innovate, Communicate. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "maskedrealness99",
    "first_name": "Ben",
    "last_name": "Boan",
    "id": "63f0d574-95bc-455c-880f-af8f1947b55a",
    "full_name": "Ben Boan"
  },
  "store_url": "https://www.langflow.store/store/component/e5cb7021-cdd7-449c-ba20-b0ed31e4bbbf",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-11-22T08:55:04.027Z",
    "updated": "2024-11-22T08:55:04.113Z",
    "downloaded": "2025-08-19T17:50:07.510Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.1.0",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatInput-Owfce",
        "type": "genericNode",
        "position": {
          "x": 160.9664243430177,
          "y": 194.60401521438604
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Write a catchy pop song about having sex with an alien",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "ChatInput",
          "id": "ChatInput-Owfce"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 160.9664243430177,
          "y": 194.60401521438604
        },
        "dragging": false
      },
      {
        "id": "LMStudioModel-b1Yz5",
        "type": "genericNode",
        "position": {
          "x": 569.3778559847806,
          "y": 205.98769776932238
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "LM Studio API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The LM Studio API Key to use for LM Studio.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "http://localhost:1234/v1",
                "display_name": "Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom axiestudio.inputs import DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom axiestudio.inputs.inputs import HandleInput\n\n\nclass LMStudioModelComponent(LCModelComponent):\n    display_name = \"LM Studio\"\n    description = \"Generate text using LM Studio Local LLMs.\"\n    icon = \"LMStudio\"\n    name = \"LMStudioModel\"\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"model_name\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:1234/v1\"\n            build_config[\"model_name\"][\"options\"] = self.get_model(base_url_value)\n\n        return build_config\n\n    def get_model(self, base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/v1/models\")\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"id\"] for model in data.get(\"data\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure the LM Studio server is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            advanced=False,\n            info=\"Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.\",\n            value=\"http://localhost:1234/v1\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LM Studio API Key\",\n            info=\"The LM Studio API Key to use for LM Studio.\",\n            advanced=True,\n            value=\"LMSTUDIO_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        lmstudio_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        base_url = self.base_url or \"http://localhost:1234/v1\"\n        seed = self.seed\n\n        api_key = SecretStr(lmstudio_api_key) if lmstudio_api_key else None\n\n        return ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=base_url,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an LM Studio exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "tiger-gemma-9b-v3"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "tiger-gemma-9b-v3",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": true,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "You are an expert songwriter. Your job is to create a rough draft of the song idea proposed by the user.",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using LM Studio Local LLMs.",
            "icon": "LMStudio",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "LM Studio",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "hidden": null,
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "model_name",
              "base_url",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "LMStudioModel",
          "id": "LMStudioModel-b1Yz5"
        },
        "selected": false,
        "width": 320,
        "height": 672,
        "positionAbsolute": {
          "x": 569.3778559847806,
          "y": 205.98769776932238
        },
        "dragging": false
      },
      {
        "id": "UpdateData-hIznT",
        "type": "genericNode",
        "position": {
          "x": 1344.2451294945852,
          "y": 357.7778506458395
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "old_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "old_data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The record to update.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom axiestudio.inputs.inputs import (\n    BoolInput,\n    DataInput,\n    DictInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass UpdateDataComponent(Component):\n    display_name: str = \"Update Data\"\n    description: str = \"Dynamically update or append data with the specified fields.\"\n    name: str = \"UpdateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n\n    inputs = [\n        DataInput(\n            name=\"old_data\",\n            display_name=\"Data\",\n            info=\"The record to update.\",\n            is_list=True,  # Changed to True to handle list of Data objects\n        ),\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=0,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update the build configuration when the number of fields changes.\n\n        Args:\n            build_config (dotdict): The current build configuration.\n            field_value (Any): The new value for the field.\n            field_name (Optional[str]): The name of the field being updated.\n        \"\"\"\n        if field_name == \"number_of_fields\":\n            default_keys = {\n                \"code\",\n                \"_type\",\n                \"number_of_fields\",\n                \"text_key\",\n                \"old_data\",\n                \"text_key_validator\",\n            }\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = f\"Number of fields cannot exceed {self.MAX_FIELDS}. \" \"Try using a Component to combine two Data.\"\n                raise ValueError(msg)\n\n            existing_fields = {}\n            # Back up the existing template fields\n            for key in list(build_config.keys()):\n                if key not in default_keys:\n                    existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Text\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data | list[Data]:\n        \"\"\"Build the updated data by combining the old data with new fields.\"\"\"\n        new_data = self.get_data()\n        if isinstance(self.old_data, list):\n            for data_item in self.old_data:\n                if not isinstance(data_item, Data):\n                    continue  # Skip invalid items\n                data_item.data.update(new_data)\n                if self.text_key:\n                    data_item.text_key = self.text_key\n                self.validate_text_key(data_item)\n            self.status = self.old_data\n            return self.old_data  # Returns List[Data]\n        if isinstance(self.old_data, Data):\n            self.old_data.data.update(new_data)\n            if self.text_key:\n                self.old_data.text_key = self.text_key\n            self.status = self.old_data\n            self.validate_text_key(self.old_data)\n            return self.old_data  # Returns Data\n        msg = \"old_data is not a Data object or list of Data objects.\"\n        raise ValueError(msg)\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        default_keys = {\n            \"code\",\n            \"_type\",\n            \"number_of_fields\",\n            \"text_key\",\n            \"old_data\",\n            \"text_key_validator\",\n        }\n        for attr_name, attr_value in self._attributes.items():\n            if attr_name in default_keys:\n                continue  # Skip default attributes\n            if isinstance(attr_value, dict):\n                for key, value in attr_value.items():\n                    data[key] = value.get_text() if isinstance(value, Data) else value\n            elif isinstance(attr_value, Data):\n                data[attr_name] = attr_value.get_text()\n            else:\n                data[attr_name] = attr_value\n        return data\n\n    def validate_text_key(self, data: Data) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = data.data.keys()\n        if self.text_key and self.text_key not in data_keys:\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: \" f\"{', '.join(data_keys)}\"\n            raise ValueError(msg)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_fields": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "int",
                  "min": 1,
                  "max": 15,
                  "step": 1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_fields",
                "value": 0,
                "display_name": "Number of Fields",
                "advanced": false,
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "text_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key",
                "value": "",
                "display_name": "Text Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text_key_validator": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key_validator",
                "value": false,
                "display_name": "Text Key Validator",
                "advanced": true,
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Dynamically update or append data with the specified fields.",
            "base_classes": [
              "Data"
            ],
            "display_name": "Update Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "hidden": null,
                "display_name": "Data",
                "method": "build_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "old_data",
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "UpdateData",
          "id": "UpdateData-hIznT"
        },
        "selected": false,
        "width": 320,
        "height": 302,
        "positionAbsolute": {
          "x": 1344.2451294945852,
          "y": 357.7778506458395
        },
        "dragging": false
      },
      {
        "id": "StructuredOutputComponent-PCR1I",
        "type": "genericNode",
        "position": {
          "x": 947.3092336067327,
          "y": 205.59403869109047
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "The language model to use to generate the structured output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import cast\n\nfrom pydantic import BaseModel, Field, create_model\n\nfrom axiestudio.base.models.chat_result import get_chat_result\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing.constants import LanguageModel\nfrom axiestudio.helpers.base_model import build_model_from_schema\nfrom axiestudio.io import BoolInput, HandleInput, MessageTextInput, Output, StrInput, TableInput\nfrom axiestudio.schema.data import Data\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        MessageTextInput(name=\"input_value\", display_name=\"Input message\"),\n        StrInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"description\": (\n                        \"Indicate the data type of the output field \" \"(e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"default\": \"text\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                },\n            ],\n        ),\n        BoolInput(\n            name=\"multiple\",\n            display_name=\"Generate Multiple\",\n            info=\"Set to True if the model should generate a list of outputs instead of a single output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"structured_output\", display_name=\"Structured Output\", method=\"build_structured_output\"),\n    ]\n\n    def build_structured_output(self) -> Data:\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        _output_model = build_model_from_schema(self.output_schema)\n        if self.multiple:\n            output_model = create_model(\n                self.schema_name,\n                objects=(list[_output_model], Field(description=f\"A list of {self.schema_name}.\")),  # type: ignore[valid-type]\n            )\n        else:\n            output_model = _output_model\n        try:\n            llm_with_structured_output = cast(LanguageModel, self.llm).with_structured_output(schema=output_model)  # type: ignore[valid-type, attr-defined]\n\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        output = get_chat_result(runnable=llm_with_structured_output, input_value=self.input_value, config=config_dict)\n        if isinstance(output, BaseModel):\n            output_dict = output.model_dump()\n        else:\n            msg = f\"Output should be a Pydantic BaseModel, got {type(output)} ({output})\"\n            raise TypeError(msg)\n        return Data(data=output_dict)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "multiple": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "multiple",
                "value": false,
                "display_name": "Generate Multiple",
                "advanced": false,
                "dynamic": false,
                "info": "Set to True if the model should generate a list of outputs instead of a single output.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "output_schema": {
                "is_list": true,
                "table_schema": {
                  "columns": [
                    {
                      "name": "name",
                      "display_name": "Name",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Specify the name of the output field.",
                      "formatter": "text"
                    },
                    {
                      "name": "description",
                      "display_name": "Description",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Describe the purpose of the output field.",
                      "formatter": "text"
                    },
                    {
                      "name": "type",
                      "display_name": "Type",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                      "default": "text",
                      "formatter": "text"
                    },
                    {
                      "name": "multiple",
                      "display_name": "Multiple",
                      "sortable": true,
                      "filterable": true,
                      "type": "boolean",
                      "description": "Set to True if this output field should be a list of the specified type.",
                      "default": "False",
                      "formatter": "text"
                    }
                  ]
                },
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": "",
                "display_name": "Output Schema",
                "advanced": false,
                "dynamic": false,
                "info": "Define the structure and data types for the model's output.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "schema_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "schema_name",
                "value": "",
                "display_name": "Schema Name",
                "advanced": false,
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
            "icon": "braces",
            "base_classes": [
              "Data"
            ],
            "display_name": "Structured Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "structured_output",
                "display_name": "Structured Output",
                "method": "build_structured_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "llm",
              "input_value",
              "schema_name",
              "output_schema",
              "multiple"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "StructuredOutputComponent",
          "id": "StructuredOutputComponent-PCR1I"
        },
        "selected": false,
        "width": 320,
        "height": 542,
        "positionAbsolute": {
          "x": 947.3092336067327,
          "y": 205.59403869109047
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatInput-Owfce",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-Owfce,name:message,output_types:[Message]}",
        "target": "LMStudioModel-b1Yz5",
        "targetHandle": "{fieldName:input_value,id:LMStudioModel-b1Yz5,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LMStudioModel-b1Yz5",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-Owfce",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-Owfce{dataType:ChatInput,id:ChatInput-Owfce,name:message,output_types:[Message]}-LMStudioModel-b1Yz5{fieldName:input_value,id:LMStudioModel-b1Yz5,inputTypes:[Message],type:str}",
        "className": ""
      },
      {
        "source": "LMStudioModel-b1Yz5",
        "sourceHandle": "{dataType:LMStudioModel,id:LMStudioModel-b1Yz5,name:model_output,output_types:[LanguageModel]}",
        "target": "StructuredOutputComponent-PCR1I",
        "targetHandle": "{fieldName:llm,id:StructuredOutputComponent-PCR1I,inputTypes:[LanguageModel],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "StructuredOutputComponent-PCR1I",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "LMStudioModel",
            "id": "LMStudioModel-b1Yz5",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-LMStudioModel-b1Yz5{dataType:LMStudioModel,id:LMStudioModel-b1Yz5,name:model_output,output_types:[LanguageModel]}-StructuredOutputComponent-PCR1I{fieldName:llm,id:StructuredOutputComponent-PCR1I,inputTypes:[LanguageModel],type:other}"
      },
      {
        "source": "StructuredOutputComponent-PCR1I",
        "sourceHandle": "{dataType:StructuredOutputComponent,id:StructuredOutputComponent-PCR1I,name:structured_output,output_types:[Data]}",
        "target": "UpdateData-hIznT",
        "targetHandle": "{fieldName:old_data,id:UpdateData-hIznT,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "old_data",
            "id": "UpdateData-hIznT",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "StructuredOutputComponent",
            "id": "StructuredOutputComponent-PCR1I",
            "name": "structured_output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-StructuredOutputComponent-PCR1I{dataType:StructuredOutputComponent,id:StructuredOutputComponent-PCR1I,name:structured_output,output_types:[Data]}-UpdateData-hIznT{fieldName:old_data,id:UpdateData-hIznT,inputTypes:[Data],type:other}"
      }
    ],
    "viewport": {
      "x": -506.36092542403844,
      "y": -139.0944927404591,
      "zoom": 0.8879759017203487
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "LMStudioModel": {
      "count": 1
    },
    "UpdateData": {
      "count": 1
    },
    "StructuredOutputComponent": {
      "count": 1
    },
    "total": 4
  },
  "original": {
    "id": "e5cb7021-cdd7-449c-ba20-b0ed31e4bbbf",
    "name": "Untitled document",
    "description": "Generate, Innovate, Communicate.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "LMStudioModel": {
        "count": 1
      },
      "UpdateData": {
        "count": 1
      },
      "StructuredOutputComponent": {
        "count": 1
      },
      "total": 4
    },
    "last_tested_version": "1.1.0",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "ChatInput-Owfce",
          "type": "genericNode",
          "position": {
            "x": 160.9664243430177,
            "y": 194.60401521438604
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "background_color": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "background_color",
                  "value": "",
                  "display_name": "Background Color",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The background color of the icon.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "chat_icon": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_icon",
                  "value": "",
                  "display_name": "Icon",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The icon of the message.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "Write a catchy pop song about having sex with an alien",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "text_color": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_color",
                  "value": "",
                  "display_name": "Text Color",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The text color of the name",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "MessagesSquare",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files",
                "background_color",
                "chat_icon",
                "text_color"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false
            },
            "type": "ChatInput",
            "id": "ChatInput-Owfce"
          },
          "selected": false,
          "width": 320,
          "height": 233,
          "positionAbsolute": {
            "x": 160.9664243430177,
            "y": 194.60401521438604
          },
          "dragging": false
        },
        {
          "id": "LMStudioModel-b1Yz5",
          "type": "genericNode",
          "position": {
            "x": 569.3778559847806,
            "y": 205.98769776932238
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "output_parser": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_parser",
                  "value": "",
                  "display_name": "Output Parser",
                  "advanced": true,
                  "input_types": [
                    "OutputParser"
                  ],
                  "dynamic": false,
                  "info": "The parser to use to parse the output of the model",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "LM Studio API Key",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The LM Studio API Key to use for LM Studio.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "base_url": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "base_url",
                  "value": "http://localhost:1234/v1",
                  "display_name": "Base URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom axiestudio.inputs import DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom axiestudio.inputs.inputs import HandleInput\n\n\nclass LMStudioModelComponent(LCModelComponent):\n    display_name = \"LM Studio\"\n    description = \"Generate text using LM Studio Local LLMs.\"\n    icon = \"LMStudio\"\n    name = \"LMStudioModel\"\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"model_name\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:1234/v1\"\n            build_config[\"model_name\"][\"options\"] = self.get_model(base_url_value)\n\n        return build_config\n\n    def get_model(self, base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/v1/models\")\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"id\"] for model in data.get(\"data\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure the LM Studio server is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            advanced=False,\n            info=\"Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.\",\n            value=\"http://localhost:1234/v1\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LM Studio API Key\",\n            info=\"The LM Studio API Key to use for LM Studio.\",\n            advanced=True,\n            value=\"LMSTUDIO_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        lmstudio_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        base_url = self.base_url or \"http://localhost:1234/v1\"\n        seed = self.seed\n\n        api_key = SecretStr(lmstudio_api_key) if lmstudio_api_key else None\n\n        return ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=base_url,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an LM Studio exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "tiger-gemma-9b-v3"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "tiger-gemma-9b-v3",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": true,
                  "display_name": "Stream",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "You are an expert songwriter. Your job is to create a rough draft of the song idea proposed by the user.",
                  "display_name": "System Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using LM Studio Local LLMs.",
              "icon": "LMStudio",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "LM Studio",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "hidden": null,
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": []
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "hidden": null,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": []
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "model_name",
                "base_url",
                "api_key",
                "temperature",
                "seed",
                "output_parser"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false
            },
            "type": "LMStudioModel",
            "id": "LMStudioModel-b1Yz5"
          },
          "selected": false,
          "width": 320,
          "height": 672,
          "positionAbsolute": {
            "x": 569.3778559847806,
            "y": 205.98769776932238
          },
          "dragging": false
        },
        {
          "id": "UpdateData-hIznT",
          "type": "genericNode",
          "position": {
            "x": 1344.2451294945852,
            "y": 357.7778506458395
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "old_data": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "old_data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The record to update.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom axiestudio.inputs.inputs import (\n    BoolInput,\n    DataInput,\n    DictInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom axiestudio.io import Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass UpdateDataComponent(Component):\n    display_name: str = \"Update Data\"\n    description: str = \"Dynamically update or append data with the specified fields.\"\n    name: str = \"UpdateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n\n    inputs = [\n        DataInput(\n            name=\"old_data\",\n            display_name=\"Data\",\n            info=\"The record to update.\",\n            is_list=True,  # Changed to True to handle list of Data objects\n        ),\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=0,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update the build configuration when the number of fields changes.\n\n        Args:\n            build_config (dotdict): The current build configuration.\n            field_value (Any): The new value for the field.\n            field_name (Optional[str]): The name of the field being updated.\n        \"\"\"\n        if field_name == \"number_of_fields\":\n            default_keys = {\n                \"code\",\n                \"_type\",\n                \"number_of_fields\",\n                \"text_key\",\n                \"old_data\",\n                \"text_key_validator\",\n            }\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = f\"Number of fields cannot exceed {self.MAX_FIELDS}. \" \"Try using a Component to combine two Data.\"\n                raise ValueError(msg)\n\n            existing_fields = {}\n            # Back up the existing template fields\n            for key in list(build_config.keys()):\n                if key not in default_keys:\n                    existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Text\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data | list[Data]:\n        \"\"\"Build the updated data by combining the old data with new fields.\"\"\"\n        new_data = self.get_data()\n        if isinstance(self.old_data, list):\n            for data_item in self.old_data:\n                if not isinstance(data_item, Data):\n                    continue  # Skip invalid items\n                data_item.data.update(new_data)\n                if self.text_key:\n                    data_item.text_key = self.text_key\n                self.validate_text_key(data_item)\n            self.status = self.old_data\n            return self.old_data  # Returns List[Data]\n        if isinstance(self.old_data, Data):\n            self.old_data.data.update(new_data)\n            if self.text_key:\n                self.old_data.text_key = self.text_key\n            self.status = self.old_data\n            self.validate_text_key(self.old_data)\n            return self.old_data  # Returns Data\n        msg = \"old_data is not a Data object or list of Data objects.\"\n        raise ValueError(msg)\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        default_keys = {\n            \"code\",\n            \"_type\",\n            \"number_of_fields\",\n            \"text_key\",\n            \"old_data\",\n            \"text_key_validator\",\n        }\n        for attr_name, attr_value in self._attributes.items():\n            if attr_name in default_keys:\n                continue  # Skip default attributes\n            if isinstance(attr_value, dict):\n                for key, value in attr_value.items():\n                    data[key] = value.get_text() if isinstance(value, Data) else value\n            elif isinstance(attr_value, Data):\n                data[attr_name] = attr_value.get_text()\n            else:\n                data[attr_name] = attr_value\n        return data\n\n    def validate_text_key(self, data: Data) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = data.data.keys()\n        if self.text_key and self.text_key not in data_keys:\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: \" f\"{', '.join(data_keys)}\"\n            raise ValueError(msg)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "number_of_fields": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "int",
                    "min": 1,
                    "max": 15,
                    "step": 1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_fields",
                  "value": 0,
                  "display_name": "Number of Fields",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Number of fields to be added to the record.",
                  "real_time_refresh": true,
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "text_key": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_key",
                  "value": "",
                  "display_name": "Text Key",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Key that identifies the field to be used as the text content.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text_key_validator": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_key_validator",
                  "value": false,
                  "display_name": "Text Key Validator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Dynamically update or append data with the specified fields.",
              "base_classes": [
                "Data"
              ],
              "display_name": "Update Data",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "hidden": null,
                  "display_name": "Data",
                  "method": "build_data",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": null
                }
              ],
              "field_order": [
                "old_data",
                "number_of_fields",
                "text_key",
                "text_key_validator"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false
            },
            "type": "UpdateData",
            "id": "UpdateData-hIznT"
          },
          "selected": false,
          "width": 320,
          "height": 302,
          "positionAbsolute": {
            "x": 1344.2451294945852,
            "y": 357.7778506458395
          },
          "dragging": false
        },
        {
          "id": "StructuredOutputComponent-PCR1I",
          "type": "genericNode",
          "position": {
            "x": 947.3092336067327,
            "y": 205.59403869109047
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "The language model to use to generate the structured output.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import cast\n\nfrom pydantic import BaseModel, Field, create_model\n\nfrom axiestudio.base.models.chat_result import get_chat_result\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing.constants import LanguageModel\nfrom axiestudio.helpers.base_model import build_model_from_schema\nfrom axiestudio.io import BoolInput, HandleInput, MessageTextInput, Output, StrInput, TableInput\nfrom axiestudio.schema.data import Data\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        MessageTextInput(name=\"input_value\", display_name=\"Input message\"),\n        StrInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"description\": (\n                        \"Indicate the data type of the output field \" \"(e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"default\": \"text\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                },\n            ],\n        ),\n        BoolInput(\n            name=\"multiple\",\n            display_name=\"Generate Multiple\",\n            info=\"Set to True if the model should generate a list of outputs instead of a single output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"structured_output\", display_name=\"Structured Output\", method=\"build_structured_output\"),\n    ]\n\n    def build_structured_output(self) -> Data:\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        _output_model = build_model_from_schema(self.output_schema)\n        if self.multiple:\n            output_model = create_model(\n                self.schema_name,\n                objects=(list[_output_model], Field(description=f\"A list of {self.schema_name}.\")),  # type: ignore[valid-type]\n            )\n        else:\n            output_model = _output_model\n        try:\n            llm_with_structured_output = cast(LanguageModel, self.llm).with_structured_output(schema=output_model)  # type: ignore[valid-type, attr-defined]\n\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        output = get_chat_result(runnable=llm_with_structured_output, input_value=self.input_value, config=config_dict)\n        if isinstance(output, BaseModel):\n            output_dict = output.model_dump()\n        else:\n            msg = f\"Output should be a Pydantic BaseModel, got {type(output)} ({output})\"\n            raise TypeError(msg)\n        return Data(data=output_dict)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "multiple": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "multiple",
                  "value": false,
                  "display_name": "Generate Multiple",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Set to True if the model should generate a list of outputs instead of a single output.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "output_schema": {
                  "is_list": true,
                  "table_schema": {
                    "columns": [
                      {
                        "name": "name",
                        "display_name": "Name",
                        "sortable": true,
                        "filterable": true,
                        "type": "text",
                        "description": "Specify the name of the output field.",
                        "formatter": "text"
                      },
                      {
                        "name": "description",
                        "display_name": "Description",
                        "sortable": true,
                        "filterable": true,
                        "type": "text",
                        "description": "Describe the purpose of the output field.",
                        "formatter": "text"
                      },
                      {
                        "name": "type",
                        "display_name": "Type",
                        "sortable": true,
                        "filterable": true,
                        "type": "text",
                        "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                        "default": "text",
                        "formatter": "text"
                      },
                      {
                        "name": "multiple",
                        "display_name": "Multiple",
                        "sortable": true,
                        "filterable": true,
                        "type": "boolean",
                        "description": "Set to True if this output field should be a list of the specified type.",
                        "default": "False",
                        "formatter": "text"
                      }
                    ]
                  },
                  "trace_as_metadata": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": "",
                  "display_name": "Output Schema",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Define the structure and data types for the model's output.",
                  "title_case": false,
                  "type": "table",
                  "_input_type": "TableInput"
                },
                "schema_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "schema_name",
                  "value": "",
                  "display_name": "Schema Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Provide a name for the output data schema.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
              "icon": "braces",
              "base_classes": [
                "Data"
              ],
              "display_name": "Structured Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "structured_output",
                  "display_name": "Structured Output",
                  "method": "build_structured_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "llm",
                "input_value",
                "schema_name",
                "output_schema",
                "multiple"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false
            },
            "type": "StructuredOutputComponent",
            "id": "StructuredOutputComponent-PCR1I"
          },
          "selected": false,
          "width": 320,
          "height": 542,
          "positionAbsolute": {
            "x": 947.3092336067327,
            "y": 205.59403869109047
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "ChatInput-Owfce",
          "sourceHandle": "{dataType:ChatInput,id:ChatInput-Owfce,name:message,output_types:[Message]}",
          "target": "LMStudioModel-b1Yz5",
          "targetHandle": "{fieldName:input_value,id:LMStudioModel-b1Yz5,inputTypes:[Message],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "LMStudioModel-b1Yz5",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-Owfce",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-Owfce{dataType:ChatInput,id:ChatInput-Owfce,name:message,output_types:[Message]}-LMStudioModel-b1Yz5{fieldName:input_value,id:LMStudioModel-b1Yz5,inputTypes:[Message],type:str}",
          "className": ""
        },
        {
          "source": "LMStudioModel-b1Yz5",
          "sourceHandle": "{dataType:LMStudioModel,id:LMStudioModel-b1Yz5,name:model_output,output_types:[LanguageModel]}",
          "target": "StructuredOutputComponent-PCR1I",
          "targetHandle": "{fieldName:llm,id:StructuredOutputComponent-PCR1I,inputTypes:[LanguageModel],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "StructuredOutputComponent-PCR1I",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "LMStudioModel",
              "id": "LMStudioModel-b1Yz5",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-LMStudioModel-b1Yz5{dataType:LMStudioModel,id:LMStudioModel-b1Yz5,name:model_output,output_types:[LanguageModel]}-StructuredOutputComponent-PCR1I{fieldName:llm,id:StructuredOutputComponent-PCR1I,inputTypes:[LanguageModel],type:other}"
        },
        {
          "source": "StructuredOutputComponent-PCR1I",
          "sourceHandle": "{dataType:StructuredOutputComponent,id:StructuredOutputComponent-PCR1I,name:structured_output,output_types:[Data]}",
          "target": "UpdateData-hIznT",
          "targetHandle": "{fieldName:old_data,id:UpdateData-hIznT,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "old_data",
              "id": "UpdateData-hIznT",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "StructuredOutputComponent",
              "id": "StructuredOutputComponent-PCR1I",
              "name": "structured_output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-StructuredOutputComponent-PCR1I{dataType:StructuredOutputComponent,id:StructuredOutputComponent-PCR1I,name:structured_output,output_types:[Data]}-UpdateData-hIznT{fieldName:old_data,id:UpdateData-hIznT,inputTypes:[Data],type:other}"
        }
      ],
      "viewport": {
        "x": -506.36092542403844,
        "y": -139.0944927404591,
        "zoom": 0.8879759017203487
      }
    },
    "date_created": "2024-11-22T08:55:04.027Z",
    "date_updated": "2024-11-22T08:55:04.113Z",
    "status": "Public",
    "sort": null,
    "user_updated": "63f0d574-95bc-455c-880f-af8f1947b55a",
    "user_created": {
      "username": "maskedrealness99",
      "first_name": "Ben",
      "last_name": "Boan",
      "id": "63f0d574-95bc-455c-880f-af8f1947b55a"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:07.304Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 46,
    "converter_version": "1.0.0"
  }
}