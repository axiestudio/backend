{
  "id": "270b3e84-711c-4b8e-bf4a-57c3fc3293b7",
  "name": "Basic Prompting (Hello, World)",
  "description": "This flow will get you experimenting with the basics of the UI, the Chat and the Prompt component. \n\nTry changing the Template in it to see how the model behaves. \nYou can change it to this and a Text Input into the `type_of_person` variable : \"Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer: \"  (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "linhe",
    "first_name": "he",
    "last_name": "lin",
    "id": "0a487e05-38b5-4c80-869d-c283888cdf0b",
    "full_name": "he lin"
  },
  "store_url": "https://www.langflow.store/store/component/270b3e84-711c-4b8e-bf4a-57c3fc3293b7",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-08-14T06:33:01.848Z",
    "updated": "2024-08-14T06:33:01.929Z",
    "downloaded": "2025-08-19T17:50:06.389Z"
  },
  "tags": [
    {
      "tags_id": {
        "name": "Agent",
        "id": "ccabb590-c9e8-4e56-9d6c-309955936c6c"
      }
    }
  ],
  "technical": {
    "last_tested_version": "1.0.7",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "id": "ChatInput-Ws0V1",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "ChatInput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "What is 3 * 12? Also, what is 11 + 49?"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "Session ID for the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 308,
        "id": "ChatInput-Ws0V1",
        "position": {
          "x": -802.8936421821533,
          "y": 1154.2501978008531
        },
        "positionAbsolute": {
          "x": -802.8936421821533,
          "y": 1154.2501978008531
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-jnm4A",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(frontend_template=frontend_node, raw_template=current_build_config[\"template\"])\n        return frontend_node\n"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer: \nå¦‚æžœæ˜¯åŠ æ³•è®¡ç®—ï¼Œä½¿ç”¨åŠ æ³•è®¡ç®—å·¥å…·"
              },
              "user_input": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_input",
                "display_name": "user_input",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "user_input"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": false,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 422,
        "id": "Prompt-jnm4A",
        "position": {
          "x": -210.42243824608772,
          "y": 808.9952656073627
        },
        "positionAbsolute": {
          "x": -210.42243824608772,
          "y": 808.9952656073627
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "ChatOutput-wateB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "ChatOutput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "data_template": {
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "Session ID for the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ChatOutput"
        },
        "dragging": true,
        "height": 308,
        "id": "ChatOutput-wateB",
        "position": {
          "x": 1943.7030442058199,
          "y": 1561.4780370969177
        },
        "positionAbsolute": {
          "x": 1943.7030442058199,
          "y": 1561.4780370969177
        },
        "selected": true,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "PythonCodeStructuredTool-yiBLT",
        "type": "genericNode",
        "position": {
          "x": -396.9938365635212,
          "y": 1562.6239959398363
        },
        "data": {
          "type": "PythonCodeStructuredTool",
          "node": {
            "template": {
              "_type": "CustomComponent",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nfrom typing import Any, Dict, List, Optional\n\nfrom langchain.agents import Tool\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(CustomComponent):\n    display_name = \"PythonCodeTool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"ðŸ\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\", \"tool_class\"]\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"tool_code\": {\n                \"display_name\": \"Tool Code\",\n                \"info\": \"Enter the dataclass code.\",\n                \"placeholder\": \"def my_function(args):\\n    pass\",\n                \"multiline\": True,\n                \"refresh_button\": True,\n                \"field_type\": \"code\",\n            },\n            \"name\": {\n                \"display_name\": \"Tool Name\",\n                \"info\": \"Enter the name of the tool.\",\n            },\n            \"description\": {\n                \"display_name\": \"Description\",\n                \"info\": \"Provide a brief description of what the tool does.\",\n            },\n            \"return_direct\": {\n                \"display_name\": \"Return Directly\",\n                \"info\": \"Should the tool return the function output directly?\",\n            },\n            \"tool_function\": {\n                \"display_name\": \"Tool Function\",\n                \"info\": \"Select the function for additional expressions.\",\n                \"options\": [],\n                \"refresh_button\": True,\n            },\n            \"tool_class\": {\n                \"display_name\": \"Tool Class\",\n                \"info\": \"Select the class for additional expressions.\",\n                \"options\": [],\n                \"refresh_button\": True,\n                \"required\": False,\n            },\n        }\n\n    def parse_source_name(self, code: str) -> Dict:\n        parsed_code = ast.parse(code)\n        class_names = [node.name for node in parsed_code.body if isinstance(node, ast.ClassDef)]\n        function_names = [node.name for node in parsed_code.body if isinstance(node, ast.FunctionDef)]\n        return {\"class\": class_names, \"function\": function_names}\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"tool_code\" or field_name == \"tool_function\" or field_name == \"tool_class\":\n            try:\n                names = self.parse_source_name(build_config.tool_code.value)\n                build_config.tool_class.options = names[\"class\"]\n                build_config.tool_function.options = names[\"function\"]\n            except Exception as e:\n                self.status = f\"Failed to extract class names: {str(e)}\"\n                build_config.tool_class.options = [\"Failed to parse\", str(e)]\n                build_config.tool_function.options = []\n        return build_config\n\n    async def build(\n        self,\n        tool_code: str,\n        name: str,\n        description: str,\n        tool_function: List[str],\n        return_direct: bool,\n        tool_class: Optional[List[str]] = None,\n    ) -> Tool:\n        local_namespace = {}  # type: ignore\n        exec(tool_code, globals(), local_namespace)\n\n        func = local_namespace[tool_function]\n        _class = None\n\n        if tool_class:\n            _class = local_namespace[tool_class]\n\n        tool = StructuredTool.from_function(\n            func=func, args_schema=_class, name=name, description=description, return_direct=return_direct\n        )\n        return tool  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "description": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "description",
                "display_name": "Description",
                "advanced": false,
                "dynamic": false,
                "info": "Provide a brief description of what the tool does.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "åŠ æ³•è®¡ç®—"
              },
              "name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "name",
                "display_name": "Tool Name",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the name of the tool.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "åŠ æ³•è®¡ç®—"
              },
              "return_direct": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_direct",
                "display_name": "Return Directly",
                "advanced": false,
                "dynamic": false,
                "info": "Should the tool return the function output directly?",
                "load_from_db": false,
                "title_case": false
              },
              "tool_class": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [],
                "name": "tool_class",
                "display_name": "Tool Class",
                "advanced": false,
                "dynamic": false,
                "info": "Select the class for additional expressions.",
                "refresh_button": true,
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "tool_code": {
                "type": "str",
                "required": true,
                "placeholder": "def my_function(args):\n    pass",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tool_code",
                "display_name": "Tool Code",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the dataclass code.",
                "refresh_button": true,
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "def add_numbers(a, b):\n    return a + b * 5\n\n\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiplies a and b.\"\"\"\n    return a * b * b\n"
              },
              "tool_function": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "add_numbers",
                  "multiply"
                ],
                "name": "tool_function",
                "display_name": "Tool Function",
                "advanced": false,
                "dynamic": false,
                "info": "Select the function for additional expressions.",
                "refresh_button": true,
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "multiply"
              }
            },
            "description": "structuredtool dataclass code to tool",
            "icon": "ðŸ",
            "base_classes": [
              "BaseTool",
              "Generic",
              "object",
              "Runnable",
              "RunnableSerializable",
              "Serializable",
              "Tool"
            ],
            "display_name": "PythonCodeTool",
            "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
            "custom_fields": {
              "tool_code": null,
              "name": null,
              "description": null,
              "tool_function": null,
              "return_direct": null,
              "tool_class": null
            },
            "output_types": [
              "Tool"
            ],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "hidden": false,
                "display_name": "Tool",
                "method": null,
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "name",
              "description",
              "tool_code",
              "return_direct",
              "tool_function",
              "tool_class"
            ],
            "beta": false,
            "edited": false
          },
          "id": "PythonCodeStructuredTool-yiBLT",
          "description": "structuredtool dataclass code to tool",
          "display_name": "PythonCodeTool"
        },
        "selected": false,
        "width": 384,
        "height": 803,
        "positionAbsolute": {
          "x": -396.9938365635212,
          "y": 1562.6239959398363
        },
        "dragging": false
      },
      {
        "id": "ToolCallingAgent-nuUk4",
        "type": "genericNode",
        "position": {
          "x": 1226.2290065730522,
          "y": 1430.297476253668
        },
        "data": {
          "type": "ToolCallingAgent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Memory to use for the agent.",
                "title_case": false,
                "type": "other"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "tools",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Dict, List, cast\n\nfrom langchain.agents import AgentExecutor, BaseSingleActionAgent\nfrom langchain.agents.tool_calling_agent.base import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, HandleInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass ToolCallingAgentComponent(Component):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools. Only models that are compatible with function calling are supported.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Input text to pass to the agent.\",\n        ),\n        MessageTextInput(\n            name=\"user_prompt\",\n            display_name=\"Prompt\",\n            info=\"This prompt must contain 'input' key.\",\n            value=\"{input}\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"handle_parsing_errors\",\n            display_name=\"Handle Parsing Errors\",\n            info=\"If True, the agent will handle parsing errors. If False, the agent will raise an error.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"Data\"],\n            info=\"Memory to use for the agent.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            input_types=[\"LanguageModel\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"run_agent\"),\n    ]\n\n    async def run_agent(self) -> Message:\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\n                \"placeholder\",\n                \"{chat_history}\",\n            ),\n            (\"human\", self.user_prompt),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        agent = create_tool_calling_agent(self.llm, self.tools, prompt)\n\n        runnable = AgentExecutor.from_agent_and_tools(\n            agent=cast(BaseSingleActionAgent, agent),\n            tools=self.tools,\n            verbose=True,\n            handle_parsing_errors=self.handle_parsing_errors,\n        )\n        input_dict: dict[str, str | list[Dict[str, str]]] = {\"input\": self.input_value}\n        if hasattr(self, \"memory\") and self.memory:\n            input_dict[\"chat_history\"] = self.convert_chat_history(self.memory)\n        result = await runnable.ainvoke(input_dict)\n\n        if \"output\" not in result:\n            raise ValueError(\"Output key not found in result. Tried 'output'.\")\n\n        results = result[\"output\"]\n        if isinstance(results, list):\n            result_string = \"\\n\".join([r[\"text\"] for r in results if \"text\" in r and r.get(\"type\") == \"text\"])\n        else:\n            result_string = results\n        self.status = result_string\n        return Message(text=result_string)\n\n    def convert_chat_history(self, chat_history: List[Data]) -> List[Dict[str, str]]:\n        messages = []\n        for item in chat_history:\n            role = \"user\" if item.sender == \"User\" else \"assistant\"\n            messages.append({\"role\": role, \"content\": item.text})\n        return messages",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "handle_parsing_errors",
                "display_name": "Handle Parsing Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If True, the agent will handle parsing errors. If False, the agent will raise an error.",
                "title_case": false,
                "type": "bool"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Inputs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Input text to pass to the agent.",
                "title_case": false,
                "type": "str"
              },
              "system_prompt": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_prompt",
                "display_name": "System Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System prompt for the agent.",
                "title_case": false,
                "type": "str"
              },
              "user_prompt": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{input}",
                "name": "user_prompt",
                "display_name": "Prompt",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "This prompt must contain 'input' key.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
            "icon": "LangChain",
            "base_classes": [
              "Message"
            ],
            "display_name": "Tool Calling Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "run_agent",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "system_prompt",
              "input_value",
              "user_prompt",
              "handle_parsing_errors",
              "memory",
              "tools",
              "llm"
            ],
            "beta": true,
            "edited": true
          },
          "id": "ToolCallingAgent-nuUk4",
          "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
          "display_name": "Tool Calling Agent"
        },
        "selected": false,
        "width": 384,
        "height": 574,
        "dragging": false,
        "positionAbsolute": {
          "x": 1226.2290065730522,
          "y": 1430.297476253668
        }
      },
      {
        "id": "OpenAIModel-6myPA",
        "type": "genericNode",
        "position": {
          "x": 500.1046348490265,
          "y": 522.3470599187954
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            # name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=[\"qwen:latest\", \"gpt-4o\", \"gpt-4-turbo\", \"gpt-4-turbo-preview\", \"gpt-4\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-0125\"], value=MODEL_NAMES[0]\n            \n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "json_mode",
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "qwen:latest",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "qwen:latest",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "http://localhost:11434/v1/",
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": false,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str"
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "output_schema",
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1,
                "name": "seed",
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.1,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "beta": false,
            "edited": true
          },
          "id": "OpenAIModel-6myPA",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI"
        },
        "selected": false,
        "width": 384,
        "height": 706,
        "dragging": false,
        "positionAbsolute": {
          "x": 500.1046348490265,
          "y": 522.3470599187954
        }
      }
    ],
    "edges": [
      {
        "source": "ChatInput-Ws0V1",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Prompt-jnm4A",
        "targetHandle": "{Å“fieldNameÅ“:Å“user_inputÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "user_input",
            "id": "Prompt-jnm4A",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-Ws0V1",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-Ws0V1{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-jnm4A{Å“fieldNameÅ“:Å“user_inputÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "OpenAIModel-6myPA",
        "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-6myPAÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}",
        "target": "ToolCallingAgent-nuUk4",
        "targetHandle": "{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“LanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ToolCallingAgent-nuUk4",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-6myPA",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-6myPA{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-6myPAÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“LanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "source": "PythonCodeStructuredTool-yiBLT",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-yiBLTÅ“,Å“nameÅ“:Å“toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}",
        "target": "ToolCallingAgent-nuUk4",
        "targetHandle": "{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“ToolÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-nuUk4",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "PythonCodeStructuredTool",
            "id": "PythonCodeStructuredTool-yiBLT",
            "name": "tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-PythonCodeStructuredTool-yiBLT{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-yiBLTÅ“,Å“nameÅ“:Å“toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“ToolÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "source": "ToolCallingAgent-nuUk4",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ToolCallingAgentÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ChatOutput-wateB",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-wateBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-wateB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ToolCallingAgent",
            "id": "ToolCallingAgent-nuUk4",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ToolCallingAgent-nuUk4{Å“dataTypeÅ“:Å“ToolCallingAgentÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-wateB{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-wateBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "Prompt-jnm4A",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ToolCallingAgent-nuUk4",
        "targetHandle": "{Å“fieldNameÅ“:Å“system_promptÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "ToolCallingAgent-nuUk4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-jnm4A",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-jnm4A{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“system_promptÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      },
      {
        "source": "ChatInput-Ws0V1",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ToolCallingAgent-nuUk4",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ToolCallingAgent-nuUk4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-Ws0V1",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-Ws0V1{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
      }
    ],
    "viewport": {
      "x": 145.76838269060602,
      "y": -335.2584967434957,
      "zoom": 0.4504094750161373
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "PythonCodeStructuredTool": {
      "count": 1
    },
    "ToolCallingAgent": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "total": 6
  },
  "original": {
    "id": "270b3e84-711c-4b8e-bf4a-57c3fc3293b7",
    "name": "Basic Prompting (Hello, World)",
    "description": "This flow will get you experimenting with the basics of the UI, the Chat and the Prompt component. \n\nTry changing the Template in it to see how the model behaves. \nYou can change it to this and a Text Input into the `type_of_person` variable : \"Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer: \" ",
    "is_component": false,
    "liked_by_count": "2",
    "downloads_count": "21",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "PythonCodeStructuredTool": {
        "count": 1
      },
      "ToolCallingAgent": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "total": 6
    },
    "last_tested_version": "1.0.7",
    "private": false,
    "data": {
      "nodes": [
        {
          "data": {
            "id": "ChatInput-Ws0V1",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Get chat inputs from the Playground.",
              "display_name": "Chat Input",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "frozen": false,
              "icon": "ChatInput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "hidden": false,
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "files": {
                  "advanced": true,
                  "display_name": "Files",
                  "dynamic": false,
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "file_path": "",
                  "info": "Files to be sent with the message.",
                  "list": true,
                  "name": "files",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "file",
                  "value": ""
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "What is 3 * 12? Also, what is 11 + 49?"
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "User"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "User"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                }
              }
            },
            "type": "ChatInput"
          },
          "dragging": false,
          "height": 308,
          "id": "ChatInput-Ws0V1",
          "position": {
            "x": -802.8936421821533,
            "y": 1154.2501978008531
          },
          "positionAbsolute": {
            "x": -802.8936421821533,
            "y": 1154.2501978008531
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-jnm4A",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(frontend_template=frontend_node, raw_template=current_build_config[\"template\"])\n        return frontend_node\n"
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer: \nå¦‚æžœæ˜¯åŠ æ³•è®¡ç®—ï¼Œä½¿ç”¨åŠ æ³•è®¡ç®—å·¥å…·"
                },
                "user_input": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_input",
                  "display_name": "user_input",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "user_input"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": false,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 422,
          "id": "Prompt-jnm4A",
          "position": {
            "x": -210.42243824608772,
            "y": 808.9952656073627
          },
          "positionAbsolute": {
            "x": -210.42243824608772,
            "y": 808.9952656073627
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "ChatOutput-wateB",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Display a chat message in the Playground.",
              "display_name": "Chat Output",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "frozen": false,
              "icon": "ChatOutput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "data_template": {
                  "advanced": true,
                  "display_name": "Data Template",
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "data_template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "{text}"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Machine"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "AI"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                }
              }
            },
            "type": "ChatOutput"
          },
          "dragging": true,
          "height": 308,
          "id": "ChatOutput-wateB",
          "position": {
            "x": 1943.7030442058199,
            "y": 1561.4780370969177
          },
          "positionAbsolute": {
            "x": 1943.7030442058199,
            "y": 1561.4780370969177
          },
          "selected": true,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "PythonCodeStructuredTool-yiBLT",
          "type": "genericNode",
          "position": {
            "x": -396.9938365635212,
            "y": 1562.6239959398363
          },
          "data": {
            "type": "PythonCodeStructuredTool",
            "node": {
              "template": {
                "_type": "CustomComponent",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nfrom typing import Any, Dict, List, Optional\n\nfrom langchain.agents import Tool\nfrom langchain.tools import StructuredTool\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(CustomComponent):\n    display_name = \"PythonCodeTool\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"ðŸ\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\", \"tool_class\"]\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"tool_code\": {\n                \"display_name\": \"Tool Code\",\n                \"info\": \"Enter the dataclass code.\",\n                \"placeholder\": \"def my_function(args):\\n    pass\",\n                \"multiline\": True,\n                \"refresh_button\": True,\n                \"field_type\": \"code\",\n            },\n            \"name\": {\n                \"display_name\": \"Tool Name\",\n                \"info\": \"Enter the name of the tool.\",\n            },\n            \"description\": {\n                \"display_name\": \"Description\",\n                \"info\": \"Provide a brief description of what the tool does.\",\n            },\n            \"return_direct\": {\n                \"display_name\": \"Return Directly\",\n                \"info\": \"Should the tool return the function output directly?\",\n            },\n            \"tool_function\": {\n                \"display_name\": \"Tool Function\",\n                \"info\": \"Select the function for additional expressions.\",\n                \"options\": [],\n                \"refresh_button\": True,\n            },\n            \"tool_class\": {\n                \"display_name\": \"Tool Class\",\n                \"info\": \"Select the class for additional expressions.\",\n                \"options\": [],\n                \"refresh_button\": True,\n                \"required\": False,\n            },\n        }\n\n    def parse_source_name(self, code: str) -> Dict:\n        parsed_code = ast.parse(code)\n        class_names = [node.name for node in parsed_code.body if isinstance(node, ast.ClassDef)]\n        function_names = [node.name for node in parsed_code.body if isinstance(node, ast.FunctionDef)]\n        return {\"class\": class_names, \"function\": function_names}\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"tool_code\" or field_name == \"tool_function\" or field_name == \"tool_class\":\n            try:\n                names = self.parse_source_name(build_config.tool_code.value)\n                build_config.tool_class.options = names[\"class\"]\n                build_config.tool_function.options = names[\"function\"]\n            except Exception as e:\n                self.status = f\"Failed to extract class names: {str(e)}\"\n                build_config.tool_class.options = [\"Failed to parse\", str(e)]\n                build_config.tool_function.options = []\n        return build_config\n\n    async def build(\n        self,\n        tool_code: str,\n        name: str,\n        description: str,\n        tool_function: List[str],\n        return_direct: bool,\n        tool_class: Optional[List[str]] = None,\n    ) -> Tool:\n        local_namespace = {}  # type: ignore\n        exec(tool_code, globals(), local_namespace)\n\n        func = local_namespace[tool_function]\n        _class = None\n\n        if tool_class:\n            _class = local_namespace[tool_class]\n\n        tool = StructuredTool.from_function(\n            func=func, args_schema=_class, name=name, description=description, return_direct=return_direct\n        )\n        return tool  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "description": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "description",
                  "display_name": "Description",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Provide a brief description of what the tool does.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "åŠ æ³•è®¡ç®—"
                },
                "name": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "name",
                  "display_name": "Tool Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Enter the name of the tool.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "åŠ æ³•è®¡ç®—"
                },
                "return_direct": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "return_direct",
                  "display_name": "Return Directly",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Should the tool return the function output directly?",
                  "load_from_db": false,
                  "title_case": false
                },
                "tool_class": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [],
                  "name": "tool_class",
                  "display_name": "Tool Class",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the class for additional expressions.",
                  "refresh_button": true,
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "tool_code": {
                  "type": "str",
                  "required": true,
                  "placeholder": "def my_function(args):\n    pass",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tool_code",
                  "display_name": "Tool Code",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Enter the dataclass code.",
                  "refresh_button": true,
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "def add_numbers(a, b):\n    return a + b * 5\n\n\ndef multiply(a: int, b: int) -> int:\n    \"\"\"Multiplies a and b.\"\"\"\n    return a * b * b\n"
                },
                "tool_function": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "add_numbers",
                    "multiply"
                  ],
                  "name": "tool_function",
                  "display_name": "Tool Function",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Select the function for additional expressions.",
                  "refresh_button": true,
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "multiply"
                }
              },
              "description": "structuredtool dataclass code to tool",
              "icon": "ðŸ",
              "base_classes": [
                "BaseTool",
                "Generic",
                "object",
                "Runnable",
                "RunnableSerializable",
                "Serializable",
                "Tool"
              ],
              "display_name": "PythonCodeTool",
              "documentation": "https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass",
              "custom_fields": {
                "tool_code": null,
                "name": null,
                "description": null,
                "tool_function": null,
                "return_direct": null,
                "tool_class": null
              },
              "output_types": [
                "Tool"
              ],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "tool",
                  "hidden": false,
                  "display_name": "Tool",
                  "method": null,
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "name",
                "description",
                "tool_code",
                "return_direct",
                "tool_function",
                "tool_class"
              ],
              "beta": false,
              "edited": false
            },
            "id": "PythonCodeStructuredTool-yiBLT",
            "description": "structuredtool dataclass code to tool",
            "display_name": "PythonCodeTool"
          },
          "selected": false,
          "width": 384,
          "height": 803,
          "positionAbsolute": {
            "x": -396.9938365635212,
            "y": 1562.6239959398363
          },
          "dragging": false
        },
        {
          "id": "ToolCallingAgent-nuUk4",
          "type": "genericNode",
          "position": {
            "x": 1226.2290065730522,
            "y": 1430.297476253668
          },
          "data": {
            "type": "ToolCallingAgent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Memory to use for the agent.",
                  "title_case": false,
                  "type": "other"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "tools",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Dict, List, cast\n\nfrom langchain.agents import AgentExecutor, BaseSingleActionAgent\nfrom langchain.agents.tool_calling_agent.base import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, HandleInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass ToolCallingAgentComponent(Component):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools. Only models that are compatible with function calling are supported.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Input text to pass to the agent.\",\n        ),\n        MessageTextInput(\n            name=\"user_prompt\",\n            display_name=\"Prompt\",\n            info=\"This prompt must contain 'input' key.\",\n            value=\"{input}\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"handle_parsing_errors\",\n            display_name=\"Handle Parsing Errors\",\n            info=\"If True, the agent will handle parsing errors. If False, the agent will raise an error.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"Data\"],\n            info=\"Memory to use for the agent.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            input_types=[\"LanguageModel\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"run_agent\"),\n    ]\n\n    async def run_agent(self) -> Message:\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\n                \"placeholder\",\n                \"{chat_history}\",\n            ),\n            (\"human\", self.user_prompt),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        agent = create_tool_calling_agent(self.llm, self.tools, prompt)\n\n        runnable = AgentExecutor.from_agent_and_tools(\n            agent=cast(BaseSingleActionAgent, agent),\n            tools=self.tools,\n            verbose=True,\n            handle_parsing_errors=self.handle_parsing_errors,\n        )\n        input_dict: dict[str, str | list[Dict[str, str]]] = {\"input\": self.input_value}\n        if hasattr(self, \"memory\") and self.memory:\n            input_dict[\"chat_history\"] = self.convert_chat_history(self.memory)\n        result = await runnable.ainvoke(input_dict)\n\n        if \"output\" not in result:\n            raise ValueError(\"Output key not found in result. Tried 'output'.\")\n\n        results = result[\"output\"]\n        if isinstance(results, list):\n            result_string = \"\\n\".join([r[\"text\"] for r in results if \"text\" in r and r.get(\"type\") == \"text\"])\n        else:\n            result_string = results\n        self.status = result_string\n        return Message(text=result_string)\n\n    def convert_chat_history(self, chat_history: List[Data]) -> List[Dict[str, str]]:\n        messages = []\n        for item in chat_history:\n            role = \"user\" if item.sender == \"User\" else \"assistant\"\n            messages.append({\"role\": role, \"content\": item.text})\n        return messages",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "handle_parsing_errors",
                  "display_name": "Handle Parsing Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, the agent will handle parsing errors. If False, the agent will raise an error.",
                  "title_case": false,
                  "type": "bool"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Inputs",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Input text to pass to the agent.",
                  "title_case": false,
                  "type": "str"
                },
                "system_prompt": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_prompt",
                  "display_name": "System Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System prompt for the agent.",
                  "title_case": false,
                  "type": "str"
                },
                "user_prompt": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{input}",
                  "name": "user_prompt",
                  "display_name": "Prompt",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "This prompt must contain 'input' key.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
              "icon": "LangChain",
              "base_classes": [
                "Message"
              ],
              "display_name": "Tool Calling Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "run_agent",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "system_prompt",
                "input_value",
                "user_prompt",
                "handle_parsing_errors",
                "memory",
                "tools",
                "llm"
              ],
              "beta": true,
              "edited": true
            },
            "id": "ToolCallingAgent-nuUk4",
            "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
            "display_name": "Tool Calling Agent"
          },
          "selected": false,
          "width": 384,
          "height": 574,
          "dragging": false,
          "positionAbsolute": {
            "x": 1226.2290065730522,
            "y": 1430.297476253668
          }
        },
        {
          "id": "OpenAIModel-6myPA",
          "type": "genericNode",
          "position": {
            "x": 500.1046348490265,
            "y": 522.3470599187954
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            # name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=[\"qwen:latest\", \"gpt-4o\", \"gpt-4-turbo\", \"gpt-4-turbo-preview\", \"gpt-4\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-0125\"], value=MODEL_NAMES[0]\n            \n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "json_mode",
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "qwen:latest",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "qwen:latest",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "load_from_db": false
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "http://localhost:11434/v1/",
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str"
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "output_schema",
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1,
                  "name": "seed",
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.1,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "beta": false,
              "edited": true
            },
            "id": "OpenAIModel-6myPA",
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI"
          },
          "selected": false,
          "width": 384,
          "height": 706,
          "dragging": false,
          "positionAbsolute": {
            "x": 500.1046348490265,
            "y": 522.3470599187954
          }
        }
      ],
      "edges": [
        {
          "source": "ChatInput-Ws0V1",
          "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "target": "Prompt-jnm4A",
          "targetHandle": "{Å“fieldNameÅ“:Å“user_inputÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "user_input",
              "id": "Prompt-jnm4A",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-Ws0V1",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-Ws0V1{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-jnm4A{Å“fieldNameÅ“:Å“user_inputÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}"
        },
        {
          "source": "OpenAIModel-6myPA",
          "sourceHandle": "{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-6myPAÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}",
          "target": "ToolCallingAgent-nuUk4",
          "targetHandle": "{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“LanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ToolCallingAgent-nuUk4",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-6myPA",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-6myPA{Å“dataTypeÅ“:Å“OpenAIModelÅ“,Å“idÅ“:Å“OpenAIModel-6myPAÅ“,Å“nameÅ“:Å“model_outputÅ“,Å“output_typesÅ“:[Å“LanguageModelÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“llmÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“LanguageModelÅ“],Å“typeÅ“:Å“otherÅ“}"
        },
        {
          "source": "PythonCodeStructuredTool-yiBLT",
          "sourceHandle": "{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-yiBLTÅ“,Å“nameÅ“:Å“toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}",
          "target": "ToolCallingAgent-nuUk4",
          "targetHandle": "{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“ToolÅ“],Å“typeÅ“:Å“otherÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "ToolCallingAgent-nuUk4",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "PythonCodeStructuredTool",
              "id": "PythonCodeStructuredTool-yiBLT",
              "name": "tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-PythonCodeStructuredTool-yiBLT{Å“dataTypeÅ“:Å“PythonCodeStructuredToolÅ“,Å“idÅ“:Å“PythonCodeStructuredTool-yiBLTÅ“,Å“nameÅ“:Å“toolÅ“,Å“output_typesÅ“:[Å“ToolÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“toolsÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“ToolÅ“],Å“typeÅ“:Å“otherÅ“}"
        },
        {
          "source": "ToolCallingAgent-nuUk4",
          "sourceHandle": "{Å“dataTypeÅ“:Å“ToolCallingAgentÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "target": "ChatOutput-wateB",
          "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-wateBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-wateB",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ToolCallingAgent",
              "id": "ToolCallingAgent-nuUk4",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ToolCallingAgent-nuUk4{Å“dataTypeÅ“:Å“ToolCallingAgentÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-wateB{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-wateBÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
        },
        {
          "source": "Prompt-jnm4A",
          "sourceHandle": "{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "target": "ToolCallingAgent-nuUk4",
          "targetHandle": "{Å“fieldNameÅ“:Å“system_promptÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "system_prompt",
              "id": "ToolCallingAgent-nuUk4",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-jnm4A",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-jnm4A{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-jnm4AÅ“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“system_promptÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
        },
        {
          "source": "ChatInput-Ws0V1",
          "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
          "target": "ToolCallingAgent-nuUk4",
          "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ToolCallingAgent-nuUk4",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-Ws0V1",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-Ws0V1{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-Ws0V1Å“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ToolCallingAgent-nuUk4{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ToolCallingAgent-nuUk4Å“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}"
        }
      ],
      "viewport": {
        "x": 145.76838269060602,
        "y": -335.2584967434957,
        "zoom": 0.4504094750161373
      }
    },
    "date_created": "2024-08-14T06:33:01.848Z",
    "date_updated": "2024-08-14T06:33:01.929Z",
    "status": "Public",
    "sort": null,
    "user_updated": "0a487e05-38b5-4c80-869d-c283888cdf0b",
    "user_created": {
      "username": "linhe",
      "first_name": "he",
      "last_name": "lin",
      "id": "0a487e05-38b5-4c80-869d-c283888cdf0b"
    },
    "tags": [
      {
        "tags_id": {
          "name": "Agent",
          "id": "ccabb590-c9e8-4e56-9d6c-309955936c6c"
        }
      }
    ]
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:55.447Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 46,
    "converter_version": "1.0.0"
  }
}