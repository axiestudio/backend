{
  "id": "de9eeda0-7031-4c1b-8730-e5ecf4be90e5",
  "name": "test",
  "description": "Harness the Power of Conversational AI. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "schobiwalter",
    "first_name": "Felix",
    "last_name": "Schoberwalter",
    "id": "53ee5d46-377b-42e0-ad7e-9c9615eb74c2",
    "full_name": "Felix Schoberwalter"
  },
  "store_url": "https://www.langflow.store/store/component/de9eeda0-7031-4c1b-8730-e5ecf4be90e5",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-06-14T14:43:21.889Z",
    "updated": "2024-06-14T14:58:03.360Z",
    "downloaded": "2025-08-19T17:50:05.667Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.0a55",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "Prompt-key40",
        "type": "genericNode",
        "position": {
          "x": -542.8707199548459,
          "y": -141.65184805333627
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import TemplateField\nfrom axiestudio.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "prompt",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Instruction:\n\nYou are a highly intelligent language model capable of understanding and analyzing stories. Your task is to extract distinct scenes from the provided story. A scene is a segment of the story where specific events happen in a specific setting, focusing on the environment and surroundings. Identify and describe each scene clearly, specifying the key elements of the setting without mentioning any characters or entities. Additionally, provide the word number where each scene starts.\n\nStory:\n\n{story}\n\nJSON Output:",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent",
              "story": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "story",
                "display_name": "story",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Message",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Prompt",
              "Record"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "story"
              ]
            },
            "output_types": [
              "Prompt"
            ],
            "full_path": null,
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "error": null
          },
          "id": "Prompt-key40",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 419,
        "positionAbsolute": {
          "x": -542.8707199548459,
          "y": -141.65184805333627
        },
        "dragging": false
      },
      {
        "id": "TextInput-iC8P2",
        "type": "genericNode",
        "position": {
          "x": -1010.638950648054,
          "y": -38.219925301801666
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "In the bustling city of Elaris, where towering skyscrapers kissed the clouds and neon lights painted the night, lived a young architect named Alex. Alex had always dreamt of designing a building that would stand as a symbol of innovation and creativity. One evening, while sketching ideas in his studio, he received a mysterious package. Inside was an old, leather-bound journal filled with intricate designs and notes, some written in an ancient language. Intrigued, Alex began to decipher the journal, uncovering plans for a unique structure that seemed to defy the laws of physics.  Determined to bring these designs to life, Alex presented the idea to his firm. However, his colleagues and superiors dismissed it as fantasy. Undeterred, Alex decided to pursue the project independently. He gathered a small team of like-minded individuals, including Elena, a brilliant engineer; Marcus, a skilled craftsman; and Dr. Lila, a historian specializing in ancient languages. Together, they worked tirelessly to understand and refine the designs from the journal.  Their journey took them to various parts of the world, from ancient ruins in Greece to hidden temples in South America, where they sought to uncover more information about the mysterious architect who had originally conceived the designs. Each location brought new challenges and discoveries. In Greece, they found a hidden chamber beneath an old temple, filled with more detailed blueprints and a strange, glowing artifact. In South America, they uncovered ancient tablets that revealed the structure was meant to harness a unique form of energy, capable of providing limitless power.  As they pieced together the puzzle, Alex and his team faced numerous obstacles. Rival corporations, sensing the potential of their discovery, tried to sabotage their efforts. Natural disasters, including a powerful earthquake, threatened to destroy their work. Despite these setbacks, their bond grew stronger, and their resolve never wavered.  Finally, after months of relentless effort, they returned to Elaris with all the knowledge and resources they needed. The construction of the building began, and the city's residents watched in awe as the structure rose, seemingly defying gravity with its elegant curves and floating platforms. It wasn't long before the media caught wind of the project, dubbing it \"The Beacon of Elaris.\"  As the building neared completion, Alex made a startling discovery. Hidden within the journal was a final, cryptic message from the original architect, hinting at a hidden chamber within the building that contained a secret of immense power. On the night of the grand unveiling, Alex and his team ventured into the building, deciphering the clues to find the hidden chamber. Inside, they discovered a powerful energy source, unlike anything they had ever seen.  Realizing the potential dangers and benefits of such a discovery, Alex decided to keep the chamber a secret, using the energy source to power the building and provide clean energy to the city without revealing its existence to the world. The Beacon of Elaris stood as a testament to human ingenuity and the power of perseverance, inspiring generations to come.  Years later, as Alex stood atop the building, looking out over the city, he couldn't help but feel a sense of fulfillment. The journey had been long and arduous, but the result was worth every challenge they had faced. The Beacon of Elaris had become a symbol of hope and innovation, a shining example of what could be achieved when one dared to dream and never gave up.",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "Text or Record to be passed as input.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextInput-iC8P2"
        },
        "selected": true,
        "width": 384,
        "height": 297,
        "positionAbsolute": {
          "x": -1010.638950648054,
          "y": -38.219925301801666
        },
        "dragging": false
      },
      {
        "id": "OllamaModel-Ncr0x",
        "type": "genericNode",
        "position": {
          "x": -36.75693357738453,
          "y": -651.4568850108401
        },
        "data": {
          "type": "OllamaModel",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Text",
                  "Record",
                  "Prompt"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "stop": {
                "type": "list",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stop",
                "display_name": "Stop Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "List of tokens to signal the model to stop generating text.",
                "load_from_db": false,
                "title_case": false
              },
              "tags": {
                "type": "list",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tags",
                "display_name": "Tags",
                "advanced": true,
                "dynamic": false,
                "info": "Tags to add to the run trace.",
                "load_from_db": false,
                "title_case": false
              },
              "base_url": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "base_url",
                "display_name": "Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "http://127.0.0.1:11434/"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any, Dict, List, Optional\n\nimport httpx\nfrom langchain_community.chat_models.ollama import ChatOllama\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Text\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    field_order = [\n        \"base_url\",\n        \"headers\",\n        \"keep_alive_flag\",\n        \"keep_alive\",\n        \"metadata\",\n        \"model\",\n        \"temperature\",\n        \"cache\",\n        \"format\",\n        \"metadata\",\n        \"mirostat\",\n        \"mirostat_eta\",\n        \"mirostat_tau\",\n        \"num_ctx\",\n        \"num_gpu\",\n        \"num_thread\",\n        \"repeat_last_n\",\n        \"repeat_penalty\",\n        \"tfs_z\",\n        \"timeout\",\n        \"top_k\",\n        \"top_p\",\n        \"verbose\",\n        \"tags\",\n        \"stop\",\n        \"system\",\n        \"template\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"info\": \"Specify the format of the output (e.g., json)\",\n                \"advanced\": True,\n            },\n            \"headers\": {\n                \"display_name\": \"Headers\",\n                \"advanced\": True,\n            },\n            \"keep_alive_flag\": {\n                \"display_name\": \"Unload interval\",\n                \"options\": [\"Keep\", \"Immediately\", \"Minute\", \"Hour\", \"sec\"],\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"keep_alive\": {\n                \"display_name\": \"interval\",\n                \"info\": \"How long the model will stay loaded into memory.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"options\": [],\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"advanced\": False,\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n                \"real_time_refresh\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n                \"real_time_refresh\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name == \"model\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:11434\"\n            build_config[\"model\"][\"options\"] = self.get_model(base_url_value + \"/api/tags\")\n\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    def get_model(self, url: str) -> List[str]:\n        try:\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                model_names = [model[\"name\"] for model in data.get(\"models\", [])]\n                return model_names\n        except Exception as e:\n            raise ValueError(\"Could not retrieve models\") from e\n            return [\"\"]\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        input_value: Text,\n        mirostat: Optional[str] = \"Disabled\",\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        keep_alive: Optional[int] = None,\n        keep_alive_flag: Optional[str] = \"Keep\",\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        if keep_alive_flag == \"Minute\":\n            keep_alive_instance = f\"{keep_alive}m\"\n        elif keep_alive_flag == \"Hour\":\n            keep_alive_instance = f\"{keep_alive}h\"\n        elif keep_alive_flag == \"sec\":\n            keep_alive_instance = f\"{keep_alive}s\"\n        elif keep_alive_flag == \"Keep\":\n            keep_alive_instance = \"-1\"\n        elif keep_alive_flag == \"Immediately\":\n            keep_alive_instance = \"0\"\n        else:\n            keep_alive_instance = \"Invalid option\"\n\n        mirostat_instance = 0\n\n        if mirostat == \"disable\":\n            mirostat_instance = 0\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"model\": model,\n            \"mirostat\": mirostat_instance,\n            \"keep_alive\": keep_alive_instance,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "format": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "format",
                "display_name": "Format",
                "advanced": true,
                "dynamic": false,
                "info": "Specify the format of the output (e.g., json)",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "keep_alive": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "keep_alive",
                "display_name": "interval",
                "advanced": false,
                "dynamic": false,
                "info": "How long the model will stay loaded into memory.",
                "load_from_db": false,
                "title_case": false,
                "value": "0"
              },
              "keep_alive_flag": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Keep",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Keep",
                  "Immediately",
                  "Minute",
                  "Hour",
                  "sec"
                ],
                "name": "keep_alive_flag",
                "display_name": "Unload interval",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "metadata",
                "display_name": "Metadata",
                "advanced": true,
                "dynamic": false,
                "info": "Metadata to add to the run trace.",
                "load_from_db": false,
                "title_case": false
              },
              "mirostat": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Disabled",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Disabled",
                  "Mirostat",
                  "Mirostat 2.0"
                ],
                "name": "mirostat",
                "display_name": "Mirostat",
                "advanced": false,
                "dynamic": false,
                "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                "real_time_refresh": true,
                "refresh_button": true,
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "mirostat_eta": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_eta",
                "display_name": "Mirostat Eta",
                "advanced": true,
                "dynamic": false,
                "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                "real_time_refresh": true,
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "mirostat_tau": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_tau",
                "display_name": "Mirostat Tau",
                "advanced": true,
                "dynamic": false,
                "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                "real_time_refresh": true,
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "llama3:latest"
                ],
                "name": "model",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "Refer to https://ollama.ai/library for more models.",
                "real_time_refresh": true,
                "refresh_button": true,
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "llama3:latest"
              },
              "num_ctx": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_ctx",
                "display_name": "Context Window Size",
                "advanced": true,
                "dynamic": false,
                "info": "Size of the context window for generating tokens. (Default: 2048)",
                "load_from_db": false,
                "title_case": false
              },
              "num_gpu": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_gpu",
                "display_name": "Number of GPUs",
                "advanced": true,
                "dynamic": false,
                "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                "load_from_db": false,
                "title_case": false
              },
              "num_thread": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_thread",
                "display_name": "Number of Threads",
                "advanced": true,
                "dynamic": false,
                "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                "load_from_db": false,
                "title_case": false
              },
              "repeat_last_n": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_last_n",
                "display_name": "Repeat Last N",
                "advanced": true,
                "dynamic": false,
                "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                "load_from_db": false,
                "title_case": false
              },
              "repeat_penalty": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_penalty",
                "display_name": "Repeat Penalty",
                "advanced": true,
                "dynamic": false,
                "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "stream": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "load_from_db": false,
                "title_case": false
              },
              "system": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system",
                "display_name": "System",
                "advanced": true,
                "dynamic": false,
                "info": "System to use for generating text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "system_message": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.8,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Controls the creativity of model responses.",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to use for generating text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "tfs_z": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tfs_z",
                "display_name": "TFS Z",
                "advanced": true,
                "dynamic": false,
                "info": "Tail free sampling value. (Default: 1)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "timeout": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "Timeout for the request stream.",
                "load_from_db": false,
                "title_case": false
              },
              "top_k": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_k",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Limits token selection to top K. (Default: 40)",
                "load_from_db": false,
                "title_case": false
              },
              "top_p": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_p",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "Works together with top-k. (Default: 0.9)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "verbose": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "verbose",
                "display_name": "Verbose",
                "advanced": false,
                "dynamic": false,
                "info": "Whether to print out response text.",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Generate text using Ollama Local LLMs.",
            "icon": "Ollama",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "Ollama",
            "documentation": "",
            "custom_fields": {
              "base_url": null,
              "model": null,
              "input_value": null,
              "mirostat": null,
              "mirostat_eta": null,
              "mirostat_tau": null,
              "repeat_last_n": null,
              "verbose": null,
              "keep_alive": null,
              "keep_alive_flag": null,
              "num_ctx": null,
              "num_gpu": null,
              "format": null,
              "metadata": null,
              "num_thread": null,
              "repeat_penalty": null,
              "stop": null,
              "system": null,
              "tags": null,
              "temperature": null,
              "template": null,
              "tfs_z": null,
              "timeout": null,
              "top_k": null,
              "top_p": null,
              "stream": null,
              "system_message": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [
              "base_url",
              "headers",
              "keep_alive_flag",
              "keep_alive",
              "metadata",
              "model",
              "temperature",
              "cache",
              "format",
              "metadata",
              "mirostat",
              "mirostat_eta",
              "mirostat_tau",
              "num_ctx",
              "num_gpu",
              "num_thread",
              "repeat_last_n",
              "repeat_penalty",
              "tfs_z",
              "timeout",
              "top_k",
              "top_p",
              "verbose",
              "tags",
              "stop",
              "system",
              "template",
              "input_value",
              "system_message",
              "stream"
            ],
            "beta": false
          },
          "id": "OllamaModel-Ncr0x"
        },
        "selected": false,
        "width": 384,
        "height": 1011,
        "positionAbsolute": {
          "x": -36.75693357738453,
          "y": -651.4568850108401
        },
        "dragging": false
      },
      {
        "id": "TextOutput-IX5aw",
        "type": "genericNode",
        "position": {
          "x": 447.6504248116242,
          "y": 81.68635528150406
        },
        "data": {
          "type": "TextOutput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "Text or Record to be passed as output.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: Optional[str] = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextOutput-IX5aw"
        },
        "selected": false,
        "width": 384,
        "height": 297,
        "positionAbsolute": {
          "x": 447.6504248116242,
          "y": 81.68635528150406
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Prompt-key40",
        "sourceHandle": "{baseClasses:[Prompt,Record],dataType:Prompt,id:Prompt-key40}",
        "target": "OllamaModel-Ncr0x",
        "targetHandle": "{fieldName:input_value,id:OllamaModel-Ncr0x,inputTypes:[Text,Record,Prompt],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OllamaModel-Ncr0x",
            "inputTypes": [
              "Text",
              "Record",
              "Prompt"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "Prompt",
              "Record"
            ],
            "dataType": "Prompt",
            "id": "Prompt-key40"
          }
        },
        "id": "reactflow__edge-Prompt-key40{baseClasses:[Prompt,Record],dataType:Prompt,id:Prompt-key40}-OllamaModel-Ncr0x{fieldName:input_value,id:OllamaModel-Ncr0x,inputTypes:[Text,Record,Prompt],type:str}",
        "className": ""
      },
      {
        "source": "OllamaModel-Ncr0x",
        "sourceHandle": "{baseClasses:[object,str,Text],dataType:OllamaModel,id:OllamaModel-Ncr0x}",
        "target": "TextOutput-IX5aw",
        "targetHandle": "{fieldName:input_value,id:TextOutput-IX5aw,inputTypes:[Record,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-IX5aw",
            "inputTypes": [
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "OllamaModel",
            "id": "OllamaModel-Ncr0x"
          }
        },
        "id": "reactflow__edge-OllamaModel-Ncr0x{baseClasses:[object,str,Text],dataType:OllamaModel,id:OllamaModel-Ncr0x}-TextOutput-IX5aw{fieldName:input_value,id:TextOutput-IX5aw,inputTypes:[Record,Text],type:str}"
      },
      {
        "source": "TextInput-iC8P2",
        "sourceHandle": "{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-iC8P2}",
        "target": "Prompt-key40",
        "targetHandle": "{fieldName:story,id:Prompt-key40,inputTypes:[Document,Message,Record,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "story",
            "id": "Prompt-key40",
            "inputTypes": [
              "Document",
              "Message",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "TextInput",
            "id": "TextInput-iC8P2"
          }
        },
        "id": "reactflow__edge-TextInput-iC8P2{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-iC8P2}-Prompt-key40{fieldName:story,id:Prompt-key40,inputTypes:[Document,Message,Record,Text],type:str}"
      }
    ],
    "viewport": {
      "x": 1509.6513718394779,
      "y": 536.7500961920451,
      "zoom": 1.0000000000000016
    }
  },
  "metadata": {
    "Prompt": {
      "count": 1
    },
    "TextInput": {
      "count": 1
    },
    "OllamaModel": {
      "count": 1
    },
    "TextOutput": {
      "count": 1
    },
    "total": 4
  },
  "original": {
    "id": "de9eeda0-7031-4c1b-8730-e5ecf4be90e5",
    "name": "test",
    "description": "Harness the Power of Conversational AI.",
    "is_component": false,
    "liked_by_count": "1",
    "downloads_count": "5",
    "metadata": {
      "Prompt": {
        "count": 1
      },
      "TextInput": {
        "count": 1
      },
      "OllamaModel": {
        "count": 1
      },
      "TextOutput": {
        "count": 1
      },
      "total": 4
    },
    "last_tested_version": "1.0.0a55",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "Prompt-key40",
          "type": "genericNode",
          "position": {
            "x": -542.8707199548459,
            "y": -141.65184805333627
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import TemplateField\nfrom axiestudio.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "prompt",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "Instruction:\n\nYou are a highly intelligent language model capable of understanding and analyzing stories. Your task is to extract distinct scenes from the provided story. A scene is a segment of the story where specific events happen in a specific setting, focusing on the environment and surroundings. Identify and describe each scene clearly, specifying the key elements of the setting without mentioning any characters or entities. Additionally, provide the word number where each scene starts.\n\nStory:\n\n{story}\n\nJSON Output:",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent",
                "story": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "story",
                  "display_name": "story",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Message",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Prompt",
                "Record"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "story"
                ]
              },
              "output_types": [
                "Prompt"
              ],
              "full_path": null,
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false,
              "error": null
            },
            "id": "Prompt-key40",
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt"
          },
          "selected": false,
          "width": 384,
          "height": 419,
          "positionAbsolute": {
            "x": -542.8707199548459,
            "y": -141.65184805333627
          },
          "dragging": false
        },
        {
          "id": "TextInput-iC8P2",
          "type": "genericNode",
          "position": {
            "x": -1010.638950648054,
            "y": -38.219925301801666
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "In the bustling city of Elaris, where towering skyscrapers kissed the clouds and neon lights painted the night, lived a young architect named Alex. Alex had always dreamt of designing a building that would stand as a symbol of innovation and creativity. One evening, while sketching ideas in his studio, he received a mysterious package. Inside was an old, leather-bound journal filled with intricate designs and notes, some written in an ancient language. Intrigued, Alex began to decipher the journal, uncovering plans for a unique structure that seemed to defy the laws of physics.  Determined to bring these designs to life, Alex presented the idea to his firm. However, his colleagues and superiors dismissed it as fantasy. Undeterred, Alex decided to pursue the project independently. He gathered a small team of like-minded individuals, including Elena, a brilliant engineer; Marcus, a skilled craftsman; and Dr. Lila, a historian specializing in ancient languages. Together, they worked tirelessly to understand and refine the designs from the journal.  Their journey took them to various parts of the world, from ancient ruins in Greece to hidden temples in South America, where they sought to uncover more information about the mysterious architect who had originally conceived the designs. Each location brought new challenges and discoveries. In Greece, they found a hidden chamber beneath an old temple, filled with more detailed blueprints and a strange, glowing artifact. In South America, they uncovered ancient tablets that revealed the structure was meant to harness a unique form of energy, capable of providing limitless power.  As they pieced together the puzzle, Alex and his team faced numerous obstacles. Rival corporations, sensing the potential of their discovery, tried to sabotage their efforts. Natural disasters, including a powerful earthquake, threatened to destroy their work. Despite these setbacks, their bond grew stronger, and their resolve never wavered.  Finally, after months of relentless effort, they returned to Elaris with all the knowledge and resources they needed. The construction of the building began, and the city's residents watched in awe as the structure rose, seemingly defying gravity with its elegant curves and floating platforms. It wasn't long before the media caught wind of the project, dubbing it \"The Beacon of Elaris.\"  As the building neared completion, Alex made a startling discovery. Hidden within the journal was a final, cryptic message from the original architect, hinting at a hidden chamber within the building that contained a secret of immense power. On the night of the grand unveiling, Alex and his team ventured into the building, deciphering the clues to find the hidden chamber. Inside, they discovered a powerful energy source, unlike anything they had ever seen.  Realizing the potential dangers and benefits of such a discovery, Alex decided to keep the chamber a secret, using the energy source to power the building and provide clean energy to the city without revealing its existence to the world. The Beacon of Elaris stood as a testament to human ingenuity and the power of perseverance, inspiring generations to come.  Years later, as Alex stood atop the building, looking out over the city, he couldn't help but feel a sense of fulfillment. The journey had been long and arduous, but the result was worth every challenge they had faced. The Beacon of Elaris had become a symbol of hope and innovation, a shining example of what could be achieved when one dared to dream and never gave up.",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "Text or Record to be passed as input.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "Text Input",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "record_template": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "TextInput-iC8P2"
          },
          "selected": true,
          "width": 384,
          "height": 297,
          "positionAbsolute": {
            "x": -1010.638950648054,
            "y": -38.219925301801666
          },
          "dragging": false
        },
        {
          "id": "OllamaModel-Ncr0x",
          "type": "genericNode",
          "position": {
            "x": -36.75693357738453,
            "y": -651.4568850108401
          },
          "data": {
            "type": "OllamaModel",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Text",
                    "Record",
                    "Prompt"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "stop": {
                  "type": "list",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "stop",
                  "display_name": "Stop Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "List of tokens to signal the model to stop generating text.",
                  "load_from_db": false,
                  "title_case": false
                },
                "tags": {
                  "type": "list",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tags",
                  "display_name": "Tags",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tags to add to the run trace.",
                  "load_from_db": false,
                  "title_case": false
                },
                "base_url": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "base_url",
                  "display_name": "Base URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "http://127.0.0.1:11434/"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any, Dict, List, Optional\n\nimport httpx\nfrom langchain_community.chat_models.ollama import ChatOllama\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Text\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    field_order = [\n        \"base_url\",\n        \"headers\",\n        \"keep_alive_flag\",\n        \"keep_alive\",\n        \"metadata\",\n        \"model\",\n        \"temperature\",\n        \"cache\",\n        \"format\",\n        \"metadata\",\n        \"mirostat\",\n        \"mirostat_eta\",\n        \"mirostat_tau\",\n        \"num_ctx\",\n        \"num_gpu\",\n        \"num_thread\",\n        \"repeat_last_n\",\n        \"repeat_penalty\",\n        \"tfs_z\",\n        \"timeout\",\n        \"top_k\",\n        \"top_p\",\n        \"verbose\",\n        \"tags\",\n        \"stop\",\n        \"system\",\n        \"template\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"info\": \"Specify the format of the output (e.g., json)\",\n                \"advanced\": True,\n            },\n            \"headers\": {\n                \"display_name\": \"Headers\",\n                \"advanced\": True,\n            },\n            \"keep_alive_flag\": {\n                \"display_name\": \"Unload interval\",\n                \"options\": [\"Keep\", \"Immediately\", \"Minute\", \"Hour\", \"sec\"],\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"keep_alive\": {\n                \"display_name\": \"interval\",\n                \"info\": \"How long the model will stay loaded into memory.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"options\": [],\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"advanced\": False,\n                \"real_time_refresh\": True,\n                \"refresh_button\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n                \"real_time_refresh\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n                \"real_time_refresh\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name == \"model\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:11434\"\n            build_config[\"model\"][\"options\"] = self.get_model(base_url_value + \"/api/tags\")\n\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    def get_model(self, url: str) -> List[str]:\n        try:\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                model_names = [model[\"name\"] for model in data.get(\"models\", [])]\n                return model_names\n        except Exception as e:\n            raise ValueError(\"Could not retrieve models\") from e\n            return [\"\"]\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        input_value: Text,\n        mirostat: Optional[str] = \"Disabled\",\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        keep_alive: Optional[int] = None,\n        keep_alive_flag: Optional[str] = \"Keep\",\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        if keep_alive_flag == \"Minute\":\n            keep_alive_instance = f\"{keep_alive}m\"\n        elif keep_alive_flag == \"Hour\":\n            keep_alive_instance = f\"{keep_alive}h\"\n        elif keep_alive_flag == \"sec\":\n            keep_alive_instance = f\"{keep_alive}s\"\n        elif keep_alive_flag == \"Keep\":\n            keep_alive_instance = \"-1\"\n        elif keep_alive_flag == \"Immediately\":\n            keep_alive_instance = \"0\"\n        else:\n            keep_alive_instance = \"Invalid option\"\n\n        mirostat_instance = 0\n\n        if mirostat == \"disable\":\n            mirostat_instance = 0\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"model\": model,\n            \"mirostat\": mirostat_instance,\n            \"keep_alive\": keep_alive_instance,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "format": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "format",
                  "display_name": "Format",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Specify the format of the output (e.g., json)",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "keep_alive": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "keep_alive",
                  "display_name": "interval",
                  "advanced": false,
                  "dynamic": false,
                  "info": "How long the model will stay loaded into memory.",
                  "load_from_db": false,
                  "title_case": false,
                  "value": "0"
                },
                "keep_alive_flag": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Keep",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Keep",
                    "Immediately",
                    "Minute",
                    "Hour",
                    "sec"
                  ],
                  "name": "keep_alive_flag",
                  "display_name": "Unload interval",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "metadata": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "metadata",
                  "display_name": "Metadata",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Metadata to add to the run trace.",
                  "load_from_db": false,
                  "title_case": false
                },
                "mirostat": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Disabled",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Disabled",
                    "Mirostat",
                    "Mirostat 2.0"
                  ],
                  "name": "mirostat",
                  "display_name": "Mirostat",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "mirostat_eta": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_eta",
                  "display_name": "Mirostat Eta",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                  "real_time_refresh": true,
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "mirostat_tau": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_tau",
                  "display_name": "Mirostat Tau",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                  "real_time_refresh": true,
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "model": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "llama3:latest"
                  ],
                  "name": "model",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Refer to https://ollama.ai/library for more models.",
                  "real_time_refresh": true,
                  "refresh_button": true,
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "llama3:latest"
                },
                "num_ctx": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_ctx",
                  "display_name": "Context Window Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Size of the context window for generating tokens. (Default: 2048)",
                  "load_from_db": false,
                  "title_case": false
                },
                "num_gpu": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_gpu",
                  "display_name": "Number of GPUs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                  "load_from_db": false,
                  "title_case": false
                },
                "num_thread": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_thread",
                  "display_name": "Number of Threads",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                  "load_from_db": false,
                  "title_case": false
                },
                "repeat_last_n": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_last_n",
                  "display_name": "Repeat Last N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                  "load_from_db": false,
                  "title_case": false
                },
                "repeat_penalty": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_penalty",
                  "display_name": "Repeat Penalty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "stream": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "load_from_db": false,
                  "title_case": false
                },
                "system": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "system",
                  "display_name": "System",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System to use for generating text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "system_message": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.8,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Controls the creativity of model responses.",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to use for generating text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "tfs_z": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tfs_z",
                  "display_name": "TFS Z",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tail free sampling value. (Default: 1)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "timeout": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Timeout for the request stream.",
                  "load_from_db": false,
                  "title_case": false
                },
                "top_k": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_k",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limits token selection to top K. (Default: 40)",
                  "load_from_db": false,
                  "title_case": false
                },
                "top_p": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_p",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Works together with top-k. (Default: 0.9)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "verbose": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "verbose",
                  "display_name": "Verbose",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether to print out response text.",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent"
              },
              "description": "Generate text using Ollama Local LLMs.",
              "icon": "Ollama",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "Ollama",
              "documentation": "",
              "custom_fields": {
                "base_url": null,
                "model": null,
                "input_value": null,
                "mirostat": null,
                "mirostat_eta": null,
                "mirostat_tau": null,
                "repeat_last_n": null,
                "verbose": null,
                "keep_alive": null,
                "keep_alive_flag": null,
                "num_ctx": null,
                "num_gpu": null,
                "format": null,
                "metadata": null,
                "num_thread": null,
                "repeat_penalty": null,
                "stop": null,
                "system": null,
                "tags": null,
                "temperature": null,
                "template": null,
                "tfs_z": null,
                "timeout": null,
                "top_k": null,
                "top_p": null,
                "stream": null,
                "system_message": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [
                "base_url",
                "headers",
                "keep_alive_flag",
                "keep_alive",
                "metadata",
                "model",
                "temperature",
                "cache",
                "format",
                "metadata",
                "mirostat",
                "mirostat_eta",
                "mirostat_tau",
                "num_ctx",
                "num_gpu",
                "num_thread",
                "repeat_last_n",
                "repeat_penalty",
                "tfs_z",
                "timeout",
                "top_k",
                "top_p",
                "verbose",
                "tags",
                "stop",
                "system",
                "template",
                "input_value",
                "system_message",
                "stream"
              ],
              "beta": false
            },
            "id": "OllamaModel-Ncr0x"
          },
          "selected": false,
          "width": 384,
          "height": 1011,
          "positionAbsolute": {
            "x": -36.75693357738453,
            "y": -651.4568850108401
          },
          "dragging": false
        },
        {
          "id": "TextOutput-IX5aw",
          "type": "genericNode",
          "position": {
            "x": 447.6504248116242,
            "y": 81.68635528150406
          },
          "data": {
            "type": "TextOutput",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "Text or Record to be passed as output.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: Optional[str] = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Display a text output in the Playground.",
              "icon": "type",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "Text Output",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "record_template": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "TextOutput-IX5aw"
          },
          "selected": false,
          "width": 384,
          "height": 297,
          "positionAbsolute": {
            "x": 447.6504248116242,
            "y": 81.68635528150406
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Prompt-key40",
          "sourceHandle": "{baseClasses:[Prompt,Record],dataType:Prompt,id:Prompt-key40}",
          "target": "OllamaModel-Ncr0x",
          "targetHandle": "{fieldName:input_value,id:OllamaModel-Ncr0x,inputTypes:[Text,Record,Prompt],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OllamaModel-Ncr0x",
              "inputTypes": [
                "Text",
                "Record",
                "Prompt"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "Prompt",
                "Record"
              ],
              "dataType": "Prompt",
              "id": "Prompt-key40"
            }
          },
          "id": "reactflow__edge-Prompt-key40{baseClasses:[Prompt,Record],dataType:Prompt,id:Prompt-key40}-OllamaModel-Ncr0x{fieldName:input_value,id:OllamaModel-Ncr0x,inputTypes:[Text,Record,Prompt],type:str}",
          "className": ""
        },
        {
          "source": "OllamaModel-Ncr0x",
          "sourceHandle": "{baseClasses:[object,str,Text],dataType:OllamaModel,id:OllamaModel-Ncr0x}",
          "target": "TextOutput-IX5aw",
          "targetHandle": "{fieldName:input_value,id:TextOutput-IX5aw,inputTypes:[Record,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "TextOutput-IX5aw",
              "inputTypes": [
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "OllamaModel",
              "id": "OllamaModel-Ncr0x"
            }
          },
          "id": "reactflow__edge-OllamaModel-Ncr0x{baseClasses:[object,str,Text],dataType:OllamaModel,id:OllamaModel-Ncr0x}-TextOutput-IX5aw{fieldName:input_value,id:TextOutput-IX5aw,inputTypes:[Record,Text],type:str}"
        },
        {
          "source": "TextInput-iC8P2",
          "sourceHandle": "{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-iC8P2}",
          "target": "Prompt-key40",
          "targetHandle": "{fieldName:story,id:Prompt-key40,inputTypes:[Document,Message,Record,Text],type:str}",
          "data": {
            "targetHandle": {
              "fieldName": "story",
              "id": "Prompt-key40",
              "inputTypes": [
                "Document",
                "Message",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "TextInput",
              "id": "TextInput-iC8P2"
            }
          },
          "id": "reactflow__edge-TextInput-iC8P2{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-iC8P2}-Prompt-key40{fieldName:story,id:Prompt-key40,inputTypes:[Document,Message,Record,Text],type:str}"
        }
      ],
      "viewport": {
        "x": 1509.6513718394779,
        "y": 536.7500961920451,
        "zoom": 1.0000000000000016
      }
    },
    "date_created": "2024-06-14T14:43:21.889Z",
    "date_updated": "2024-06-14T14:58:03.360Z",
    "status": "Public",
    "sort": null,
    "user_updated": "53ee5d46-377b-42e0-ad7e-9c9615eb74c2",
    "user_created": {
      "username": "schobiwalter",
      "first_name": "Felix",
      "last_name": "Schoberwalter",
      "id": "53ee5d46-377b-42e0-ad7e-9c9615eb74c2"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.827Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 20,
    "converter_version": "1.0.0"
  }
}