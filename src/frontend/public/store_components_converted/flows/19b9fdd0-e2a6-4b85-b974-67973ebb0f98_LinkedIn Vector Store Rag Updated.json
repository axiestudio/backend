{
  "id": "19b9fdd0-e2a6-4b85-b974-67973ebb0f98",
  "name": "LinkedIn Vector Store Rag Updated",
  "description": "This component reads content from a specified file (CSV, JSON, or TXT), extracts URLs, and fetches their corresponding webpage content. It then utilizes OpenAI's LLM to extract structured metadata from the fetched content, returning a list of enriched data objects for further processing (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "SahilSapte",
    "first_name": "Sahil",
    "last_name": "Sapte",
    "id": "694f46e0-3805-4a2c-9852-cd3f52377859",
    "full_name": "Sahil Sapte"
  },
  "store_url": "https://www.langflow.store/store/component/19b9fdd0-e2a6-4b85-b974-67973ebb0f98",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-04T10:16:54.301Z",
    "updated": "2024-10-04T10:16:54.498Z",
    "downloaded": "2025-08-19T17:50:07.430Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "Chroma-tqgXG",
        "type": "genericNode",
        "position": {
          "x": 1079.833636986872,
          "y": 136.29324102690651
        },
        "data": {
          "type": "Chroma",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "allow_duplicates": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_duplicates",
                "value": false,
                "display_name": "Allow Duplicates",
                "advanced": true,
                "dynamic": false,
                "info": "If false, will not add documents that are already in the Vector Store.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "chroma_server_cors_allow_origins": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_cors_allow_origins",
                "value": "",
                "display_name": "Server CORS Allow Origins",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "chroma_server_grpc_port": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_grpc_port",
                "value": "",
                "display_name": "Server gRPC Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chroma_server_host": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_host",
                "value": "",
                "display_name": "Server Host",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "chroma_server_http_port": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_http_port",
                "value": "",
                "display_name": "Server HTTP Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chroma_server_ssl_enabled": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chroma_server_ssl_enabled",
                "value": false,
                "display_name": "Server SSL Enabled",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.base.vectorstores.utils import chroma_collection_to_data\nfrom axiestudio.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom axiestudio.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"axiestudio\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "axiestudio",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "limit": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "limit",
                "value": "",
                "display_name": "Limit",
                "advanced": true,
                "dynamic": false,
                "info": "Limit the number of records to compare when Allow Duplicates is False.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 10,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "persist_directory",
                "value": "C:\\Users\\sahil\\OneDrive\\Desktop\\internship\\axiestudio",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "search_type": {
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "MMR"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_type",
                "value": "Similarity",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Chroma Vector Store with search capabilities",
            "icon": "Chroma",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "Chroma DB",
            "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "collection_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "embedding",
              "chroma_server_cors_allow_origins",
              "chroma_server_host",
              "chroma_server_http_port",
              "chroma_server_grpc_port",
              "chroma_server_ssl_enabled",
              "allow_duplicates",
              "search_type",
              "number_of_results",
              "limit"
            ],
            "beta": false,
            "edited": false
          },
          "id": "Chroma-tqgXG"
        },
        "selected": false,
        "width": 384,
        "height": 653,
        "positionAbsolute": {
          "x": 1079.833636986872,
          "y": 136.29324102690651
        },
        "dragging": false
      },
      {
        "id": "RecursiveCharacterTextSplitter-jBqJZ",
        "type": "genericNode",
        "position": {
          "x": 515.5040103904057,
          "y": -99.13306811944449
        },
        "data": {
          "type": "RecursiveCharacterTextSplitter",
          "node": {
            "template": {
              "_type": "Component",
              "data_input": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_input",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Data"
                ],
                "dynamic": false,
                "info": "The texts to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom axiestudio.base.textsplitters.model import LCTextSplitterComponent\nfrom axiestudio.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom axiestudio.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separators": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separators",
                "value": "",
                "display_name": "Separators",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text trying to keep all related text together.",
            "base_classes": [
              "Data"
            ],
            "display_name": "Recursive Character Text Splitter",
            "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "split_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "chunk_size",
              "chunk_overlap",
              "data_input",
              "separators"
            ],
            "beta": false,
            "edited": false
          },
          "id": "RecursiveCharacterTextSplitter-jBqJZ"
        },
        "selected": false,
        "width": 384,
        "height": 515,
        "positionAbsolute": {
          "x": 515.5040103904057,
          "y": -99.13306811944449
        },
        "dragging": false
      },
      {
        "id": "CohereEmbeddings-3IoMM",
        "type": "genericNode",
        "position": {
          "x": 442.8887226659634,
          "y": 553.3211133188571
        },
        "data": {
          "type": "CohereEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"cohere_api_key\", display_name=\"Cohere API Key\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=self.cohere_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "cohere_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cohere_api_key",
                "value": "",
                "display_name": "Cohere API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "embed-english-v2.0",
                  "embed-multilingual-v2.0",
                  "embed-english-light-v2.0",
                  "embed-multilingual-light-v2.0"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "embed-english-v2.0",
                "display_name": "Model",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "truncate": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "truncate",
                "value": "",
                "display_name": "Truncate",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_agent": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_agent",
                "value": "langchain",
                "display_name": "User Agent",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using Cohere models.",
            "icon": "Cohere",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Cohere Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cohere_api_key",
              "model",
              "truncate",
              "max_retries",
              "user_agent",
              "request_timeout"
            ],
            "beta": false,
            "edited": false
          },
          "id": "CohereEmbeddings-3IoMM"
        },
        "selected": false,
        "width": 384,
        "height": 296,
        "positionAbsolute": {
          "x": 442.8887226659634,
          "y": 553.3211133188571
        },
        "dragging": false
      },
      {
        "id": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba",
        "type": "genericNode",
        "position": {
          "x": -118.4211792171294,
          "y": -79.97852769744964
        },
        "data": {
          "type": "CreateListFromFileWithURLParsingAndMetadataExtraction",
          "node": {
            "template": {
              "_type": "Component",
              "file_path": {
                "trace_as_metadata": true,
                "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-10-04_15-32-32_Saved_Items.csv",
                "fileTypes": [
                  "csv",
                  "json",
                  "txt"
                ],
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "",
                "display_name": "File Path",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "api_key": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nimport pandas as pd\r\nimport json\r\nimport os\r\nimport asyncio\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\nfrom datetime import datetime\r\nimport logging\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain.schema import SystemMessage, HumanMessage  # Imported message classes\r\n\r\n# Set up logging\r\nlogging.basicConfig(\r\n    level=logging.INFO,\r\n    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',\r\n    handlers=[\r\n        logging.FileHandler(\"component.log\"),\r\n        logging.StreamHandler()\r\n    ]\r\n)\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass CreateListComponent(Component):\r\n    display_name = \"Create List from File with URL Parsing and Metadata Extraction\"\r\n    description = \"Creates a list of texts from a file, fetches content from URLs if present, and extracts metadata using OpenAI's LLM.\"\r\n    icon = \"list\"\r\n    name = \"CreateListFromFileWithURLParsingAndMetadataExtraction\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n        SecretStrInput(  # Input for OpenAI API Key\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"Ensures the given string is a valid URL.\"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)\"\r\n            r\"(www\\.)?\"\r\n            r\"([a-zA-Z0-9.-]+)\"\r\n            r\"(\\.[a-zA-Z]{2,})\"\r\n            r\"(:\\d+)?\"\r\n            r\"(\\/[^\\s]*)?$\",\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    async def generate_prompt(self, content: str) -> str:\r\n        \"\"\"Constructs a prompt for the LLM to extract metadata from URL content.\"\"\"\r\n        prompt = f\"\"\"\r\n        You are a helpful assistant. Given the following URL and webpage content, extract metadata.\r\n\r\n\r\n        Content: {content}\r\n\r\n        Please return only the data in the following structured JSON format without any additional text:\r\n\r\n        {{\r\n            \"name\": \"The name of the webpage or article\",\r\n            \"number_of_likes\": 0,  # The number of likes (if available)\r\n            \"comments\": [],  # List of comments (if available)\r\n            \"author\": \"Author of the content (if available)\",\r\n            \"publication_date\": \"YYYY-MM-DD\"  # Publication date in YYYY-MM-DD format (if available)\r\n        }}\r\n\r\n        If any information is missing, set the field to an empty string or an empty list, as appropriate.\r\n\r\n        Example:\r\n        {{\r\n            \"name\": \"Example Article\",\r\n            \"number_of_likes\": 100,\r\n            \"comments\": [\"Great article!\", \"Very informative.\"],\r\n            \"author\": \"Jane Doe\",\r\n            \"publication_date\": \"2023-08-15\"\r\n        }}\r\n        \"\"\"\r\n        return prompt\r\n\r\n    async def generate_metadata_from_url_and_content(self, url: str, content: str) -> dict:\r\n        \"\"\"Uses an LLM to extract metadata by passing both the URL and content.\"\"\"\r\n        prompt = await self.generate_prompt(content)\r\n        metadata_str = \"\"  # Initialize to ensure it's always defined\r\n\r\n        try:\r\n            # Initialize ChatOpenAI with parameters\r\n            chat_openai = ChatOpenAI(\r\n                model=\"gpt-4\",\r\n                temperature=0.1,  # Default temperature; adjust as needed\r\n                max_tokens=500,\r\n                api_key=self.api_key,  # Use the API key directly as a string\r\n            )\r\n\r\n            # Construct messages using proper message classes\r\n            messages = [\r\n                SystemMessage(content=\"You are a helpful assistant.\"),\r\n                HumanMessage(content=prompt)\r\n            ]\r\n\r\n            # Make an asynchronous call to the LLM with a list of message lists\r\n            response = await chat_openai.agenerate([messages])\r\n\r\n            # Access the generated text\r\n            metadata_str = response.generations[0][0].text.strip()\r\n            \r\n            # Extract JSON using regex to find the first JSON object in the response\r\n            json_match = re.search(r'\\{.*\\}', metadata_str, re.DOTALL)\r\n            if json_match:\r\n                metadata_str = json_match.group()\r\n            else:\r\n                raise ValueError(\"No JSON object found in the LLM response.\")\r\n\r\n            metadata = json.loads(metadata_str)\r\n\r\n            return {\r\n              \r\n                \"name\": metadata.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": int(metadata.get(\"number_of_likes\", 0)) if isinstance(metadata.get(\"number_of_likes\", 0), (int, float, str)) else 0,\r\n                \"comments\": metadata.get(\"comments\", []),\r\n                \"author\": metadata.get(\"author\", \"Unknown\"),\r\n                \"publication_date\": metadata.get(\"publication_date\", \"\")\r\n            }\r\n\r\n        except json.JSONDecodeError as jde:\r\n            logger.error(f\"JSON decoding failed for URL {url}: {jde}\")\r\n            logger.debug(f\"LLM Response: {metadata_str}\")\r\n            return {\r\n              \r\n                \"name\": \"Unknown\",\r\n                \"number_of_likes\": 0,\r\n                \"comments\": [],\r\n                \"author\": \"Unknown\",\r\n                \"publication_date\": \"\"\r\n            }\r\n        except Exception as e:\r\n            logger.error(f\"An error occurred while generating metadata for URL {url}: {e}\")\r\n            return {\r\n                \r\n                \"name\": \"Unknown\",\r\n                \"number_of_likes\": 0,\r\n                \"comments\": [],\r\n                \"author\": \"Unknown\",\r\n                \"publication_date\": \"\"\r\n            }\r\n\r\n    async def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from the provided URLs and uses LLM for metadata extraction.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        data_list = []\r\n\r\n        logger.info(f\"Fetched {len(docs)} documents from URLs.\")\r\n        url_docs=zip(docs,urls)\r\n        # Loop through each document\r\n        for doc,link in url_docs:\r\n            url = link\r\n            content = doc.page_content\r\n            logger.info(f\"Processing URL: {url}\")\r\n\r\n            metadata = await self.generate_metadata_from_url_and_content(url, content)\r\n            \r\n            # Create a Data object with the metadata returned from the LLM\r\n            data = Data(\r\n                text=content,\r\n                url=url,\r\n                timestamp=datetime.utcnow().isoformat(),\r\n                name=metadata.get(\"name\"),\r\n                number_of_likes=str(metadata.get(\"number_of_likes\", 0)),\r\n                comments=metadata.get(\"comments\", []),\r\n                author=metadata.get(\"author\", \"Unknown\"),\r\n                publication_date=metadata.get(\"publication_date\", \"\")\r\n            )\r\n            data_list.append(data)\r\n\r\n        return data_list\r\n\r\n    async def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        \r\n        # Determine file type and parse accordingly\r\n        if self.file_path.endswith(\".csv\"):\r\n            logger.info(f\"Processing CSV file: {self.file_path}\")\r\n            df = pd.read_csv(self.file_path)\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n                logger.info(f\"Extracted texts from column '{self.column_name}'.\")\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n                logger.info(f\"No column specified or column not found. Extracted all lines as texts.\")\r\n        elif self.file_path.endswith(\".json\"):\r\n            logger.info(f\"Processing JSON file: {self.file_path}\")\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                    logger.info(f\"Extracted texts from key '{self.column_name}'.\")\r\n                else:\r\n                    texts = [json.dumps(json_data)]\r\n                    logger.info(f\"No key specified or key not found. Serialized entire JSON object as a single text entry.\")\r\n        else:\r\n            logger.info(f\"Processing TXT file: {self.file_path}\")\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n            logger.info(f\"Extracted {len(texts)} lines from TXT file.\")\r\n\r\n        # Separate URLs from regular text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n                logger.info(f\"Identified URL: {text}\")\r\n            else:\r\n                logger.info(f\"Non-URL text found and skipped: {text}\")\r\n\r\n        # If URLs are present, fetch their content and extract metadata\r\n        if urls:\r\n            fetched_data = await self.fetch_url_content(urls)\r\n            data_list.extend(fetched_data)\r\n            logger.info(f\"Added {len(fetched_data)} Data objects from URLs.\")\r\n        else:\r\n            logger.warning(\"No URLs found in the input file.\")\r\n\r\n        self.status = data_list\r\n        logger.info(\"Data list creation completed.\")\r\n        return data_list\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "column_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "column_name",
                "value": "savedItem",
                "display_name": "Column Name (for CSV/JSON)",
                "advanced": false,
                "dynamic": false,
                "info": "Specify the column name if using CSV or JSON files.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Creates a list of texts from a file, fetches content from URLs if present, and extracts metadata using OpenAI's LLM.",
            "icon": "list",
            "base_classes": [
              "Data"
            ],
            "display_name": "Create List",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "list",
                "display_name": "Data List",
                "method": "create_list",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_path",
              "column_name",
              "api_key"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba"
        },
        "selected": false,
        "width": 384,
        "height": 523,
        "positionAbsolute": {
          "x": -118.4211792171294,
          "y": -79.97852769744964
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "RecursiveCharacterTextSplitter-jBqJZ",
        "sourceHandle": "{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}",
        "target": "Chroma-tqgXG",
        "targetHandle": "{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "Chroma-tqgXG",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "RecursiveCharacterTextSplitter",
            "id": "RecursiveCharacterTextSplitter-jBqJZ",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-RecursiveCharacterTextSplitter-jBqJZ{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}-Chroma-tqgXG{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
        "className": ""
      },
      {
        "source": "CohereEmbeddings-3IoMM",
        "sourceHandle": "{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}",
        "target": "Chroma-tqgXG",
        "targetHandle": "{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Chroma-tqgXG",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CohereEmbeddings",
            "id": "CohereEmbeddings-3IoMM",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-CohereEmbeddings-3IoMM{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}-Chroma-tqgXG{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
        "className": ""
      },
      {
        "source": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba",
        "sourceHandle": "{dataType:CreateListFromFileWithURLParsingAndMetadataExtraction,id:CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba,name:list,output_types:[Data]}",
        "target": "RecursiveCharacterTextSplitter-jBqJZ",
        "targetHandle": "{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data_input",
            "id": "RecursiveCharacterTextSplitter-jBqJZ",
            "inputTypes": [
              "Document",
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CreateListFromFileWithURLParsingAndMetadataExtraction",
            "id": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba",
            "name": "list",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba{dataType:CreateListFromFileWithURLParsingAndMetadataExtraction,id:CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba,name:list,output_types:[Data]}-RecursiveCharacterTextSplitter-jBqJZ{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 314.4154753960768,
      "y": 77.44848851731638,
      "zoom": 0.48085212666200444
    }
  },
  "metadata": {
    "Chroma": {
      "count": 1
    },
    "RecursiveCharacterTextSplitter": {
      "count": 1
    },
    "CohereEmbeddings": {
      "count": 1
    },
    "CreateListFromFileWithURLParsingAndMetadataExtraction": {
      "count": 1
    },
    "total": 4
  },
  "original": {
    "id": "19b9fdd0-e2a6-4b85-b974-67973ebb0f98",
    "name": "LinkedIn Vector Store Rag Updated",
    "description": "This component reads content from a specified file (CSV, JSON, or TXT), extracts URLs, and fetches their corresponding webpage content. It then utilizes OpenAI's LLM to extract structured metadata from the fetched content, returning a list of enriched data objects for further processing",
    "is_component": false,
    "liked_by_count": "7",
    "downloads_count": "69",
    "metadata": {
      "Chroma": {
        "count": 1
      },
      "RecursiveCharacterTextSplitter": {
        "count": 1
      },
      "CohereEmbeddings": {
        "count": 1
      },
      "CreateListFromFileWithURLParsingAndMetadataExtraction": {
        "count": 1
      },
      "total": 4
    },
    "last_tested_version": "1.0.17",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "Chroma-tqgXG",
          "type": "genericNode",
          "position": {
            "x": 1079.833636986872,
            "y": 136.29324102690651
          },
          "data": {
            "type": "Chroma",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ingest_data",
                  "value": "",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "allow_duplicates": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_duplicates",
                  "value": false,
                  "display_name": "Allow Duplicates",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If false, will not add documents that are already in the Vector Store.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "chroma_server_cors_allow_origins": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_cors_allow_origins",
                  "value": "",
                  "display_name": "Server CORS Allow Origins",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "chroma_server_grpc_port": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_grpc_port",
                  "value": "",
                  "display_name": "Server gRPC Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chroma_server_host": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_host",
                  "value": "",
                  "display_name": "Server Host",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "chroma_server_http_port": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_http_port",
                  "value": "",
                  "display_name": "Server HTTP Port",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chroma_server_ssl_enabled": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chroma_server_ssl_enabled",
                  "value": false,
                  "display_name": "Server SSL Enabled",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma.vectorstores import Chroma\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.base.vectorstores.utils import chroma_collection_to_data\nfrom axiestudio.io import BoolInput, DataInput, DropdownInput, HandleInput, IntInput, StrInput, MultilineInput\nfrom axiestudio.schema import Data\n\nif TYPE_CHECKING:\n    from langchain_chroma import Chroma\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    Chroma Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"axiestudio\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"\n        Builds the Chroma object.\n        \"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError:\n            raise ImportError(\n                \"Could not import Chroma integration package. \" \"Please install it with `pip install langchain-chroma`.\"\n            )\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        if self.persist_directory is not None:\n            persist_directory = self.resolve_path(self.persist_directory)\n        else:\n            persist_directory = None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"\n        Adds documents to the Vector Store.\n        \"\"\"\n        if not self.ingest_data:\n            self.status = \"\"\n            return\n\n        _stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                _stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents and self.embedding is not None:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "collection_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "collection_name",
                  "value": "axiestudio",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "limit": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "limit",
                  "value": "",
                  "display_name": "Limit",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limit the number of records to compare when Allow Duplicates is False.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 10,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "persist_directory",
                  "value": "C:\\Users\\sahil\\OneDrive\\Desktop\\internship\\axiestudio",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "search_type": {
                  "trace_as_metadata": true,
                  "options": [
                    "Similarity",
                    "MMR"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_type",
                  "value": "Similarity",
                  "display_name": "Search Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                }
              },
              "description": "Chroma Vector Store with search capabilities",
              "icon": "Chroma",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "Chroma DB",
              "documentation": "https://python.langchain.com/docs/integrations/vectorstores/chroma",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "collection_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "embedding",
                "chroma_server_cors_allow_origins",
                "chroma_server_host",
                "chroma_server_http_port",
                "chroma_server_grpc_port",
                "chroma_server_ssl_enabled",
                "allow_duplicates",
                "search_type",
                "number_of_results",
                "limit"
              ],
              "beta": false,
              "edited": false
            },
            "id": "Chroma-tqgXG"
          },
          "selected": false,
          "width": 384,
          "height": 653,
          "positionAbsolute": {
            "x": 1079.833636986872,
            "y": 136.29324102690651
          },
          "dragging": false
        },
        {
          "id": "RecursiveCharacterTextSplitter-jBqJZ",
          "type": "genericNode",
          "position": {
            "x": 515.5040103904057,
            "y": -99.13306811944449
          },
          "data": {
            "type": "RecursiveCharacterTextSplitter",
            "node": {
              "template": {
                "_type": "Component",
                "data_input": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_input",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The texts to split.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "chunk_overlap": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_overlap",
                  "value": 200,
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The amount of overlap between chunks.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum length of each chunk.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\nfrom axiestudio.base.textsplitters.model import LCTextSplitterComponent\nfrom axiestudio.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom axiestudio.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separators": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "separators",
                  "value": "",
                  "display_name": "Separators",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Split text trying to keep all related text together.",
              "base_classes": [
                "Data"
              ],
              "display_name": "Recursive Character Text Splitter",
              "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "split_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "chunk_size",
                "chunk_overlap",
                "data_input",
                "separators"
              ],
              "beta": false,
              "edited": false
            },
            "id": "RecursiveCharacterTextSplitter-jBqJZ"
          },
          "selected": false,
          "width": 384,
          "height": 515,
          "positionAbsolute": {
            "x": 515.5040103904057,
            "y": -99.13306811944449
          },
          "dragging": false
        },
        {
          "id": "CohereEmbeddings-3IoMM",
          "type": "genericNode",
          "position": {
            "x": 442.8887226659634,
            "y": 553.3211133188571
          },
          "data": {
            "type": "CohereEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"cohere_api_key\", display_name=\"Cohere API Key\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=self.cohere_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "cohere_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cohere_api_key",
                  "value": "",
                  "display_name": "Cohere API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "max_retries": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_retries",
                  "value": 3,
                  "display_name": "Max Retries",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "embed-english-v2.0",
                    "embed-multilingual-v2.0",
                    "embed-english-light-v2.0",
                    "embed-multilingual-light-v2.0"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "embed-english-v2.0",
                  "display_name": "Model",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "request_timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "request_timeout",
                  "value": "",
                  "display_name": "Request Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "truncate": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "truncate",
                  "value": "",
                  "display_name": "Truncate",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user_agent": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_agent",
                  "value": "langchain",
                  "display_name": "User Agent",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generate embeddings using Cohere models.",
              "icon": "Cohere",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Cohere Embeddings",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cohere_api_key",
                "model",
                "truncate",
                "max_retries",
                "user_agent",
                "request_timeout"
              ],
              "beta": false,
              "edited": false
            },
            "id": "CohereEmbeddings-3IoMM"
          },
          "selected": false,
          "width": 384,
          "height": 296,
          "positionAbsolute": {
            "x": 442.8887226659634,
            "y": 553.3211133188571
          },
          "dragging": false
        },
        {
          "id": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba",
          "type": "genericNode",
          "position": {
            "x": -118.4211792171294,
            "y": -79.97852769744964
          },
          "data": {
            "type": "CreateListFromFileWithURLParsingAndMetadataExtraction",
            "node": {
              "template": {
                "_type": "Component",
                "file_path": {
                  "trace_as_metadata": true,
                  "file_path": "c4046d27-af41-4945-8170-238e75e596bf\\2024-10-04_15-32-32_Saved_Items.csv",
                  "fileTypes": [
                    "csv",
                    "json",
                    "txt"
                  ],
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "file_path",
                  "value": "",
                  "display_name": "File Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput",
                  "load_from_db": false
                },
                "api_key": {
                  "load_from_db": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nimport pandas as pd\r\nimport json\r\nimport os\r\nimport asyncio\r\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import StrInput, FileInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.template import Output\r\nfrom datetime import datetime\r\nimport logging\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain.schema import SystemMessage, HumanMessage  # Imported message classes\r\n\r\n# Set up logging\r\nlogging.basicConfig(\r\n    level=logging.INFO,\r\n    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',\r\n    handlers=[\r\n        logging.FileHandler(\"component.log\"),\r\n        logging.StreamHandler()\r\n    ]\r\n)\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass CreateListComponent(Component):\r\n    display_name = \"Create List from File with URL Parsing and Metadata Extraction\"\r\n    description = \"Creates a list of texts from a file, fetches content from URLs if present, and extracts metadata using OpenAI's LLM.\"\r\n    icon = \"list\"\r\n    name = \"CreateListFromFileWithURLParsingAndMetadataExtraction\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"file_path\",\r\n            display_name=\"File Path\",\r\n            file_types=[\"csv\", \"json\", \"txt\"],  # Allow different file types\r\n            required=True,\r\n        ),\r\n        StrInput(\r\n            name=\"column_name\",\r\n            display_name=\"Column Name (for CSV/JSON)\",\r\n            info=\"Specify the column name if using CSV or JSON files.\",\r\n            required=False,\r\n        ),\r\n        SecretStrInput(  # Input for OpenAI API Key\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\r\n    ]\r\n\r\n    def ensure_url(self, string: str) -> str:\r\n        \"\"\"Ensures the given string is a valid URL.\"\"\"\r\n        if not string.startswith((\"http://\", \"https://\")):\r\n            string = \"http://\" + string\r\n\r\n        # Basic URL validation regex\r\n        url_regex = re.compile(\r\n            r\"^(https?:\\/\\/)\"\r\n            r\"(www\\.)?\"\r\n            r\"([a-zA-Z0-9.-]+)\"\r\n            r\"(\\.[a-zA-Z]{2,})\"\r\n            r\"(:\\d+)?\"\r\n            r\"(\\/[^\\s]*)?$\",\r\n            re.IGNORECASE,\r\n        )\r\n\r\n        if not url_regex.match(string):\r\n            raise ValueError(f\"Invalid URL: {string}\")\r\n\r\n        return string\r\n\r\n    async def generate_prompt(self, content: str) -> str:\r\n        \"\"\"Constructs a prompt for the LLM to extract metadata from URL content.\"\"\"\r\n        prompt = f\"\"\"\r\n        You are a helpful assistant. Given the following URL and webpage content, extract metadata.\r\n\r\n\r\n        Content: {content}\r\n\r\n        Please return only the data in the following structured JSON format without any additional text:\r\n\r\n        {{\r\n            \"name\": \"The name of the webpage or article\",\r\n            \"number_of_likes\": 0,  # The number of likes (if available)\r\n            \"comments\": [],  # List of comments (if available)\r\n            \"author\": \"Author of the content (if available)\",\r\n            \"publication_date\": \"YYYY-MM-DD\"  # Publication date in YYYY-MM-DD format (if available)\r\n        }}\r\n\r\n        If any information is missing, set the field to an empty string or an empty list, as appropriate.\r\n\r\n        Example:\r\n        {{\r\n            \"name\": \"Example Article\",\r\n            \"number_of_likes\": 100,\r\n            \"comments\": [\"Great article!\", \"Very informative.\"],\r\n            \"author\": \"Jane Doe\",\r\n            \"publication_date\": \"2023-08-15\"\r\n        }}\r\n        \"\"\"\r\n        return prompt\r\n\r\n    async def generate_metadata_from_url_and_content(self, url: str, content: str) -> dict:\r\n        \"\"\"Uses an LLM to extract metadata by passing both the URL and content.\"\"\"\r\n        prompt = await self.generate_prompt(content)\r\n        metadata_str = \"\"  # Initialize to ensure it's always defined\r\n\r\n        try:\r\n            # Initialize ChatOpenAI with parameters\r\n            chat_openai = ChatOpenAI(\r\n                model=\"gpt-4\",\r\n                temperature=0.1,  # Default temperature; adjust as needed\r\n                max_tokens=500,\r\n                api_key=self.api_key,  # Use the API key directly as a string\r\n            )\r\n\r\n            # Construct messages using proper message classes\r\n            messages = [\r\n                SystemMessage(content=\"You are a helpful assistant.\"),\r\n                HumanMessage(content=prompt)\r\n            ]\r\n\r\n            # Make an asynchronous call to the LLM with a list of message lists\r\n            response = await chat_openai.agenerate([messages])\r\n\r\n            # Access the generated text\r\n            metadata_str = response.generations[0][0].text.strip()\r\n            \r\n            # Extract JSON using regex to find the first JSON object in the response\r\n            json_match = re.search(r'\\{.*\\}', metadata_str, re.DOTALL)\r\n            if json_match:\r\n                metadata_str = json_match.group()\r\n            else:\r\n                raise ValueError(\"No JSON object found in the LLM response.\")\r\n\r\n            metadata = json.loads(metadata_str)\r\n\r\n            return {\r\n              \r\n                \"name\": metadata.get(\"name\", \"Unknown\"),\r\n                \"number_of_likes\": int(metadata.get(\"number_of_likes\", 0)) if isinstance(metadata.get(\"number_of_likes\", 0), (int, float, str)) else 0,\r\n                \"comments\": metadata.get(\"comments\", []),\r\n                \"author\": metadata.get(\"author\", \"Unknown\"),\r\n                \"publication_date\": metadata.get(\"publication_date\", \"\")\r\n            }\r\n\r\n        except json.JSONDecodeError as jde:\r\n            logger.error(f\"JSON decoding failed for URL {url}: {jde}\")\r\n            logger.debug(f\"LLM Response: {metadata_str}\")\r\n            return {\r\n              \r\n                \"name\": \"Unknown\",\r\n                \"number_of_likes\": 0,\r\n                \"comments\": [],\r\n                \"author\": \"Unknown\",\r\n                \"publication_date\": \"\"\r\n            }\r\n        except Exception as e:\r\n            logger.error(f\"An error occurred while generating metadata for URL {url}: {e}\")\r\n            return {\r\n                \r\n                \"name\": \"Unknown\",\r\n                \"number_of_likes\": 0,\r\n                \"comments\": [],\r\n                \"author\": \"Unknown\",\r\n                \"publication_date\": \"\"\r\n            }\r\n\r\n    async def fetch_url_content(self, urls: list[str]) -> list[Data]:\r\n        \"\"\"Fetches content from the provided URLs and uses LLM for metadata extraction.\"\"\"\r\n        urls = [self.ensure_url(url.strip()) for url in urls if url.strip()]\r\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\r\n        docs = loader.load()\r\n        data_list = []\r\n\r\n        logger.info(f\"Fetched {len(docs)} documents from URLs.\")\r\n        url_docs=zip(docs,urls)\r\n        # Loop through each document\r\n        for doc,link in url_docs:\r\n            url = link\r\n            content = doc.page_content\r\n            logger.info(f\"Processing URL: {url}\")\r\n\r\n            metadata = await self.generate_metadata_from_url_and_content(url, content)\r\n            \r\n            # Create a Data object with the metadata returned from the LLM\r\n            data = Data(\r\n                text=content,\r\n                url=url,\r\n                timestamp=datetime.utcnow().isoformat(),\r\n                name=metadata.get(\"name\"),\r\n                number_of_likes=str(metadata.get(\"number_of_likes\", 0)),\r\n                comments=metadata.get(\"comments\", []),\r\n                author=metadata.get(\"author\", \"Unknown\"),\r\n                publication_date=metadata.get(\"publication_date\", \"\")\r\n            )\r\n            data_list.append(data)\r\n\r\n        return data_list\r\n\r\n    async def create_list(self) -> list[Data]:\r\n        data_list = []\r\n        urls = []\r\n        \r\n        # Determine file type and parse accordingly\r\n        if self.file_path.endswith(\".csv\"):\r\n            logger.info(f\"Processing CSV file: {self.file_path}\")\r\n            df = pd.read_csv(self.file_path)\r\n            if self.column_name and self.column_name in df.columns:\r\n                texts = df[self.column_name].tolist()\r\n                logger.info(f\"Extracted texts from column '{self.column_name}'.\")\r\n            else:\r\n                texts = df.to_string(index=False).splitlines()\r\n                logger.info(f\"No column specified or column not found. Extracted all lines as texts.\")\r\n        elif self.file_path.endswith(\".json\"):\r\n            logger.info(f\"Processing JSON file: {self.file_path}\")\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                json_data = json.load(f)\r\n                if self.column_name and self.column_name in json_data:\r\n                    texts = json_data[self.column_name]\r\n                    logger.info(f\"Extracted texts from key '{self.column_name}'.\")\r\n                else:\r\n                    texts = [json.dumps(json_data)]\r\n                    logger.info(f\"No key specified or key not found. Serialized entire JSON object as a single text entry.\")\r\n        else:\r\n            logger.info(f\"Processing TXT file: {self.file_path}\")\r\n            with open(self.file_path, 'r', encoding='utf-8') as f:\r\n                texts = f.readlines()\r\n            logger.info(f\"Extracted {len(texts)} lines from TXT file.\")\r\n\r\n        # Separate URLs from regular text\r\n        for text in texts:\r\n            text = text.strip()\r\n            if re.match(r'^(https?:\\/\\/)', text):\r\n                urls.append(text)\r\n                logger.info(f\"Identified URL: {text}\")\r\n            else:\r\n                logger.info(f\"Non-URL text found and skipped: {text}\")\r\n\r\n        # If URLs are present, fetch their content and extract metadata\r\n        if urls:\r\n            fetched_data = await self.fetch_url_content(urls)\r\n            data_list.extend(fetched_data)\r\n            logger.info(f\"Added {len(fetched_data)} Data objects from URLs.\")\r\n        else:\r\n            logger.warning(\"No URLs found in the input file.\")\r\n\r\n        self.status = data_list\r\n        logger.info(\"Data list creation completed.\")\r\n        return data_list\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "column_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "column_name",
                  "value": "savedItem",
                  "display_name": "Column Name (for CSV/JSON)",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Specify the column name if using CSV or JSON files.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Creates a list of texts from a file, fetches content from URLs if present, and extracts metadata using OpenAI's LLM.",
              "icon": "list",
              "base_classes": [
                "Data"
              ],
              "display_name": "Create List",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "list",
                  "display_name": "Data List",
                  "method": "create_list",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "file_path",
                "column_name",
                "api_key"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba"
          },
          "selected": false,
          "width": 384,
          "height": 523,
          "positionAbsolute": {
            "x": -118.4211792171294,
            "y": -79.97852769744964
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "RecursiveCharacterTextSplitter-jBqJZ",
          "sourceHandle": "{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}",
          "target": "Chroma-tqgXG",
          "targetHandle": "{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "Chroma-tqgXG",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "RecursiveCharacterTextSplitter",
              "id": "RecursiveCharacterTextSplitter-jBqJZ",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-RecursiveCharacterTextSplitter-jBqJZ{dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-jBqJZ,name:data,output_types:[Data]}-Chroma-tqgXG{fieldName:ingest_data,id:Chroma-tqgXG,inputTypes:[Data],type:other}",
          "className": ""
        },
        {
          "source": "CohereEmbeddings-3IoMM",
          "sourceHandle": "{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}",
          "target": "Chroma-tqgXG",
          "targetHandle": "{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "Chroma-tqgXG",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CohereEmbeddings",
              "id": "CohereEmbeddings-3IoMM",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-CohereEmbeddings-3IoMM{dataType:CohereEmbeddings,id:CohereEmbeddings-3IoMM,name:embeddings,output_types:[Embeddings]}-Chroma-tqgXG{fieldName:embedding,id:Chroma-tqgXG,inputTypes:[Embeddings],type:other}",
          "className": ""
        },
        {
          "source": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba",
          "sourceHandle": "{dataType:CreateListFromFileWithURLParsingAndMetadataExtraction,id:CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba,name:list,output_types:[Data]}",
          "target": "RecursiveCharacterTextSplitter-jBqJZ",
          "targetHandle": "{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
          "data": {
            "targetHandle": {
              "fieldName": "data_input",
              "id": "RecursiveCharacterTextSplitter-jBqJZ",
              "inputTypes": [
                "Document",
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CreateListFromFileWithURLParsingAndMetadataExtraction",
              "id": "CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba",
              "name": "list",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba{dataType:CreateListFromFileWithURLParsingAndMetadataExtraction,id:CreateListFromFileWithURLParsingAndMetadataExtraction-c67ba,name:list,output_types:[Data]}-RecursiveCharacterTextSplitter-jBqJZ{fieldName:data_input,id:RecursiveCharacterTextSplitter-jBqJZ,inputTypes:[Document,Data],type:other}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 314.4154753960768,
        "y": 77.44848851731638,
        "zoom": 0.48085212666200444
      }
    },
    "date_created": "2024-10-04T10:16:54.301Z",
    "date_updated": "2024-10-04T10:16:54.498Z",
    "status": "Public",
    "sort": null,
    "user_updated": "694f46e0-3805-4a2c-9852-cd3f52377859",
    "user_created": {
      "username": "SahilSapte",
      "first_name": "Sahil",
      "last_name": "Sapte",
      "id": "694f46e0-3805-4a2c-9852-cd3f52377859"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:54.655Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 38,
    "converter_version": "1.0.0"
  }
}